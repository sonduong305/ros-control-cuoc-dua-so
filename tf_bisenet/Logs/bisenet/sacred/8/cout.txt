INFO - bisenet-v2 - Running command 'main'
INFO - bisenet-v2 - Started run with ID "8"
INFO - root - nvidia-ml-py is not installed, automatically select gpu is disabled!
WARNING:tensorflow:From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - tensorflow - From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - root - img_mean is not explicitly specified, using default value: None
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:53: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:53: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:65: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:65: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO - root - preproces -- augment
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:73: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:73: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:74: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:74: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:131: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/Dataset/dataset.py:131: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:156: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:156: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a245128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a245128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a245128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a245128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c498e6080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498e6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a22a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a22a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a22a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a22a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49326a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49326a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49326a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49326a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4a22a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a278588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a278588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a278588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a278588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c4a22a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c4a22a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c4a22a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c4a22a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a278630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a278630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a278630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a278630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a119f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a119f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a119f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a119f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a16d208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49900860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49900860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49900860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49900860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a0af7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a0af7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a0af7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a0af7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926b860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926b860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926b860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926b860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a181d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a181d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a181d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a181d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926bd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926bd30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926bd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4926bd30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a07d8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a07d8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a07d8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a07d8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f878d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f878d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f878d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f878d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49900748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49900748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49900748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49900748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03d30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03d30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e7e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e7e550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e7e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e7e550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49f03128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e63d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e63d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e63d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49e63d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d66cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d66cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d66cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d66cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4a0af080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d66cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d66cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d66cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d66cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb80f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb80f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49bb0c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49bb0c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49bb0c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49bb0c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a119ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c03320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c03320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c03320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c03320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49a23f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49a23f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49a23f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49a23f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c95630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49c95630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49a23cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49a23cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49a23cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49a23cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4992d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4992d668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4992d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4992d668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49257e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49257e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49257e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49257e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49926630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49926630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49926630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49926630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4998f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4998f860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4998f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4998f860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49d7b668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb8be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb8be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb8be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49cb8be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49794278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49794278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49794278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49794278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d7bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d7bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d7bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49d7bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499ffba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499ffba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499ffba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499ffba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982fb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982fb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982fb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982fb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982f5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982f5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982f5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4982f5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49761668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49761668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49761668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49761668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49761780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49761780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49761780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49761780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c495c1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c495c1fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c495c1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c495c1fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c499fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c499fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c499fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c499fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49707320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49707320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49707320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49707320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4973b5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4973b5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4973b5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4973b5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49603a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49603a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49603a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c49603a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4959a358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4959a358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4959a358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4959a358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4957e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4957e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4957e6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4957e6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49893080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49893080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49893080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49893080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4978e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4978e128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4978e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4978e128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49794e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49794e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49794e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49794e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4947ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4947ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4947ba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4947ba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4957e048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4957e048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4957e048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4957e048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491ee7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491ee7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491ee7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491ee7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978eac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978eac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978eac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978eac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978ee80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4978ee80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490fff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490fff60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c495efcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c495efcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c495efcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c495efcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c491ea390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c491ea390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c491ea390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c491ea390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c491c8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4968ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4968ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4968ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4968ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49465b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49465b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49465b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c49465b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c493736a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c493736a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c493736a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c493736a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a26d978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a26d978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a26d978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c4a26d978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48fbdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48fbdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48fbdd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48fbdd68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48f73278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48f73278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48f73278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48f73278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48df4f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48df4f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48df4f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48df4f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48f73278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c498bc400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490ff780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490ff780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490ff780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c490ff780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ffd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ffd30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ffd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ffd30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48debe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48debe80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48debe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48debe80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ff6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ff6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ff6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c490ff6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48c14be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48c14be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48c14be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48c14be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48ca9ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48ca9ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48ca9ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48ca9ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b9cc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b9cc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b9cc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b9cc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e4f080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48b331d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48c14518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48c14518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48c14518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48c14518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f39e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f39e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f39e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f39e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e5a978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e5a978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e5a978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48e5a978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48a2fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48a2fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48a2fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48a2fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48b33b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48b33b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48b33b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48b33b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c489f3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48a2fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48a2fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48a2fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c48a2fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48866a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c489ac940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48776780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48776780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48776780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48776780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c489ace48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c489ace48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c489ace48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c489ace48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48695128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48695128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48695128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48695128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:178: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:178: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c488667b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c488667b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c488667b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c488667b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c486fbcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c486fbcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c486fbcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c486fbcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48646128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48646128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48646128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48646128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48695128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c485e1b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c485e1b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c485e1b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c485e1b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c485e1780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c485e1780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c485e1780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c485e1780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499224a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499224a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499224a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c499224a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4860df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4860df98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4860df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4860df98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48537390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48537390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48537390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48537390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c484f5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c484f5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c484f5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c484f5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c487982b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c487982b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c487982b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c487982b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4845d748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4845d748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4845d748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4845d748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4845d438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4845d438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4845d438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4845d438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48798e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48798e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48798e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48798e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48476c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48476c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48476c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48476c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48e5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48e5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48e5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c48e5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848dcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848dcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848dcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4848dcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4839c908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4839c908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4839c908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4839c908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839cb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839cb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839cb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839cb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4833b4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4833b4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4833b4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4833b4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48351eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48351eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48351eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c48351eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c482c2630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c482c2630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c482c2630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c482c2630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c482a9be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c482a9be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c482a9be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c482a9be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4821f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4821f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4821f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4821f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839c6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839c6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839c6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c4839c6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:216: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:216: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:220: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:220: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:223: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:223: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:228: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:228: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:235: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:235: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:239: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/bisenet-tensorflow/models/bisenet.py:239: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - root - img_mean is not explicitly specified, using default value: None
INFO - root - preproces -- None
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db09b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db09b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db09b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db09b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e183c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e183c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e183c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e183c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e18fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e184e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e184e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e184e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e184e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e185f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e185f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e185f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43e185f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e188d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db0748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43db0748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e18400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e18400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e18400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e18400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c43db0d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c43db0d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c43db0d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3c43db0d68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eebcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eebcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eebcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eebcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeba20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeba20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e052e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e052e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e052e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e052e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e055c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e055c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e055c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e055c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e27908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e27908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e27908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e27908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e27278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e27278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e27278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e27278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e185f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e185f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e185f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e185f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed84a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed84a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed84a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed84a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ee2470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ee2470>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ee2470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ee2470>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed8438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed8438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed8438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed8438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e2b198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e2b198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e2b198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e2b198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed81d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed81d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed81d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed81d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeb080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeb080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeb080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eeb080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eebcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eebcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eebcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eebcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eeb4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ed1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ed1710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ed1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ed1710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e2be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e2be10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e2be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e2be10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e1ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e1ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e1ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e1ea90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed16d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed16d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed16d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ed16d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3a3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3a3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3a3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3a3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e1e748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e1e748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e1e748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e1e748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3ab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3ab70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3ab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43f3ab70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e24400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3a0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e9e358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e9e358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e9e358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e9e358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e24ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e24ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e24ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e24ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3aa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3aa58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3aa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3aa58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e90b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3ac88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3ac88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3ac88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43f3ac88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ebb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ebb710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ebb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ebb710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ebbda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ebbda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ebbda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ebbda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4e828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4e828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4e828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e4e828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e46940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e46940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e46940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e46940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e752b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e752b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e752b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e752b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e4e358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e4e358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e4e358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e4e358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e6b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e6b160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e6b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43e6b160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43ee4320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d6cfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d6cfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d6cfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d6cfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e75400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e75400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e75400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e75400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eb6160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eb6160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eb6160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43eb6160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eb61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eb61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eb61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43eb61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d4ee10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6ce80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6ce80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6ce80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6ce80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4e2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4e2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d35710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d35710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d35710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d35710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e6b128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e6b128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e6b128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43e6b128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d15898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d15898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d15898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d15898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c860>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d61748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d61748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d61748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d61748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d6c400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cc5f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d613c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d613c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d613c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d613c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d3a7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d3a7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d3a7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43d3a7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cc5668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfea58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfea58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3add8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3add8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3add8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3add8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfe780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfe780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfe780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cfe780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3acf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3acf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3acf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d3acf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cd8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cd8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cd8e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43cd8e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c53358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c53358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c53358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c53358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43cfe4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d4eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c652b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c652b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c652b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c652b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c536a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c536a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c536a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c536a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c65160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d26198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d26198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d26198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43d26198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c5c048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c5c048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c5c048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c5c048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c63da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c63da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c63da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c63da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c65ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c31748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c31748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c31748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c31748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c313c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c313c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c313c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c313c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c9b7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c9b7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c9b7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c9b7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9b898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9b898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9b898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9b898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c1a7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c1a7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c1a7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c1a7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9bf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c9bf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c75828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c75828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c75828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c75828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2b048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2b048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2b048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2b048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c31e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c31e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c31e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c31e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c2bbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c2bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c2bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c2bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c2bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c3d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c3d780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c3d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43c3d780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f3c43c0f710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bf6588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bad8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bad8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bad8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bad8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bf6b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ba6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ba6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ba6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ba6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0ccf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0ccf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0ccf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0ccf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43badb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43badb70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43badb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43badb70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bbaac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bbaac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bbaac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bbaac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bcd550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bcd550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bcd550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43bcd550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bba7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bba7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bba7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43bba7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7a9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7a9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7a9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7a9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7a160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7a160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7a160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7a160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0c518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0c518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0c518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b0c518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b0c438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4854ebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4854ebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4854ebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c4854ebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498b64e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498b64e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498b64e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c498b64e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43c1b278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43c1b278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43c1b278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43c1b278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ba6630>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c484f5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c484f5048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c484f5048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c484f5048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b691d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b691d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b691d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b691d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7af60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43b7af60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43b7ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ac5e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ac5e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ac5e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43ac5e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af52e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af52e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af52e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af52e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43af5c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43af5c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43af5c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f3c43af5c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af5b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af5b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af5b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43af5b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43a24c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43a24c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43a24c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43a24c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ac7cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ac7cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ac7cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3c43ac7cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From train.py:66: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From train.py:66: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING - tensorflow - From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From train.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING - tensorflow - From train.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING - tensorflow - From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING - tensorflow - From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING - tensorflow - From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-11-04 03:33:50.335618: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-04 03:33:50.340738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-04 03:33:50.437440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.437896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b8813c3a0 executing computations on platform CUDA. Devices:
2019-11-04 03:33:50.437913: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-11-04 03:33:50.457888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-11-04 03:33:50.458771: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b880b4e80 executing computations on platform Host. Devices:
2019-11-04 03:33:50.458821: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-04 03:33:50.459348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.460350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-04 03:33:50.461613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-11-04 03:33:50.478899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-11-04 03:33:50.488489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-11-04 03:33:50.500307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-11-04 03:33:50.515077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-11-04 03:33:50.526183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-11-04 03:33:50.555852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-04 03:33:50.555971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.556390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.556746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-04 03:33:50.556785: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-11-04 03:33:50.557661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-04 03:33:50.557681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-04 03:33:50.557687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-04 03:33:50.557868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.558430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-04 03:33:50.558834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6951 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-11-04 03:33:51.872504: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO - root - Train for 6000000 steps
2019-11-04 03:33:56.761165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
INFO - root - 2019-11-04 03:33:58.494702: step 0, total loss = 6.34, predict loss = 1.66 (0.7 examples/sec; 5.981 sec/batch; 9968h:52m:52s remains)
2019-11-04 03:33:59.999659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
INFO - root - 2019-11-04 03:34:02.389061: step 10, total loss = 1.99, predict loss = 0.57 (87.1 examples/sec; 0.046 sec/batch; 76h:33m:11s remains)
INFO - root - 2019-11-04 03:34:02.891698: step 20, total loss = 1.46, predict loss = 0.35 (89.2 examples/sec; 0.045 sec/batch; 74h:45m:16s remains)
INFO - root - 2019-11-04 03:34:03.398442: step 30, total loss = 1.84, predict loss = 0.58 (96.9 examples/sec; 0.041 sec/batch; 68h:49m:46s remains)
INFO - root - 2019-11-04 03:34:03.888552: step 40, total loss = 2.00, predict loss = 0.62 (91.7 examples/sec; 0.044 sec/batch; 72h:42m:23s remains)
INFO - root - 2019-11-04 03:34:04.394360: step 50, total loss = 1.45, predict loss = 0.41 (85.9 examples/sec; 0.047 sec/batch; 77h:38m:19s remains)
INFO - root - 2019-11-04 03:34:04.886488: step 60, total loss = 1.42, predict loss = 0.44 (92.0 examples/sec; 0.043 sec/batch; 72h:28m:55s remains)
INFO - root - 2019-11-04 03:34:05.379826: step 70, total loss = 1.90, predict loss = 0.56 (93.3 examples/sec; 0.043 sec/batch; 71h:29m:16s remains)
INFO - root - 2019-11-04 03:34:05.864351: step 80, total loss = 1.86, predict loss = 0.50 (95.5 examples/sec; 0.042 sec/batch; 69h:49m:06s remains)
INFO - root - 2019-11-04 03:34:06.379363: step 90, total loss = 1.29, predict loss = 0.38 (86.2 examples/sec; 0.046 sec/batch; 77h:22m:35s remains)
INFO - root - 2019-11-04 03:34:06.877540: step 100, total loss = 1.98, predict loss = 0.58 (84.9 examples/sec; 0.047 sec/batch; 78h:32m:28s remains)
INFO - root - 2019-11-04 03:34:07.398051: step 110, total loss = 1.37, predict loss = 0.35 (88.7 examples/sec; 0.045 sec/batch; 75h:10m:23s remains)
INFO - root - 2019-11-04 03:34:07.957458: step 120, total loss = 1.11, predict loss = 0.29 (67.1 examples/sec; 0.060 sec/batch; 99h:21m:09s remains)
INFO - root - 2019-11-04 03:34:08.581731: step 130, total loss = 0.93, predict loss = 0.28 (69.5 examples/sec; 0.058 sec/batch; 95h:52m:40s remains)
INFO - root - 2019-11-04 03:34:09.156214: step 140, total loss = 0.89, predict loss = 0.21 (79.5 examples/sec; 0.050 sec/batch; 83h:49m:30s remains)
INFO - root - 2019-11-04 03:34:09.724534: step 150, total loss = 0.77, predict loss = 0.18 (83.4 examples/sec; 0.048 sec/batch; 79h:56m:23s remains)
INFO - root - 2019-11-04 03:34:10.245474: step 160, total loss = 0.91, predict loss = 0.19 (79.0 examples/sec; 0.051 sec/batch; 84h:21m:45s remains)
INFO - root - 2019-11-04 03:34:10.766223: step 170, total loss = 1.00, predict loss = 0.26 (89.6 examples/sec; 0.045 sec/batch; 74h:22m:09s remains)
INFO - root - 2019-11-04 03:34:11.280161: step 180, total loss = 0.91, predict loss = 0.26 (88.8 examples/sec; 0.045 sec/batch; 75h:03m:29s remains)
INFO - root - 2019-11-04 03:34:11.788138: step 190, total loss = 0.99, predict loss = 0.27 (84.3 examples/sec; 0.047 sec/batch; 79h:02m:36s remains)
INFO - root - 2019-11-04 03:34:12.303948: step 200, total loss = 1.34, predict loss = 0.39 (87.3 examples/sec; 0.046 sec/batch; 76h:21m:10s remains)
INFO - root - 2019-11-04 03:34:12.809219: step 210, total loss = 0.84, predict loss = 0.19 (86.2 examples/sec; 0.046 sec/batch; 77h:18m:36s remains)
INFO - root - 2019-11-04 03:34:13.330776: step 220, total loss = 0.89, predict loss = 0.23 (84.9 examples/sec; 0.047 sec/batch; 78h:29m:07s remains)
INFO - root - 2019-11-04 03:34:13.911623: step 230, total loss = 0.71, predict loss = 0.19 (77.8 examples/sec; 0.051 sec/batch; 85h:44m:08s remains)
INFO - root - 2019-11-04 03:34:14.450182: step 240, total loss = 0.79, predict loss = 0.19 (73.1 examples/sec; 0.055 sec/batch; 91h:09m:44s remains)
INFO - root - 2019-11-04 03:34:14.953986: step 250, total loss = 1.09, predict loss = 0.23 (88.4 examples/sec; 0.045 sec/batch; 75h:24m:52s remains)
INFO - root - 2019-11-04 03:34:15.499255: step 260, total loss = 1.12, predict loss = 0.25 (79.7 examples/sec; 0.050 sec/batch; 83h:40m:01s remains)
INFO - root - 2019-11-04 03:34:16.019448: step 270, total loss = 0.95, predict loss = 0.21 (87.6 examples/sec; 0.046 sec/batch; 76h:06m:42s remains)
INFO - root - 2019-11-04 03:34:16.527913: step 280, total loss = 0.95, predict loss = 0.25 (86.8 examples/sec; 0.046 sec/batch; 76h:49m:05s remains)
INFO - root - 2019-11-04 03:34:17.040196: step 290, total loss = 1.22, predict loss = 0.37 (66.3 examples/sec; 0.060 sec/batch; 100h:30m:07s remains)
INFO - root - 2019-11-04 03:34:17.705950: step 300, total loss = 0.72, predict loss = 0.20 (66.9 examples/sec; 0.060 sec/batch; 99h:41m:51s remains)
INFO - root - 2019-11-04 03:34:18.302006: step 310, total loss = 1.12, predict loss = 0.30 (62.7 examples/sec; 0.064 sec/batch; 106h:23m:08s remains)
INFO - root - 2019-11-04 03:34:18.862832: step 320, total loss = 1.15, predict loss = 0.30 (87.3 examples/sec; 0.046 sec/batch; 76h:21m:18s remains)
INFO - root - 2019-11-04 03:34:19.392093: step 330, total loss = 0.85, predict loss = 0.23 (85.9 examples/sec; 0.047 sec/batch; 77h:38m:56s remains)
INFO - root - 2019-11-04 03:34:19.904986: step 340, total loss = 1.30, predict loss = 0.35 (93.1 examples/sec; 0.043 sec/batch; 71h:37m:32s remains)
INFO - root - 2019-11-04 03:34:20.438668: step 350, total loss = 1.21, predict loss = 0.35 (80.4 examples/sec; 0.050 sec/batch; 82h:54m:24s remains)
INFO - root - 2019-11-04 03:34:21.112317: step 360, total loss = 2.28, predict loss = 0.79 (85.5 examples/sec; 0.047 sec/batch; 77h:58m:13s remains)
INFO - root - 2019-11-04 03:34:21.837968: step 370, total loss = 1.10, predict loss = 0.27 (73.4 examples/sec; 0.055 sec/batch; 90h:52m:14s remains)
INFO - root - 2019-11-04 03:34:22.556385: step 380, total loss = 0.96, predict loss = 0.23 (69.4 examples/sec; 0.058 sec/batch; 96h:05m:25s remains)
INFO - root - 2019-11-04 03:34:23.172357: step 390, total loss = 1.12, predict loss = 0.24 (77.5 examples/sec; 0.052 sec/batch; 86h:00m:32s remains)
INFO - root - 2019-11-04 03:34:23.805081: step 400, total loss = 1.22, predict loss = 0.31 (67.4 examples/sec; 0.059 sec/batch; 98h:56m:27s remains)
INFO - root - 2019-11-04 03:34:24.332706: step 410, total loss = 1.09, predict loss = 0.25 (95.3 examples/sec; 0.042 sec/batch; 69h:56m:55s remains)
INFO - root - 2019-11-04 03:34:24.857954: step 420, total loss = 1.23, predict loss = 0.35 (88.6 examples/sec; 0.045 sec/batch; 75h:15m:29s remains)
INFO - root - 2019-11-04 03:34:25.365006: step 430, total loss = 1.08, predict loss = 0.26 (84.2 examples/sec; 0.048 sec/batch; 79h:09m:50s remains)
INFO - root - 2019-11-04 03:34:25.893192: step 440, total loss = 0.81, predict loss = 0.20 (70.8 examples/sec; 0.057 sec/batch; 94h:10m:42s remains)
INFO - root - 2019-11-04 03:34:26.495618: step 450, total loss = 1.00, predict loss = 0.28 (82.5 examples/sec; 0.048 sec/batch; 80h:45m:28s remains)
INFO - root - 2019-11-04 03:34:26.990394: step 460, total loss = 1.13, predict loss = 0.27 (88.2 examples/sec; 0.045 sec/batch; 75h:36m:59s remains)
INFO - root - 2019-11-04 03:34:27.482687: step 470, total loss = 0.95, predict loss = 0.23 (84.4 examples/sec; 0.047 sec/batch; 79h:01m:22s remains)
INFO - root - 2019-11-04 03:34:27.988175: step 480, total loss = 0.67, predict loss = 0.17 (87.3 examples/sec; 0.046 sec/batch; 76h:21m:35s remains)
INFO - root - 2019-11-04 03:34:28.483586: step 490, total loss = 1.03, predict loss = 0.28 (88.6 examples/sec; 0.045 sec/batch; 75h:16m:05s remains)
INFO - root - 2019-11-04 03:34:28.980977: step 500, total loss = 0.94, predict loss = 0.26 (90.5 examples/sec; 0.044 sec/batch; 73h:38m:01s remains)
INFO - root - 2019-11-04 03:34:29.467072: step 510, total loss = 0.86, predict loss = 0.24 (87.9 examples/sec; 0.046 sec/batch; 75h:50m:55s remains)
INFO - root - 2019-11-04 03:34:29.967269: step 520, total loss = 0.96, predict loss = 0.25 (84.8 examples/sec; 0.047 sec/batch; 78h:37m:10s remains)
INFO - root - 2019-11-04 03:34:30.482163: step 530, total loss = 1.53, predict loss = 0.40 (78.8 examples/sec; 0.051 sec/batch; 84h:34m:27s remains)
INFO - root - 2019-11-04 03:34:30.984121: step 540, total loss = 0.85, predict loss = 0.21 (85.7 examples/sec; 0.047 sec/batch; 77h:44m:31s remains)
INFO - root - 2019-11-04 03:34:31.502811: step 550, total loss = 0.88, predict loss = 0.19 (84.0 examples/sec; 0.048 sec/batch; 79h:23m:27s remains)
INFO - root - 2019-11-04 03:34:32.015308: step 560, total loss = 1.25, predict loss = 0.30 (89.3 examples/sec; 0.045 sec/batch; 74h:39m:23s remains)
INFO - root - 2019-11-04 03:34:32.505673: step 570, total loss = 0.77, predict loss = 0.21 (78.0 examples/sec; 0.051 sec/batch; 85h:30m:39s remains)
INFO - root - 2019-11-04 03:34:32.998733: step 580, total loss = 1.53, predict loss = 0.49 (87.5 examples/sec; 0.046 sec/batch; 76h:12m:25s remains)
INFO - root - 2019-11-04 03:34:33.495720: step 590, total loss = 0.87, predict loss = 0.21 (87.4 examples/sec; 0.046 sec/batch; 76h:16m:29s remains)
INFO - root - 2019-11-04 03:34:33.990547: step 600, total loss = 0.71, predict loss = 0.21 (87.6 examples/sec; 0.046 sec/batch; 76h:06m:45s remains)
INFO - root - 2019-11-04 03:34:34.479154: step 610, total loss = 0.74, predict loss = 0.18 (88.4 examples/sec; 0.045 sec/batch; 75h:23m:23s remains)
INFO - root - 2019-11-04 03:34:34.988741: step 620, total loss = 1.11, predict loss = 0.31 (88.9 examples/sec; 0.045 sec/batch; 74h:58m:45s remains)
INFO - root - 2019-11-04 03:34:35.482882: step 630, total loss = 0.76, predict loss = 0.18 (92.9 examples/sec; 0.043 sec/batch; 71h:43m:47s remains)
INFO - root - 2019-11-04 03:34:35.973705: step 640, total loss = 0.75, predict loss = 0.22 (90.7 examples/sec; 0.044 sec/batch; 73h:27m:33s remains)
INFO - root - 2019-11-04 03:34:36.470890: step 650, total loss = 0.66, predict loss = 0.18 (91.9 examples/sec; 0.044 sec/batch; 72h:33m:34s remains)
INFO - root - 2019-11-04 03:34:36.981234: step 660, total loss = 0.98, predict loss = 0.27 (88.3 examples/sec; 0.045 sec/batch; 75h:29m:07s remains)
INFO - root - 2019-11-04 03:34:37.483945: step 670, total loss = 0.82, predict loss = 0.20 (80.2 examples/sec; 0.050 sec/batch; 83h:04m:45s remains)
INFO - root - 2019-11-04 03:34:37.975654: step 680, total loss = 0.62, predict loss = 0.14 (88.3 examples/sec; 0.045 sec/batch; 75h:28m:30s remains)
INFO - root - 2019-11-04 03:34:38.469393: step 690, total loss = 0.62, predict loss = 0.16 (85.2 examples/sec; 0.047 sec/batch; 78h:16m:12s remains)
INFO - root - 2019-11-04 03:34:38.967302: step 700, total loss = 0.76, predict loss = 0.19 (84.6 examples/sec; 0.047 sec/batch; 78h:46m:22s remains)
INFO - root - 2019-11-04 03:34:39.455352: step 710, total loss = 0.61, predict loss = 0.16 (88.1 examples/sec; 0.045 sec/batch; 75h:38m:01s remains)
INFO - root - 2019-11-04 03:34:40.014434: step 720, total loss = 0.85, predict loss = 0.19 (86.1 examples/sec; 0.046 sec/batch; 77h:23m:51s remains)
INFO - root - 2019-11-04 03:34:40.496511: step 730, total loss = 0.83, predict loss = 0.24 (91.1 examples/sec; 0.044 sec/batch; 73h:11m:56s remains)
INFO - root - 2019-11-04 03:34:41.002094: step 740, total loss = 0.71, predict loss = 0.20 (78.8 examples/sec; 0.051 sec/batch; 84h:35m:36s remains)
INFO - root - 2019-11-04 03:34:41.524729: step 750, total loss = 0.58, predict loss = 0.16 (87.7 examples/sec; 0.046 sec/batch; 76h:00m:39s remains)
INFO - root - 2019-11-04 03:34:42.024879: step 760, total loss = 0.54, predict loss = 0.16 (91.1 examples/sec; 0.044 sec/batch; 73h:07m:55s remains)
INFO - root - 2019-11-04 03:34:42.522605: step 770, total loss = 0.64, predict loss = 0.18 (85.2 examples/sec; 0.047 sec/batch; 78h:11m:39s remains)
INFO - root - 2019-11-04 03:34:43.017246: step 780, total loss = 0.93, predict loss = 0.23 (84.2 examples/sec; 0.048 sec/batch; 79h:12m:23s remains)
INFO - root - 2019-11-04 03:34:43.516806: step 790, total loss = 1.12, predict loss = 0.25 (89.2 examples/sec; 0.045 sec/batch; 74h:43m:58s remains)
INFO - root - 2019-11-04 03:34:44.009170: step 800, total loss = 0.58, predict loss = 0.12 (91.3 examples/sec; 0.044 sec/batch; 73h:00m:24s remains)
INFO - root - 2019-11-04 03:34:44.487139: step 810, total loss = 0.66, predict loss = 0.16 (101.8 examples/sec; 0.039 sec/batch; 65h:29m:27s remains)
INFO - root - 2019-11-04 03:34:44.983222: step 820, total loss = 0.58, predict loss = 0.15 (85.3 examples/sec; 0.047 sec/batch; 78h:08m:17s remains)
INFO - root - 2019-11-04 03:34:45.512481: step 830, total loss = 0.73, predict loss = 0.21 (77.1 examples/sec; 0.052 sec/batch; 86h:25m:30s remains)
INFO - root - 2019-11-04 03:34:46.015935: step 840, total loss = 1.08, predict loss = 0.27 (91.1 examples/sec; 0.044 sec/batch; 73h:08m:33s remains)
INFO - root - 2019-11-04 03:34:46.507245: step 850, total loss = 1.09, predict loss = 0.31 (89.1 examples/sec; 0.045 sec/batch; 74h:49m:07s remains)
INFO - root - 2019-11-04 03:34:47.003699: step 860, total loss = 0.89, predict loss = 0.24 (90.4 examples/sec; 0.044 sec/batch; 73h:44m:44s remains)
INFO - root - 2019-11-04 03:34:47.491718: step 870, total loss = 0.50, predict loss = 0.13 (93.2 examples/sec; 0.043 sec/batch; 71h:30m:28s remains)
INFO - root - 2019-11-04 03:34:47.999782: step 880, total loss = 0.73, predict loss = 0.20 (97.5 examples/sec; 0.041 sec/batch; 68h:23m:24s remains)
INFO - root - 2019-11-04 03:34:48.493050: step 890, total loss = 0.73, predict loss = 0.15 (87.6 examples/sec; 0.046 sec/batch; 76h:06m:59s remains)
INFO - root - 2019-11-04 03:34:49.000562: step 900, total loss = 0.76, predict loss = 0.16 (86.2 examples/sec; 0.046 sec/batch; 77h:22m:06s remains)
INFO - root - 2019-11-04 03:34:49.485721: step 910, total loss = 0.68, predict loss = 0.19 (86.6 examples/sec; 0.046 sec/batch; 77h:00m:13s remains)
INFO - root - 2019-11-04 03:34:49.981314: step 920, total loss = 0.84, predict loss = 0.23 (88.8 examples/sec; 0.045 sec/batch; 75h:01m:39s remains)
INFO - root - 2019-11-04 03:34:50.475679: step 930, total loss = 0.69, predict loss = 0.19 (87.9 examples/sec; 0.046 sec/batch; 75h:51m:15s remains)
INFO - root - 2019-11-04 03:34:50.967689: step 940, total loss = 0.53, predict loss = 0.15 (94.8 examples/sec; 0.042 sec/batch; 70h:19m:29s remains)
INFO - root - 2019-11-04 03:34:51.463136: step 950, total loss = 1.31, predict loss = 0.23 (90.5 examples/sec; 0.044 sec/batch; 73h:41m:34s remains)
INFO - root - 2019-11-04 03:34:51.968540: step 960, total loss = 0.56, predict loss = 0.16 (84.9 examples/sec; 0.047 sec/batch; 78h:27m:57s remains)
INFO - root - 2019-11-04 03:34:52.528244: step 970, total loss = 0.94, predict loss = 0.21 (87.9 examples/sec; 0.046 sec/batch; 75h:50m:47s remains)
INFO - root - 2019-11-04 03:34:53.086088: step 980, total loss = 0.96, predict loss = 0.23 (92.5 examples/sec; 0.043 sec/batch; 72h:01m:52s remains)
INFO - root - 2019-11-04 03:34:53.598308: step 990, total loss = 0.81, predict loss = 0.20 (99.2 examples/sec; 0.040 sec/batch; 67h:12m:43s remains)
INFO - root - 2019-11-04 03:34:54.087436: step 1000, total loss = 0.88, predict loss = 0.21 (98.8 examples/sec; 0.040 sec/batch; 67h:26m:48s remains)
INFO - root - 2019-11-04 03:34:54.578193: step 1010, total loss = 0.68, predict loss = 0.16 (85.2 examples/sec; 0.047 sec/batch; 78h:13m:21s remains)
INFO - root - 2019-11-04 03:34:55.083915: step 1020, total loss = 0.79, predict loss = 0.19 (87.9 examples/sec; 0.046 sec/batch; 75h:50m:29s remains)
INFO - root - 2019-11-04 03:34:55.604789: step 1030, total loss = 0.83, predict loss = 0.15 (82.2 examples/sec; 0.049 sec/batch; 81h:08m:00s remains)
INFO - root - 2019-11-04 03:34:56.113925: step 1040, total loss = 1.04, predict loss = 0.19 (88.3 examples/sec; 0.045 sec/batch; 75h:26m:54s remains)
INFO - root - 2019-11-04 03:34:56.602815: step 1050, total loss = 0.84, predict loss = 0.22 (90.3 examples/sec; 0.044 sec/batch; 73h:50m:46s remains)
INFO - root - 2019-11-04 03:34:57.096397: step 1060, total loss = 0.49, predict loss = 0.09 (93.6 examples/sec; 0.043 sec/batch; 71h:10m:59s remains)
INFO - root - 2019-11-04 03:34:57.586246: step 1070, total loss = 1.19, predict loss = 0.23 (92.4 examples/sec; 0.043 sec/batch; 72h:07m:48s remains)
INFO - root - 2019-11-04 03:34:58.092096: step 1080, total loss = 0.79, predict loss = 0.15 (87.1 examples/sec; 0.046 sec/batch; 76h:31m:28s remains)
INFO - root - 2019-11-04 03:34:58.580568: step 1090, total loss = 0.66, predict loss = 0.18 (92.4 examples/sec; 0.043 sec/batch; 72h:09m:29s remains)
INFO - root - 2019-11-04 03:34:59.080942: step 1100, total loss = 0.67, predict loss = 0.17 (86.2 examples/sec; 0.046 sec/batch; 77h:20m:53s remains)
INFO - root - 2019-11-04 03:34:59.574400: step 1110, total loss = 0.41, predict loss = 0.10 (95.2 examples/sec; 0.042 sec/batch; 70h:00m:30s remains)
INFO - root - 2019-11-04 03:35:00.072644: step 1120, total loss = 0.73, predict loss = 0.17 (92.1 examples/sec; 0.043 sec/batch; 72h:20m:00s remains)
INFO - root - 2019-11-04 03:35:00.569917: step 1130, total loss = 0.95, predict loss = 0.22 (87.5 examples/sec; 0.046 sec/batch; 76h:07m:58s remains)
INFO - root - 2019-11-04 03:35:01.063391: step 1140, total loss = 0.75, predict loss = 0.18 (86.3 examples/sec; 0.046 sec/batch; 77h:14m:37s remains)
INFO - root - 2019-11-04 03:35:01.545551: step 1150, total loss = 0.91, predict loss = 0.24 (88.4 examples/sec; 0.045 sec/batch; 75h:22m:06s remains)
INFO - root - 2019-11-04 03:35:02.060163: step 1160, total loss = 0.64, predict loss = 0.14 (82.4 examples/sec; 0.049 sec/batch; 80h:56m:16s remains)
INFO - root - 2019-11-04 03:35:02.564542: step 1170, total loss = 0.70, predict loss = 0.16 (91.0 examples/sec; 0.044 sec/batch; 73h:16m:24s remains)
INFO - root - 2019-11-04 03:35:03.078998: step 1180, total loss = 0.63, predict loss = 0.14 (80.6 examples/sec; 0.050 sec/batch; 82h:44m:12s remains)
INFO - root - 2019-11-04 03:35:03.565562: step 1190, total loss = 0.83, predict loss = 0.23 (90.3 examples/sec; 0.044 sec/batch; 73h:50m:23s remains)
INFO - root - 2019-11-04 03:35:04.062923: step 1200, total loss = 0.76, predict loss = 0.26 (87.3 examples/sec; 0.046 sec/batch; 76h:22m:10s remains)
INFO - root - 2019-11-04 03:35:04.560981: step 1210, total loss = 0.64, predict loss = 0.15 (90.6 examples/sec; 0.044 sec/batch; 73h:34m:05s remains)
INFO - root - 2019-11-04 03:35:05.063464: step 1220, total loss = 0.63, predict loss = 0.18 (86.4 examples/sec; 0.046 sec/batch; 77h:06m:44s remains)
INFO - root - 2019-11-04 03:35:05.563597: step 1230, total loss = 1.53, predict loss = 0.39 (89.5 examples/sec; 0.045 sec/batch; 74h:28m:32s remains)
INFO - root - 2019-11-04 03:35:06.050568: step 1240, total loss = 0.69, predict loss = 0.16 (88.6 examples/sec; 0.045 sec/batch; 75h:13m:49s remains)
INFO - root - 2019-11-04 03:35:06.545404: step 1250, total loss = 0.89, predict loss = 0.24 (88.3 examples/sec; 0.045 sec/batch; 75h:28m:19s remains)
INFO - root - 2019-11-04 03:35:07.041717: step 1260, total loss = 0.79, predict loss = 0.17 (94.8 examples/sec; 0.042 sec/batch; 70h:16m:47s remains)
INFO - root - 2019-11-04 03:35:07.541572: step 1270, total loss = 0.98, predict loss = 0.25 (89.6 examples/sec; 0.045 sec/batch; 74h:24m:15s remains)
INFO - root - 2019-11-04 03:35:08.036337: step 1280, total loss = 0.74, predict loss = 0.15 (86.8 examples/sec; 0.046 sec/batch; 76h:45m:11s remains)
INFO - root - 2019-11-04 03:35:08.535333: step 1290, total loss = 0.66, predict loss = 0.15 (85.6 examples/sec; 0.047 sec/batch; 77h:51m:34s remains)
INFO - root - 2019-11-04 03:35:09.023817: step 1300, total loss = 0.68, predict loss = 0.14 (89.9 examples/sec; 0.045 sec/batch; 74h:10m:30s remains)
INFO - root - 2019-11-04 03:35:09.530025: step 1310, total loss = 0.69, predict loss = 0.13 (87.2 examples/sec; 0.046 sec/batch; 76h:27m:00s remains)
INFO - root - 2019-11-04 03:35:10.029376: step 1320, total loss = 1.28, predict loss = 0.36 (89.2 examples/sec; 0.045 sec/batch; 74h:44m:07s remains)
INFO - root - 2019-11-04 03:35:10.529242: step 1330, total loss = 0.39, predict loss = 0.10 (87.2 examples/sec; 0.046 sec/batch; 76h:25m:55s remains)
INFO - root - 2019-11-04 03:35:11.015453: step 1340, total loss = 0.44, predict loss = 0.11 (89.6 examples/sec; 0.045 sec/batch; 74h:22m:53s remains)
INFO - root - 2019-11-04 03:35:11.512246: step 1350, total loss = 0.30, predict loss = 0.07 (90.8 examples/sec; 0.044 sec/batch; 73h:23m:14s remains)
INFO - root - 2019-11-04 03:35:11.993375: step 1360, total loss = 0.38, predict loss = 0.11 (93.4 examples/sec; 0.043 sec/batch; 71h:21m:45s remains)
INFO - root - 2019-11-04 03:35:12.496112: step 1370, total loss = 1.23, predict loss = 0.40 (89.3 examples/sec; 0.045 sec/batch; 74h:37m:55s remains)
INFO - root - 2019-11-04 03:35:12.989658: step 1380, total loss = 1.00, predict loss = 0.28 (87.6 examples/sec; 0.046 sec/batch; 76h:04m:55s remains)
INFO - root - 2019-11-04 03:35:13.483876: step 1390, total loss = 0.50, predict loss = 0.11 (90.2 examples/sec; 0.044 sec/batch; 73h:52m:27s remains)
INFO - root - 2019-11-04 03:35:13.966120: step 1400, total loss = 0.73, predict loss = 0.18 (87.4 examples/sec; 0.046 sec/batch; 76h:17m:51s remains)
INFO - root - 2019-11-04 03:35:14.459383: step 1410, total loss = 0.48, predict loss = 0.12 (88.2 examples/sec; 0.045 sec/batch; 75h:33m:49s remains)
INFO - root - 2019-11-04 03:35:14.955160: step 1420, total loss = 0.76, predict loss = 0.21 (88.3 examples/sec; 0.045 sec/batch; 75h:30m:42s remains)
INFO - root - 2019-11-04 03:35:15.449073: step 1430, total loss = 1.20, predict loss = 0.33 (88.4 examples/sec; 0.045 sec/batch; 75h:22m:54s remains)
INFO - root - 2019-11-04 03:35:15.943634: step 1440, total loss = 0.88, predict loss = 0.23 (88.3 examples/sec; 0.045 sec/batch; 75h:27m:03s remains)
INFO - root - 2019-11-04 03:35:16.443810: step 1450, total loss = 1.00, predict loss = 0.24 (90.1 examples/sec; 0.044 sec/batch; 73h:58m:49s remains)
INFO - root - 2019-11-04 03:35:16.950881: step 1460, total loss = 1.01, predict loss = 0.24 (85.3 examples/sec; 0.047 sec/batch; 78h:06m:05s remains)
INFO - root - 2019-11-04 03:35:17.543567: step 1470, total loss = 0.98, predict loss = 0.26 (52.4 examples/sec; 0.076 sec/batch; 127h:17m:40s remains)
INFO - root - 2019-11-04 03:35:18.127386: step 1480, total loss = 0.84, predict loss = 0.22 (75.8 examples/sec; 0.053 sec/batch; 87h:52m:43s remains)
INFO - root - 2019-11-04 03:35:18.641953: step 1490, total loss = 1.21, predict loss = 0.34 (84.6 examples/sec; 0.047 sec/batch; 78h:47m:30s remains)
INFO - root - 2019-11-04 03:35:19.234375: step 1500, total loss = 1.36, predict loss = 0.34 (75.7 examples/sec; 0.053 sec/batch; 88h:02m:09s remains)
INFO - root - 2019-11-04 03:35:19.859956: step 1510, total loss = 0.80, predict loss = 0.18 (68.8 examples/sec; 0.058 sec/batch; 96h:48m:40s remains)
INFO - root - 2019-11-04 03:35:20.485472: step 1520, total loss = 1.13, predict loss = 0.28 (67.6 examples/sec; 0.059 sec/batch; 98h:36m:44s remains)
INFO - root - 2019-11-04 03:35:21.111257: step 1530, total loss = 0.90, predict loss = 0.24 (77.7 examples/sec; 0.051 sec/batch; 85h:43m:52s remains)
INFO - root - 2019-11-04 03:35:21.623598: step 1540, total loss = 1.01, predict loss = 0.26 (92.1 examples/sec; 0.043 sec/batch; 72h:22m:03s remains)
INFO - root - 2019-11-04 03:35:22.145410: step 1550, total loss = 1.05, predict loss = 0.25 (88.1 examples/sec; 0.045 sec/batch; 75h:39m:59s remains)
INFO - root - 2019-11-04 03:35:22.659753: step 1560, total loss = 1.12, predict loss = 0.33 (91.9 examples/sec; 0.044 sec/batch; 72h:29m:30s remains)
INFO - root - 2019-11-04 03:35:23.149524: step 1570, total loss = 0.65, predict loss = 0.16 (89.2 examples/sec; 0.045 sec/batch; 74h:43m:01s remains)
INFO - root - 2019-11-04 03:35:23.657906: step 1580, total loss = 0.58, predict loss = 0.15 (88.3 examples/sec; 0.045 sec/batch; 75h:28m:22s remains)
INFO - root - 2019-11-04 03:35:24.158431: step 1590, total loss = 0.67, predict loss = 0.19 (89.0 examples/sec; 0.045 sec/batch; 74h:50m:55s remains)
INFO - root - 2019-11-04 03:35:24.654543: step 1600, total loss = 0.55, predict loss = 0.14 (98.2 examples/sec; 0.041 sec/batch; 67h:50m:53s remains)
INFO - root - 2019-11-04 03:35:25.148455: step 1610, total loss = 0.70, predict loss = 0.17 (85.7 examples/sec; 0.047 sec/batch; 77h:44m:44s remains)
INFO - root - 2019-11-04 03:35:25.645667: step 1620, total loss = 0.83, predict loss = 0.20 (88.6 examples/sec; 0.045 sec/batch; 75h:15m:12s remains)
INFO - root - 2019-11-04 03:35:26.124180: step 1630, total loss = 0.74, predict loss = 0.17 (91.8 examples/sec; 0.044 sec/batch; 72h:38m:23s remains)
INFO - root - 2019-11-04 03:35:26.627084: step 1640, total loss = 0.83, predict loss = 0.17 (83.6 examples/sec; 0.048 sec/batch; 79h:45m:20s remains)
INFO - root - 2019-11-04 03:35:27.114111: step 1650, total loss = 1.18, predict loss = 0.30 (91.5 examples/sec; 0.044 sec/batch; 72h:52m:19s remains)
INFO - root - 2019-11-04 03:35:27.610749: step 1660, total loss = 1.14, predict loss = 0.32 (88.6 examples/sec; 0.045 sec/batch; 75h:15m:42s remains)
INFO - root - 2019-11-04 03:35:28.100250: step 1670, total loss = 0.75, predict loss = 0.17 (94.4 examples/sec; 0.042 sec/batch; 70h:34m:15s remains)
INFO - root - 2019-11-04 03:35:28.603627: step 1680, total loss = 0.83, predict loss = 0.22 (93.5 examples/sec; 0.043 sec/batch; 71h:15m:00s remains)
INFO - root - 2019-11-04 03:35:29.096847: step 1690, total loss = 0.83, predict loss = 0.21 (91.9 examples/sec; 0.044 sec/batch; 72h:33m:33s remains)
INFO - root - 2019-11-04 03:35:29.607948: step 1700, total loss = 0.81, predict loss = 0.19 (81.7 examples/sec; 0.049 sec/batch; 81h:34m:10s remains)
INFO - root - 2019-11-04 03:35:30.096083: step 1710, total loss = 0.98, predict loss = 0.26 (88.3 examples/sec; 0.045 sec/batch; 75h:29m:56s remains)
INFO - root - 2019-11-04 03:35:30.619311: step 1720, total loss = 0.72, predict loss = 0.19 (76.4 examples/sec; 0.052 sec/batch; 87h:12m:12s remains)
INFO - root - 2019-11-04 03:35:31.245594: step 1730, total loss = 0.73, predict loss = 0.16 (87.2 examples/sec; 0.046 sec/batch; 76h:26m:15s remains)
INFO - root - 2019-11-04 03:35:31.757780: step 1740, total loss = 0.79, predict loss = 0.23 (86.0 examples/sec; 0.047 sec/batch; 77h:31m:06s remains)
INFO - root - 2019-11-04 03:35:32.299790: step 1750, total loss = 0.72, predict loss = 0.18 (73.3 examples/sec; 0.055 sec/batch; 90h:58m:41s remains)
INFO - root - 2019-11-04 03:35:32.882478: step 1760, total loss = 0.70, predict loss = 0.19 (84.7 examples/sec; 0.047 sec/batch; 78h:42m:51s remains)
INFO - root - 2019-11-04 03:35:33.391508: step 1770, total loss = 0.56, predict loss = 0.14 (84.0 examples/sec; 0.048 sec/batch; 79h:21m:34s remains)
INFO - root - 2019-11-04 03:35:33.912055: step 1780, total loss = 0.66, predict loss = 0.19 (85.2 examples/sec; 0.047 sec/batch; 78h:15m:12s remains)
INFO - root - 2019-11-04 03:35:34.418693: step 1790, total loss = 0.55, predict loss = 0.14 (82.8 examples/sec; 0.048 sec/batch; 80h:30m:53s remains)
INFO - root - 2019-11-04 03:35:34.989372: step 1800, total loss = 0.60, predict loss = 0.14 (87.3 examples/sec; 0.046 sec/batch; 76h:20m:43s remains)
INFO - root - 2019-11-04 03:35:35.498328: step 1810, total loss = 0.91, predict loss = 0.24 (83.4 examples/sec; 0.048 sec/batch; 79h:57m:15s remains)
INFO - root - 2019-11-04 03:35:36.048027: step 1820, total loss = 0.60, predict loss = 0.14 (87.6 examples/sec; 0.046 sec/batch; 76h:06m:21s remains)
INFO - root - 2019-11-04 03:35:36.575550: step 1830, total loss = 0.74, predict loss = 0.21 (85.9 examples/sec; 0.047 sec/batch; 77h:35m:10s remains)
INFO - root - 2019-11-04 03:35:37.105642: step 1840, total loss = 0.73, predict loss = 0.18 (88.6 examples/sec; 0.045 sec/batch; 75h:12m:31s remains)
INFO - root - 2019-11-04 03:35:37.628322: step 1850, total loss = 0.65, predict loss = 0.18 (85.3 examples/sec; 0.047 sec/batch; 78h:06m:47s remains)
INFO - root - 2019-11-04 03:35:38.177660: step 1860, total loss = 1.01, predict loss = 0.27 (71.6 examples/sec; 0.056 sec/batch; 93h:01m:21s remains)
INFO - root - 2019-11-04 03:35:38.703609: step 1870, total loss = 0.77, predict loss = 0.19 (87.7 examples/sec; 0.046 sec/batch; 75h:59m:14s remains)
INFO - root - 2019-11-04 03:35:39.191796: step 1880, total loss = 0.66, predict loss = 0.17 (93.6 examples/sec; 0.043 sec/batch; 71h:12m:53s remains)
INFO - root - 2019-11-04 03:35:39.689450: step 1890, total loss = 0.79, predict loss = 0.19 (91.3 examples/sec; 0.044 sec/batch; 73h:01m:23s remains)
INFO - root - 2019-11-04 03:35:40.187317: step 1900, total loss = 0.84, predict loss = 0.25 (84.9 examples/sec; 0.047 sec/batch; 78h:32m:32s remains)
INFO - root - 2019-11-04 03:35:40.685449: step 1910, total loss = 0.93, predict loss = 0.22 (89.2 examples/sec; 0.045 sec/batch; 74h:41m:49s remains)
INFO - root - 2019-11-04 03:35:41.172858: step 1920, total loss = 1.09, predict loss = 0.30 (88.9 examples/sec; 0.045 sec/batch; 74h:56m:13s remains)
INFO - root - 2019-11-04 03:35:41.665925: step 1930, total loss = 1.00, predict loss = 0.24 (89.5 examples/sec; 0.045 sec/batch; 74h:29m:18s remains)
INFO - root - 2019-11-04 03:35:42.159598: step 1940, total loss = 0.78, predict loss = 0.18 (87.0 examples/sec; 0.046 sec/batch; 76h:37m:45s remains)
INFO - root - 2019-11-04 03:35:42.698440: step 1950, total loss = 0.78, predict loss = 0.18 (75.3 examples/sec; 0.053 sec/batch; 88h:28m:15s remains)
INFO - root - 2019-11-04 03:35:43.199516: step 1960, total loss = 1.16, predict loss = 0.30 (87.0 examples/sec; 0.046 sec/batch; 76h:37m:05s remains)
INFO - root - 2019-11-04 03:35:43.704937: step 1970, total loss = 0.68, predict loss = 0.17 (80.4 examples/sec; 0.050 sec/batch; 82h:50m:25s remains)
INFO - root - 2019-11-04 03:35:44.207052: step 1980, total loss = 0.89, predict loss = 0.21 (90.1 examples/sec; 0.044 sec/batch; 73h:59m:49s remains)
INFO - root - 2019-11-04 03:35:44.697447: step 1990, total loss = 0.71, predict loss = 0.17 (94.1 examples/sec; 0.043 sec/batch; 70h:49m:29s remains)
INFO - root - 2019-11-04 03:35:45.230590: step 2000, total loss = 0.74, predict loss = 0.20 (83.4 examples/sec; 0.048 sec/batch; 79h:54m:34s remains)
INFO - root - 2019-11-04 03:35:45.798572: step 2010, total loss = 0.68, predict loss = 0.16 (85.7 examples/sec; 0.047 sec/batch; 77h:46m:26s remains)
INFO - root - 2019-11-04 03:35:46.320979: step 2020, total loss = 0.77, predict loss = 0.20 (81.8 examples/sec; 0.049 sec/batch; 81h:30m:57s remains)
INFO - root - 2019-11-04 03:35:46.840726: step 2030, total loss = 0.95, predict loss = 0.26 (84.0 examples/sec; 0.048 sec/batch; 79h:21m:23s remains)
INFO - root - 2019-11-04 03:35:47.334407: step 2040, total loss = 0.90, predict loss = 0.25 (84.7 examples/sec; 0.047 sec/batch; 78h:42m:53s remains)
INFO - root - 2019-11-04 03:35:47.868856: step 2050, total loss = 0.83, predict loss = 0.22 (84.3 examples/sec; 0.047 sec/batch; 79h:00m:51s remains)
INFO - root - 2019-11-04 03:35:48.366723: step 2060, total loss = 1.01, predict loss = 0.26 (86.1 examples/sec; 0.046 sec/batch; 77h:22m:13s remains)
INFO - root - 2019-11-04 03:35:48.930686: step 2070, total loss = 0.82, predict loss = 0.20 (75.3 examples/sec; 0.053 sec/batch; 88h:31m:36s remains)
INFO - root - 2019-11-04 03:35:49.430805: step 2080, total loss = 0.62, predict loss = 0.14 (83.0 examples/sec; 0.048 sec/batch; 80h:19m:34s remains)
INFO - root - 2019-11-04 03:35:49.943899: step 2090, total loss = 0.93, predict loss = 0.21 (87.0 examples/sec; 0.046 sec/batch; 76h:38m:38s remains)
INFO - root - 2019-11-04 03:35:50.491766: step 2100, total loss = 0.77, predict loss = 0.18 (72.1 examples/sec; 0.055 sec/batch; 92h:26m:12s remains)
INFO - root - 2019-11-04 03:35:51.051366: step 2110, total loss = 0.69, predict loss = 0.16 (87.2 examples/sec; 0.046 sec/batch; 76h:23m:20s remains)
INFO - root - 2019-11-04 03:35:51.566063: step 2120, total loss = 0.66, predict loss = 0.18 (80.4 examples/sec; 0.050 sec/batch; 82h:51m:39s remains)
INFO - root - 2019-11-04 03:35:52.122485: step 2130, total loss = 0.90, predict loss = 0.25 (76.4 examples/sec; 0.052 sec/batch; 87h:17m:03s remains)
INFO - root - 2019-11-04 03:35:52.670145: step 2140, total loss = 0.57, predict loss = 0.14 (81.7 examples/sec; 0.049 sec/batch; 81h:35m:46s remains)
INFO - root - 2019-11-04 03:35:53.217542: step 2150, total loss = 0.68, predict loss = 0.18 (83.5 examples/sec; 0.048 sec/batch; 79h:46m:38s remains)
INFO - root - 2019-11-04 03:35:53.775889: step 2160, total loss = 0.75, predict loss = 0.20 (73.7 examples/sec; 0.054 sec/batch; 90h:28m:20s remains)
INFO - root - 2019-11-04 03:35:54.372280: step 2170, total loss = 0.56, predict loss = 0.12 (81.0 examples/sec; 0.049 sec/batch; 82h:15m:40s remains)
INFO - root - 2019-11-04 03:35:54.873198: step 2180, total loss = 0.75, predict loss = 0.20 (93.8 examples/sec; 0.043 sec/batch; 71h:04m:06s remains)
INFO - root - 2019-11-04 03:35:55.365351: step 2190, total loss = 0.73, predict loss = 0.16 (88.5 examples/sec; 0.045 sec/batch; 75h:19m:53s remains)
INFO - root - 2019-11-04 03:35:55.914753: step 2200, total loss = 0.68, predict loss = 0.16 (73.8 examples/sec; 0.054 sec/batch; 90h:16m:56s remains)
INFO - root - 2019-11-04 03:35:56.489832: step 2210, total loss = 0.58, predict loss = 0.15 (86.2 examples/sec; 0.046 sec/batch; 77h:18m:29s remains)
INFO - root - 2019-11-04 03:35:57.004085: step 2220, total loss = 0.81, predict loss = 0.20 (86.8 examples/sec; 0.046 sec/batch; 76h:48m:41s remains)
INFO - root - 2019-11-04 03:35:57.492674: step 2230, total loss = 0.55, predict loss = 0.14 (87.9 examples/sec; 0.045 sec/batch; 75h:48m:08s remains)
INFO - root - 2019-11-04 03:35:58.009220: step 2240, total loss = 0.68, predict loss = 0.16 (81.5 examples/sec; 0.049 sec/batch; 81h:49m:03s remains)
INFO - root - 2019-11-04 03:35:58.507018: step 2250, total loss = 0.80, predict loss = 0.19 (83.1 examples/sec; 0.048 sec/batch; 80h:10m:27s remains)
INFO - root - 2019-11-04 03:35:59.011305: step 2260, total loss = 0.71, predict loss = 0.16 (85.5 examples/sec; 0.047 sec/batch; 77h:58m:07s remains)
INFO - root - 2019-11-04 03:35:59.515988: step 2270, total loss = 0.56, predict loss = 0.14 (84.3 examples/sec; 0.047 sec/batch; 79h:04m:57s remains)
INFO - root - 2019-11-04 03:36:00.099852: step 2280, total loss = 0.79, predict loss = 0.18 (77.1 examples/sec; 0.052 sec/batch; 86h:24m:50s remains)
INFO - root - 2019-11-04 03:36:00.716358: step 2290, total loss = 0.70, predict loss = 0.14 (74.6 examples/sec; 0.054 sec/batch; 89h:23m:20s remains)
INFO - root - 2019-11-04 03:36:01.361803: step 2300, total loss = 0.64, predict loss = 0.15 (66.3 examples/sec; 0.060 sec/batch; 100h:35m:00s remains)
INFO - root - 2019-11-04 03:36:02.041656: step 2310, total loss = 0.71, predict loss = 0.16 (66.6 examples/sec; 0.060 sec/batch; 100h:05m:14s remains)
INFO - root - 2019-11-04 03:36:02.601181: step 2320, total loss = 0.72, predict loss = 0.17 (87.5 examples/sec; 0.046 sec/batch; 76h:09m:45s remains)
INFO - root - 2019-11-04 03:36:03.093800: step 2330, total loss = 0.79, predict loss = 0.19 (95.1 examples/sec; 0.042 sec/batch; 70h:02m:31s remains)
INFO - root - 2019-11-04 03:36:03.582263: step 2340, total loss = 0.66, predict loss = 0.14 (92.8 examples/sec; 0.043 sec/batch; 71h:50m:19s remains)
INFO - root - 2019-11-04 03:36:04.067301: step 2350, total loss = 0.80, predict loss = 0.17 (92.5 examples/sec; 0.043 sec/batch; 72h:00m:18s remains)
INFO - root - 2019-11-04 03:36:04.566710: step 2360, total loss = 0.69, predict loss = 0.15 (88.7 examples/sec; 0.045 sec/batch; 75h:08m:36s remains)
INFO - root - 2019-11-04 03:36:05.101825: step 2370, total loss = 0.67, predict loss = 0.16 (68.3 examples/sec; 0.059 sec/batch; 97h:33m:20s remains)
INFO - root - 2019-11-04 03:36:05.701784: step 2380, total loss = 0.79, predict loss = 0.20 (75.7 examples/sec; 0.053 sec/batch; 87h:59m:25s remains)
INFO - root - 2019-11-04 03:36:06.326644: step 2390, total loss = 0.62, predict loss = 0.15 (66.3 examples/sec; 0.060 sec/batch; 100h:32m:33s remains)
INFO - root - 2019-11-04 03:36:06.926827: step 2400, total loss = 0.84, predict loss = 0.19 (71.4 examples/sec; 0.056 sec/batch; 93h:19m:08s remains)
INFO - root - 2019-11-04 03:36:07.494796: step 2410, total loss = 0.81, predict loss = 0.21 (92.8 examples/sec; 0.043 sec/batch; 71h:47m:45s remains)
INFO - root - 2019-11-04 03:36:07.988919: step 2420, total loss = 0.59, predict loss = 0.15 (89.6 examples/sec; 0.045 sec/batch; 74h:23m:55s remains)
INFO - root - 2019-11-04 03:36:08.498827: step 2430, total loss = 0.89, predict loss = 0.23 (89.4 examples/sec; 0.045 sec/batch; 74h:32m:21s remains)
INFO - root - 2019-11-04 03:36:08.997453: step 2440, total loss = 0.93, predict loss = 0.25 (85.6 examples/sec; 0.047 sec/batch; 77h:50m:57s remains)
INFO - root - 2019-11-04 03:36:09.502438: step 2450, total loss = 0.61, predict loss = 0.13 (88.6 examples/sec; 0.045 sec/batch; 75h:13m:56s remains)
INFO - root - 2019-11-04 03:36:10.038698: step 2460, total loss = 0.54, predict loss = 0.12 (86.8 examples/sec; 0.046 sec/batch; 76h:47m:18s remains)
INFO - root - 2019-11-04 03:36:10.543999: step 2470, total loss = 0.77, predict loss = 0.18 (81.8 examples/sec; 0.049 sec/batch; 81h:29m:48s remains)
INFO - root - 2019-11-04 03:36:11.079345: step 2480, total loss = 0.81, predict loss = 0.23 (85.4 examples/sec; 0.047 sec/batch; 78h:01m:13s remains)
INFO - root - 2019-11-04 03:36:11.575646: step 2490, total loss = 0.84, predict loss = 0.20 (93.8 examples/sec; 0.043 sec/batch; 71h:02m:03s remains)
INFO - root - 2019-11-04 03:36:12.056647: step 2500, total loss = 0.91, predict loss = 0.23 (93.5 examples/sec; 0.043 sec/batch; 71h:17m:22s remains)
INFO - root - 2019-11-04 03:36:12.563679: step 2510, total loss = 0.86, predict loss = 0.22 (86.4 examples/sec; 0.046 sec/batch; 77h:10m:07s remains)
INFO - root - 2019-11-04 03:36:13.056666: step 2520, total loss = 1.12, predict loss = 0.25 (90.0 examples/sec; 0.044 sec/batch; 74h:03m:52s remains)
INFO - root - 2019-11-04 03:36:13.548090: step 2530, total loss = 0.84, predict loss = 0.22 (89.2 examples/sec; 0.045 sec/batch; 74h:42m:28s remains)
INFO - root - 2019-11-04 03:36:14.039053: step 2540, total loss = 0.99, predict loss = 0.27 (88.3 examples/sec; 0.045 sec/batch; 75h:25m:33s remains)
INFO - root - 2019-11-04 03:36:14.528404: step 2550, total loss = 1.06, predict loss = 0.20 (88.3 examples/sec; 0.045 sec/batch; 75h:30m:28s remains)
INFO - root - 2019-11-04 03:36:15.019204: step 2560, total loss = 0.91, predict loss = 0.22 (93.3 examples/sec; 0.043 sec/batch; 71h:27m:27s remains)
INFO - root - 2019-11-04 03:36:15.503269: step 2570, total loss = 0.46, predict loss = 0.11 (88.1 examples/sec; 0.045 sec/batch; 75h:35m:56s remains)
INFO - root - 2019-11-04 03:36:15.999110: step 2580, total loss = 0.63, predict loss = 0.15 (89.1 examples/sec; 0.045 sec/batch; 74h:48m:52s remains)
INFO - root - 2019-11-04 03:36:16.519716: step 2590, total loss = 0.36, predict loss = 0.09 (88.7 examples/sec; 0.045 sec/batch; 75h:09m:48s remains)
INFO - root - 2019-11-04 03:36:17.035926: step 2600, total loss = 0.86, predict loss = 0.20 (72.6 examples/sec; 0.055 sec/batch; 91h:47m:59s remains)
INFO - root - 2019-11-04 03:36:17.548466: step 2610, total loss = 0.79, predict loss = 0.19 (81.0 examples/sec; 0.049 sec/batch; 82h:16m:28s remains)
INFO - root - 2019-11-04 03:36:18.051884: step 2620, total loss = 0.66, predict loss = 0.16 (85.1 examples/sec; 0.047 sec/batch; 78h:17m:53s remains)
INFO - root - 2019-11-04 03:36:18.553779: step 2630, total loss = 0.76, predict loss = 0.19 (93.9 examples/sec; 0.043 sec/batch; 70h:58m:01s remains)
INFO - root - 2019-11-04 03:36:19.061146: step 2640, total loss = 0.64, predict loss = 0.14 (98.0 examples/sec; 0.041 sec/batch; 68h:00m:28s remains)
INFO - root - 2019-11-04 03:36:19.573948: step 2650, total loss = 0.65, predict loss = 0.18 (92.7 examples/sec; 0.043 sec/batch; 71h:53m:33s remains)
INFO - root - 2019-11-04 03:36:20.079186: step 2660, total loss = 0.52, predict loss = 0.13 (87.9 examples/sec; 0.046 sec/batch; 75h:48m:44s remains)
INFO - root - 2019-11-04 03:36:20.591832: step 2670, total loss = 0.61, predict loss = 0.16 (83.0 examples/sec; 0.048 sec/batch; 80h:19m:37s remains)
INFO - root - 2019-11-04 03:36:21.094755: step 2680, total loss = 0.53, predict loss = 0.12 (98.9 examples/sec; 0.040 sec/batch; 67h:21m:23s remains)
INFO - root - 2019-11-04 03:36:21.594831: step 2690, total loss = 0.64, predict loss = 0.15 (83.5 examples/sec; 0.048 sec/batch; 79h:48m:20s remains)
INFO - root - 2019-11-04 03:36:22.102163: step 2700, total loss = 0.60, predict loss = 0.14 (92.2 examples/sec; 0.043 sec/batch; 72h:14m:28s remains)
INFO - root - 2019-11-04 03:36:22.566202: step 2710, total loss = 0.83, predict loss = 0.17 (96.7 examples/sec; 0.041 sec/batch; 68h:53m:50s remains)
INFO - root - 2019-11-04 03:36:23.008365: step 2720, total loss = 0.90, predict loss = 0.19 (98.3 examples/sec; 0.041 sec/batch; 67h:48m:44s remains)
INFO - root - 2019-11-04 03:36:23.760734: step 2730, total loss = 0.41, predict loss = 0.08 (87.8 examples/sec; 0.046 sec/batch; 75h:55m:47s remains)
INFO - root - 2019-11-04 03:36:24.366234: step 2740, total loss = 0.34, predict loss = 0.09 (73.6 examples/sec; 0.054 sec/batch; 90h:33m:10s remains)
INFO - root - 2019-11-04 03:36:24.955255: step 2750, total loss = 1.23, predict loss = 0.21 (79.1 examples/sec; 0.051 sec/batch; 84h:14m:32s remains)
INFO - root - 2019-11-04 03:36:25.553526: step 2760, total loss = 0.65, predict loss = 0.19 (73.8 examples/sec; 0.054 sec/batch; 90h:14m:32s remains)
INFO - root - 2019-11-04 03:36:26.129105: step 2770, total loss = 0.84, predict loss = 0.19 (78.0 examples/sec; 0.051 sec/batch; 85h:27m:58s remains)
INFO - root - 2019-11-04 03:36:26.731547: step 2780, total loss = 0.88, predict loss = 0.29 (74.6 examples/sec; 0.054 sec/batch; 89h:18m:58s remains)
INFO - root - 2019-11-04 03:36:27.328401: step 2790, total loss = 0.61, predict loss = 0.15 (76.2 examples/sec; 0.053 sec/batch; 87h:28m:26s remains)
INFO - root - 2019-11-04 03:36:27.921506: step 2800, total loss = 0.63, predict loss = 0.12 (88.4 examples/sec; 0.045 sec/batch; 75h:21m:50s remains)
INFO - root - 2019-11-04 03:36:28.526129: step 2810, total loss = 1.17, predict loss = 0.38 (71.3 examples/sec; 0.056 sec/batch; 93h:25m:41s remains)
INFO - root - 2019-11-04 03:36:29.125099: step 2820, total loss = 0.68, predict loss = 0.15 (71.5 examples/sec; 0.056 sec/batch; 93h:08m:47s remains)
INFO - root - 2019-11-04 03:36:29.721563: step 2830, total loss = 0.65, predict loss = 0.14 (76.9 examples/sec; 0.052 sec/batch; 86h:39m:07s remains)
INFO - root - 2019-11-04 03:36:30.318154: step 2840, total loss = 0.55, predict loss = 0.14 (75.3 examples/sec; 0.053 sec/batch; 88h:32m:05s remains)
INFO - root - 2019-11-04 03:36:30.928801: step 2850, total loss = 0.49, predict loss = 0.11 (76.8 examples/sec; 0.052 sec/batch; 86h:43m:30s remains)
INFO - root - 2019-11-04 03:36:31.537266: step 2860, total loss = 0.68, predict loss = 0.17 (68.0 examples/sec; 0.059 sec/batch; 98h:02m:20s remains)
INFO - root - 2019-11-04 03:36:32.144465: step 2870, total loss = 0.46, predict loss = 0.11 (81.8 examples/sec; 0.049 sec/batch; 81h:28m:17s remains)
INFO - root - 2019-11-04 03:36:32.666409: step 2880, total loss = 0.52, predict loss = 0.13 (85.2 examples/sec; 0.047 sec/batch; 78h:15m:11s remains)
INFO - root - 2019-11-04 03:36:33.184139: step 2890, total loss = 0.53, predict loss = 0.13 (77.7 examples/sec; 0.051 sec/batch; 85h:46m:55s remains)
INFO - root - 2019-11-04 03:36:33.698403: step 2900, total loss = 0.58, predict loss = 0.13 (90.9 examples/sec; 0.044 sec/batch; 73h:16m:16s remains)
INFO - root - 2019-11-04 03:36:34.199497: step 2910, total loss = 0.69, predict loss = 0.17 (87.5 examples/sec; 0.046 sec/batch; 76h:11m:19s remains)
INFO - root - 2019-11-04 03:36:34.707033: step 2920, total loss = 0.44, predict loss = 0.10 (86.5 examples/sec; 0.046 sec/batch; 77h:03m:57s remains)
INFO - root - 2019-11-04 03:36:35.199133: step 2930, total loss = 0.65, predict loss = 0.19 (88.8 examples/sec; 0.045 sec/batch; 75h:01m:55s remains)
INFO - root - 2019-11-04 03:36:35.705486: step 2940, total loss = 0.39, predict loss = 0.09 (88.7 examples/sec; 0.045 sec/batch; 75h:08m:04s remains)
INFO - root - 2019-11-04 03:36:36.219900: step 2950, total loss = 0.47, predict loss = 0.11 (87.8 examples/sec; 0.046 sec/batch; 75h:53m:14s remains)
INFO - root - 2019-11-04 03:36:36.729448: step 2960, total loss = 0.39, predict loss = 0.10 (89.5 examples/sec; 0.045 sec/batch; 74h:25m:59s remains)
INFO - root - 2019-11-04 03:36:37.221719: step 2970, total loss = 0.77, predict loss = 0.17 (91.9 examples/sec; 0.044 sec/batch; 72h:31m:42s remains)
INFO - root - 2019-11-04 03:36:37.717849: step 2980, total loss = 0.54, predict loss = 0.11 (85.3 examples/sec; 0.047 sec/batch; 78h:04m:50s remains)
INFO - root - 2019-11-04 03:36:38.215568: step 2990, total loss = 0.43, predict loss = 0.10 (92.4 examples/sec; 0.043 sec/batch; 72h:07m:41s remains)
INFO - root - 2019-11-04 03:36:38.711407: step 3000, total loss = 0.50, predict loss = 0.12 (88.2 examples/sec; 0.045 sec/batch; 75h:31m:10s remains)
INFO - root - 2019-11-04 03:36:39.206880: step 3010, total loss = 0.48, predict loss = 0.11 (90.9 examples/sec; 0.044 sec/batch; 73h:19m:31s remains)
INFO - root - 2019-11-04 03:36:39.700060: step 3020, total loss = 0.62, predict loss = 0.15 (88.0 examples/sec; 0.045 sec/batch; 75h:43m:02s remains)
INFO - root - 2019-11-04 03:36:40.198480: step 3030, total loss = 0.63, predict loss = 0.15 (90.6 examples/sec; 0.044 sec/batch; 73h:33m:54s remains)
INFO - root - 2019-11-04 03:36:40.687904: step 3040, total loss = 0.70, predict loss = 0.19 (89.5 examples/sec; 0.045 sec/batch; 74h:25m:54s remains)
INFO - root - 2019-11-04 03:36:41.181114: step 3050, total loss = 0.63, predict loss = 0.15 (92.2 examples/sec; 0.043 sec/batch; 72h:17m:10s remains)
INFO - root - 2019-11-04 03:36:41.668165: step 3060, total loss = 0.63, predict loss = 0.13 (91.6 examples/sec; 0.044 sec/batch; 72h:43m:50s remains)
INFO - root - 2019-11-04 03:36:42.163932: step 3070, total loss = 0.59, predict loss = 0.12 (88.0 examples/sec; 0.045 sec/batch; 75h:44m:58s remains)
INFO - root - 2019-11-04 03:36:42.659468: step 3080, total loss = 0.50, predict loss = 0.11 (84.2 examples/sec; 0.048 sec/batch; 79h:10m:31s remains)
INFO - root - 2019-11-04 03:36:43.157539: step 3090, total loss = 0.60, predict loss = 0.14 (88.0 examples/sec; 0.045 sec/batch; 75h:42m:37s remains)
INFO - root - 2019-11-04 03:36:43.666623: step 3100, total loss = 0.66, predict loss = 0.17 (89.7 examples/sec; 0.045 sec/batch; 74h:19m:11s remains)
INFO - root - 2019-11-04 03:36:44.180612: step 3110, total loss = 0.79, predict loss = 0.16 (86.1 examples/sec; 0.046 sec/batch; 77h:20m:54s remains)
INFO - root - 2019-11-04 03:36:44.701563: step 3120, total loss = 0.56, predict loss = 0.11 (92.6 examples/sec; 0.043 sec/batch; 71h:57m:05s remains)
INFO - root - 2019-11-04 03:36:45.206362: step 3130, total loss = 0.60, predict loss = 0.13 (90.0 examples/sec; 0.044 sec/batch; 74h:02m:49s remains)
INFO - root - 2019-11-04 03:36:45.724658: step 3140, total loss = 1.22, predict loss = 0.39 (87.8 examples/sec; 0.046 sec/batch; 75h:54m:43s remains)
INFO - root - 2019-11-04 03:36:46.244938: step 3150, total loss = 1.37, predict loss = 0.50 (78.7 examples/sec; 0.051 sec/batch; 84h:38m:37s remains)
INFO - root - 2019-11-04 03:36:46.771567: step 3160, total loss = 0.96, predict loss = 0.26 (84.9 examples/sec; 0.047 sec/batch; 78h:30m:08s remains)
INFO - root - 2019-11-04 03:36:47.293042: step 3170, total loss = 0.59, predict loss = 0.13 (87.3 examples/sec; 0.046 sec/batch; 76h:17m:00s remains)
INFO - root - 2019-11-04 03:36:47.813478: step 3180, total loss = 0.63, predict loss = 0.14 (79.4 examples/sec; 0.050 sec/batch; 83h:56m:06s remains)
INFO - root - 2019-11-04 03:36:48.336851: step 3190, total loss = 0.45, predict loss = 0.11 (83.0 examples/sec; 0.048 sec/batch; 80h:15m:38s remains)
INFO - root - 2019-11-04 03:36:48.849783: step 3200, total loss = 0.44, predict loss = 0.10 (82.0 examples/sec; 0.049 sec/batch; 81h:14m:53s remains)
INFO - root - 2019-11-04 03:36:49.380988: step 3210, total loss = 0.35, predict loss = 0.08 (89.1 examples/sec; 0.045 sec/batch; 74h:45m:25s remains)
INFO - root - 2019-11-04 03:36:49.920551: step 3220, total loss = 0.58, predict loss = 0.14 (81.7 examples/sec; 0.049 sec/batch; 81h:33m:39s remains)
INFO - root - 2019-11-04 03:36:50.462148: step 3230, total loss = 0.46, predict loss = 0.10 (83.8 examples/sec; 0.048 sec/batch; 79h:31m:38s remains)
INFO - root - 2019-11-04 03:36:51.005169: step 3240, total loss = 0.50, predict loss = 0.13 (89.4 examples/sec; 0.045 sec/batch; 74h:29m:49s remains)
INFO - root - 2019-11-04 03:36:51.553817: step 3250, total loss = 0.55, predict loss = 0.12 (82.0 examples/sec; 0.049 sec/batch; 81h:13m:42s remains)
INFO - root - 2019-11-04 03:36:52.093342: step 3260, total loss = 0.49, predict loss = 0.09 (88.5 examples/sec; 0.045 sec/batch; 75h:18m:44s remains)
INFO - root - 2019-11-04 03:36:52.653926: step 3270, total loss = 0.40, predict loss = 0.08 (83.5 examples/sec; 0.048 sec/batch; 79h:50m:36s remains)
INFO - root - 2019-11-04 03:36:53.237529: step 3280, total loss = 0.51, predict loss = 0.11 (76.8 examples/sec; 0.052 sec/batch; 86h:45m:58s remains)
INFO - root - 2019-11-04 03:36:53.797827: step 3290, total loss = 0.73, predict loss = 0.18 (78.8 examples/sec; 0.051 sec/batch; 84h:31m:43s remains)
INFO - root - 2019-11-04 03:36:54.369809: step 3300, total loss = 0.46, predict loss = 0.10 (73.5 examples/sec; 0.054 sec/batch; 90h:38m:23s remains)
INFO - root - 2019-11-04 03:36:54.979913: step 3310, total loss = 0.90, predict loss = 0.24 (72.2 examples/sec; 0.055 sec/batch; 92h:13m:52s remains)
INFO - root - 2019-11-04 03:36:55.550769: step 3320, total loss = 0.57, predict loss = 0.12 (82.0 examples/sec; 0.049 sec/batch; 81h:16m:42s remains)
INFO - root - 2019-11-04 03:36:56.090867: step 3330, total loss = 0.46, predict loss = 0.11 (84.3 examples/sec; 0.047 sec/batch; 79h:00m:49s remains)
INFO - root - 2019-11-04 03:36:56.619313: step 3340, total loss = 0.51, predict loss = 0.14 (83.6 examples/sec; 0.048 sec/batch; 79h:43m:13s remains)
INFO - root - 2019-11-04 03:36:57.142155: step 3350, total loss = 0.31, predict loss = 0.07 (85.3 examples/sec; 0.047 sec/batch; 78h:08m:54s remains)
INFO - root - 2019-11-04 03:36:57.680654: step 3360, total loss = 0.38, predict loss = 0.09 (82.4 examples/sec; 0.049 sec/batch; 80h:48m:44s remains)
INFO - root - 2019-11-04 03:36:58.209735: step 3370, total loss = 0.49, predict loss = 0.10 (85.6 examples/sec; 0.047 sec/batch; 77h:51m:21s remains)
INFO - root - 2019-11-04 03:36:58.734624: step 3380, total loss = 0.63, predict loss = 0.14 (85.0 examples/sec; 0.047 sec/batch; 78h:25m:41s remains)
INFO - root - 2019-11-04 03:36:59.265029: step 3390, total loss = 0.35, predict loss = 0.06 (80.8 examples/sec; 0.050 sec/batch; 82h:28m:33s remains)
INFO - root - 2019-11-04 03:36:59.802337: step 3400, total loss = 0.40, predict loss = 0.07 (87.0 examples/sec; 0.046 sec/batch; 76h:33m:54s remains)
INFO - root - 2019-11-04 03:37:00.336593: step 3410, total loss = 0.50, predict loss = 0.10 (80.3 examples/sec; 0.050 sec/batch; 82h:58m:28s remains)
INFO - root - 2019-11-04 03:37:00.857805: step 3420, total loss = 0.44, predict loss = 0.10 (79.2 examples/sec; 0.051 sec/batch; 84h:09m:34s remains)
INFO - root - 2019-11-04 03:37:01.390373: step 3430, total loss = 0.52, predict loss = 0.11 (91.9 examples/sec; 0.044 sec/batch; 72h:31m:06s remains)
INFO - root - 2019-11-04 03:37:01.990216: step 3440, total loss = 0.52, predict loss = 0.14 (83.3 examples/sec; 0.048 sec/batch; 80h:00m:12s remains)
INFO - root - 2019-11-04 03:37:02.539167: step 3450, total loss = 0.59, predict loss = 0.13 (82.7 examples/sec; 0.048 sec/batch; 80h:34m:03s remains)
INFO - root - 2019-11-04 03:37:03.091304: step 3460, total loss = 0.62, predict loss = 0.16 (76.2 examples/sec; 0.052 sec/batch; 87h:26m:52s remains)
INFO - root - 2019-11-04 03:37:03.651480: step 3470, total loss = 0.69, predict loss = 0.18 (83.1 examples/sec; 0.048 sec/batch; 80h:09m:58s remains)
INFO - root - 2019-11-04 03:37:04.238493: step 3480, total loss = 0.60, predict loss = 0.13 (77.3 examples/sec; 0.052 sec/batch; 86h:09m:22s remains)
INFO - root - 2019-11-04 03:37:04.790905: step 3490, total loss = 0.52, predict loss = 0.13 (78.3 examples/sec; 0.051 sec/batch; 85h:04m:51s remains)
INFO - root - 2019-11-04 03:37:05.359488: step 3500, total loss = 0.62, predict loss = 0.17 (75.5 examples/sec; 0.053 sec/batch; 88h:17m:50s remains)
INFO - root - 2019-11-04 03:37:05.921328: step 3510, total loss = 0.53, predict loss = 0.13 (78.4 examples/sec; 0.051 sec/batch; 84h:56m:31s remains)
INFO - root - 2019-11-04 03:37:06.499253: step 3520, total loss = 0.37, predict loss = 0.08 (79.7 examples/sec; 0.050 sec/batch; 83h:33m:28s remains)
INFO - root - 2019-11-04 03:37:07.065008: step 3530, total loss = 0.47, predict loss = 0.10 (73.2 examples/sec; 0.055 sec/batch; 91h:00m:17s remains)
INFO - root - 2019-11-04 03:37:07.636991: step 3540, total loss = 0.90, predict loss = 0.24 (79.2 examples/sec; 0.050 sec/batch; 84h:04m:57s remains)
INFO - root - 2019-11-04 03:37:08.235561: step 3550, total loss = 0.44, predict loss = 0.11 (75.1 examples/sec; 0.053 sec/batch; 88h:40m:18s remains)
INFO - root - 2019-11-04 03:37:08.839042: step 3560, total loss = 0.43, predict loss = 0.10 (73.1 examples/sec; 0.055 sec/batch; 91h:09m:10s remains)
INFO - root - 2019-11-04 03:37:09.460250: step 3570, total loss = 0.47, predict loss = 0.09 (77.5 examples/sec; 0.052 sec/batch; 86h:01m:05s remains)
INFO - root - 2019-11-04 03:37:10.080670: step 3580, total loss = 0.32, predict loss = 0.07 (69.2 examples/sec; 0.058 sec/batch; 96h:14m:26s remains)
INFO - root - 2019-11-04 03:37:10.695363: step 3590, total loss = 0.53, predict loss = 0.12 (79.0 examples/sec; 0.051 sec/batch; 84h:18m:48s remains)
INFO - root - 2019-11-04 03:37:11.296394: step 3600, total loss = 0.36, predict loss = 0.08 (73.6 examples/sec; 0.054 sec/batch; 90h:28m:27s remains)
INFO - root - 2019-11-04 03:37:11.876410: step 3610, total loss = 0.39, predict loss = 0.09 (81.7 examples/sec; 0.049 sec/batch; 81h:34m:38s remains)
INFO - root - 2019-11-04 03:37:12.469076: step 3620, total loss = 0.31, predict loss = 0.06 (76.8 examples/sec; 0.052 sec/batch; 86h:45m:42s remains)
INFO - root - 2019-11-04 03:37:13.012616: step 3630, total loss = 0.47, predict loss = 0.08 (87.0 examples/sec; 0.046 sec/batch; 76h:35m:57s remains)
INFO - root - 2019-11-04 03:37:13.533053: step 3640, total loss = 0.89, predict loss = 0.26 (88.6 examples/sec; 0.045 sec/batch; 75h:14m:05s remains)
INFO - root - 2019-11-04 03:37:14.060945: step 3650, total loss = 0.58, predict loss = 0.15 (84.8 examples/sec; 0.047 sec/batch; 78h:32m:45s remains)
INFO - root - 2019-11-04 03:37:14.588050: step 3660, total loss = 0.48, predict loss = 0.11 (84.1 examples/sec; 0.048 sec/batch; 79h:15m:21s remains)
INFO - root - 2019-11-04 03:37:15.111837: step 3670, total loss = 0.43, predict loss = 0.10 (87.2 examples/sec; 0.046 sec/batch; 76h:24m:17s remains)
INFO - root - 2019-11-04 03:37:15.638113: step 3680, total loss = 0.40, predict loss = 0.10 (86.4 examples/sec; 0.046 sec/batch; 77h:04m:07s remains)
INFO - root - 2019-11-04 03:37:16.152579: step 3690, total loss = 0.49, predict loss = 0.11 (86.7 examples/sec; 0.046 sec/batch; 76h:48m:46s remains)
INFO - root - 2019-11-04 03:37:16.669340: step 3700, total loss = 0.49, predict loss = 0.13 (79.6 examples/sec; 0.050 sec/batch; 83h:40m:21s remains)
INFO - root - 2019-11-04 03:37:17.188829: step 3710, total loss = 0.43, predict loss = 0.09 (80.6 examples/sec; 0.050 sec/batch; 82h:36m:43s remains)
INFO - root - 2019-11-04 03:37:17.708613: step 3720, total loss = 0.45, predict loss = 0.10 (84.1 examples/sec; 0.048 sec/batch; 79h:10m:49s remains)
INFO - root - 2019-11-04 03:37:18.234305: step 3730, total loss = 0.53, predict loss = 0.12 (83.6 examples/sec; 0.048 sec/batch; 79h:43m:56s remains)
INFO - root - 2019-11-04 03:37:18.750866: step 3740, total loss = 0.55, predict loss = 0.13 (83.7 examples/sec; 0.048 sec/batch; 79h:35m:10s remains)
INFO - root - 2019-11-04 03:37:19.260918: step 3750, total loss = 0.54, predict loss = 0.10 (85.5 examples/sec; 0.047 sec/batch; 77h:52m:53s remains)
INFO - root - 2019-11-04 03:37:19.797340: step 3760, total loss = 0.57, predict loss = 0.12 (84.5 examples/sec; 0.047 sec/batch; 78h:51m:17s remains)
INFO - root - 2019-11-04 03:37:20.349875: step 3770, total loss = 0.51, predict loss = 0.11 (83.4 examples/sec; 0.048 sec/batch; 79h:51m:10s remains)
INFO - root - 2019-11-04 03:37:20.908806: step 3780, total loss = 0.46, predict loss = 0.09 (86.0 examples/sec; 0.046 sec/batch; 77h:26m:16s remains)
INFO - root - 2019-11-04 03:37:21.462932: step 3790, total loss = 0.83, predict loss = 0.28 (80.4 examples/sec; 0.050 sec/batch; 82h:53m:12s remains)
INFO - root - 2019-11-04 03:37:22.043805: step 3800, total loss = 0.62, predict loss = 0.13 (81.7 examples/sec; 0.049 sec/batch; 81h:34m:53s remains)
INFO - root - 2019-11-04 03:37:22.609088: step 3810, total loss = 0.51, predict loss = 0.15 (78.0 examples/sec; 0.051 sec/batch; 85h:24m:29s remains)
INFO - root - 2019-11-04 03:37:23.170549: step 3820, total loss = 0.45, predict loss = 0.10 (79.0 examples/sec; 0.051 sec/batch; 84h:22m:32s remains)
INFO - root - 2019-11-04 03:37:23.733303: step 3830, total loss = 0.34, predict loss = 0.07 (80.4 examples/sec; 0.050 sec/batch; 82h:49m:59s remains)
INFO - root - 2019-11-04 03:37:24.305867: step 3840, total loss = 0.68, predict loss = 0.15 (76.6 examples/sec; 0.052 sec/batch; 87h:00m:00s remains)
INFO - root - 2019-11-04 03:37:24.883709: step 3850, total loss = 0.47, predict loss = 0.09 (76.7 examples/sec; 0.052 sec/batch; 86h:52m:59s remains)
INFO - root - 2019-11-04 03:37:25.443018: step 3860, total loss = 0.51, predict loss = 0.10 (79.3 examples/sec; 0.050 sec/batch; 84h:02m:25s remains)
INFO - root - 2019-11-04 03:37:26.017301: step 3870, total loss = 0.49, predict loss = 0.09 (79.1 examples/sec; 0.051 sec/batch; 84h:14m:51s remains)
INFO - root - 2019-11-04 03:37:26.588389: step 3880, total loss = 0.66, predict loss = 0.15 (67.4 examples/sec; 0.059 sec/batch; 98h:48m:35s remains)
INFO - root - 2019-11-04 03:37:27.168714: step 3890, total loss = 0.67, predict loss = 0.15 (72.7 examples/sec; 0.055 sec/batch; 91h:34m:46s remains)
INFO - root - 2019-11-04 03:37:27.766550: step 3900, total loss = 0.73, predict loss = 0.17 (78.9 examples/sec; 0.051 sec/batch; 84h:28m:34s remains)
INFO - root - 2019-11-04 03:37:28.362896: step 3910, total loss = 0.34, predict loss = 0.08 (75.6 examples/sec; 0.053 sec/batch; 88h:05m:56s remains)
INFO - root - 2019-11-04 03:37:28.955489: step 3920, total loss = 0.64, predict loss = 0.16 (78.9 examples/sec; 0.051 sec/batch; 84h:24m:13s remains)
INFO - root - 2019-11-04 03:37:29.509674: step 3930, total loss = 0.74, predict loss = 0.16 (80.4 examples/sec; 0.050 sec/batch; 82h:52m:57s remains)
INFO - root - 2019-11-04 03:37:30.047603: step 3940, total loss = 0.38, predict loss = 0.08 (86.3 examples/sec; 0.046 sec/batch; 77h:11m:13s remains)
INFO - root - 2019-11-04 03:37:30.595827: step 3950, total loss = 0.35, predict loss = 0.07 (79.3 examples/sec; 0.050 sec/batch; 84h:00m:09s remains)
INFO - root - 2019-11-04 03:37:31.127886: step 3960, total loss = 0.47, predict loss = 0.13 (83.8 examples/sec; 0.048 sec/batch; 79h:30m:22s remains)
INFO - root - 2019-11-04 03:37:31.731877: step 3970, total loss = 0.65, predict loss = 0.14 (65.7 examples/sec; 0.061 sec/batch; 101h:19m:57s remains)
INFO - root - 2019-11-04 03:37:32.291417: step 3980, total loss = 0.44, predict loss = 0.09 (88.5 examples/sec; 0.045 sec/batch; 75h:18m:50s remains)
INFO - root - 2019-11-04 03:37:32.781994: step 3990, total loss = 0.57, predict loss = 0.11 (90.6 examples/sec; 0.044 sec/batch; 73h:32m:47s remains)
INFO - root - 2019-11-04 03:37:33.278322: step 4000, total loss = 0.85, predict loss = 0.25 (95.3 examples/sec; 0.042 sec/batch; 69h:56m:28s remains)
INFO - root - 2019-11-04 03:37:33.775041: step 4010, total loss = 0.43, predict loss = 0.08 (96.5 examples/sec; 0.041 sec/batch; 69h:02m:48s remains)
INFO - root - 2019-11-04 03:37:34.270313: step 4020, total loss = 0.57, predict loss = 0.11 (86.4 examples/sec; 0.046 sec/batch; 77h:08m:32s remains)
INFO - root - 2019-11-04 03:37:34.764737: step 4030, total loss = 0.59, predict loss = 0.13 (92.5 examples/sec; 0.043 sec/batch; 72h:02m:29s remains)
INFO - root - 2019-11-04 03:37:35.258535: step 4040, total loss = 0.58, predict loss = 0.13 (91.0 examples/sec; 0.044 sec/batch; 73h:12m:14s remains)
INFO - root - 2019-11-04 03:37:35.745063: step 4050, total loss = 0.68, predict loss = 0.14 (94.0 examples/sec; 0.043 sec/batch; 70h:52m:19s remains)
INFO - root - 2019-11-04 03:37:36.235116: step 4060, total loss = 0.32, predict loss = 0.07 (85.9 examples/sec; 0.047 sec/batch; 77h:34m:14s remains)
INFO - root - 2019-11-04 03:37:36.727972: step 4070, total loss = 0.22, predict loss = 0.05 (87.8 examples/sec; 0.046 sec/batch; 75h:54m:48s remains)
INFO - root - 2019-11-04 03:37:37.217653: step 4080, total loss = 0.20, predict loss = 0.05 (86.3 examples/sec; 0.046 sec/batch; 77h:13m:12s remains)
INFO - root - 2019-11-04 03:37:37.703013: step 4090, total loss = 0.56, predict loss = 0.12 (89.3 examples/sec; 0.045 sec/batch; 74h:34m:51s remains)
INFO - root - 2019-11-04 03:37:38.192229: step 4100, total loss = 0.80, predict loss = 0.25 (84.8 examples/sec; 0.047 sec/batch; 78h:36m:19s remains)
INFO - root - 2019-11-04 03:37:38.674017: step 4110, total loss = 0.37, predict loss = 0.08 (82.2 examples/sec; 0.049 sec/batch; 81h:03m:14s remains)
INFO - root - 2019-11-04 03:37:39.167919: step 4120, total loss = 0.36, predict loss = 0.08 (90.8 examples/sec; 0.044 sec/batch; 73h:20m:46s remains)
INFO - root - 2019-11-04 03:37:39.665865: step 4130, total loss = 0.37, predict loss = 0.08 (88.8 examples/sec; 0.045 sec/batch; 75h:00m:01s remains)
INFO - root - 2019-11-04 03:37:40.158425: step 4140, total loss = 0.65, predict loss = 0.18 (84.4 examples/sec; 0.047 sec/batch; 78h:56m:25s remains)
INFO - root - 2019-11-04 03:37:40.641833: step 4150, total loss = 0.52, predict loss = 0.12 (92.0 examples/sec; 0.043 sec/batch; 72h:23m:10s remains)
INFO - root - 2019-11-04 03:37:41.131226: step 4160, total loss = 1.03, predict loss = 0.23 (93.2 examples/sec; 0.043 sec/batch; 71h:28m:53s remains)
INFO - root - 2019-11-04 03:37:41.614602: step 4170, total loss = 1.66, predict loss = 0.43 (100.3 examples/sec; 0.040 sec/batch; 66h:23m:18s remains)
INFO - root - 2019-11-04 03:37:42.101189: step 4180, total loss = 1.06, predict loss = 0.27 (96.4 examples/sec; 0.042 sec/batch; 69h:08m:27s remains)
INFO - root - 2019-11-04 03:37:42.581298: step 4190, total loss = 0.89, predict loss = 0.22 (98.2 examples/sec; 0.041 sec/batch; 67h:48m:46s remains)
INFO - root - 2019-11-04 03:37:43.069312: step 4200, total loss = 0.95, predict loss = 0.23 (85.2 examples/sec; 0.047 sec/batch; 78h:11m:17s remains)
INFO - root - 2019-11-04 03:37:43.560509: step 4210, total loss = 0.99, predict loss = 0.28 (88.5 examples/sec; 0.045 sec/batch; 75h:19m:04s remains)
INFO - root - 2019-11-04 03:37:44.066839: step 4220, total loss = 0.80, predict loss = 0.19 (82.4 examples/sec; 0.049 sec/batch; 80h:48m:12s remains)
INFO - root - 2019-11-04 03:37:44.560146: step 4230, total loss = 0.67, predict loss = 0.15 (87.2 examples/sec; 0.046 sec/batch; 76h:21m:30s remains)
INFO - root - 2019-11-04 03:37:45.053383: step 4240, total loss = 0.73, predict loss = 0.16 (90.2 examples/sec; 0.044 sec/batch; 73h:52m:32s remains)
INFO - root - 2019-11-04 03:37:45.553332: step 4250, total loss = 0.74, predict loss = 0.20 (89.6 examples/sec; 0.045 sec/batch; 74h:21m:23s remains)
INFO - root - 2019-11-04 03:37:46.044477: step 4260, total loss = 0.76, predict loss = 0.17 (87.5 examples/sec; 0.046 sec/batch; 76h:08m:55s remains)
INFO - root - 2019-11-04 03:37:46.538806: step 4270, total loss = 1.10, predict loss = 0.26 (86.8 examples/sec; 0.046 sec/batch; 76h:44m:13s remains)
INFO - root - 2019-11-04 03:37:47.020800: step 4280, total loss = 0.79, predict loss = 0.16 (97.3 examples/sec; 0.041 sec/batch; 68h:29m:44s remains)
INFO - root - 2019-11-04 03:37:47.516522: step 4290, total loss = 0.67, predict loss = 0.16 (88.2 examples/sec; 0.045 sec/batch; 75h:31m:28s remains)
INFO - root - 2019-11-04 03:37:48.015093: step 4300, total loss = 0.72, predict loss = 0.18 (90.8 examples/sec; 0.044 sec/batch; 73h:23m:04s remains)
INFO - root - 2019-11-04 03:37:48.513063: step 4310, total loss = 0.61, predict loss = 0.14 (85.4 examples/sec; 0.047 sec/batch; 77h:59m:34s remains)
INFO - root - 2019-11-04 03:37:48.990840: step 4320, total loss = 0.62, predict loss = 0.13 (86.2 examples/sec; 0.046 sec/batch; 77h:19m:37s remains)
INFO - root - 2019-11-04 03:37:49.489566: step 4330, total loss = 0.83, predict loss = 0.18 (93.1 examples/sec; 0.043 sec/batch; 71h:33m:13s remains)
INFO - root - 2019-11-04 03:37:49.985385: step 4340, total loss = 0.50, predict loss = 0.11 (90.3 examples/sec; 0.044 sec/batch; 73h:44m:52s remains)
INFO - root - 2019-11-04 03:37:50.469163: step 4350, total loss = 0.64, predict loss = 0.15 (88.6 examples/sec; 0.045 sec/batch; 75h:11m:08s remains)
INFO - root - 2019-11-04 03:37:50.957394: step 4360, total loss = 0.69, predict loss = 0.16 (86.1 examples/sec; 0.046 sec/batch; 77h:22m:19s remains)
INFO - root - 2019-11-04 03:37:51.443461: step 4370, total loss = 0.53, predict loss = 0.13 (88.8 examples/sec; 0.045 sec/batch; 75h:00m:03s remains)
INFO - root - 2019-11-04 03:37:51.938589: step 4380, total loss = 0.83, predict loss = 0.18 (84.8 examples/sec; 0.047 sec/batch; 78h:31m:28s remains)
INFO - root - 2019-11-04 03:37:52.424138: step 4390, total loss = 0.65, predict loss = 0.15 (86.3 examples/sec; 0.046 sec/batch; 77h:14m:13s remains)
INFO - root - 2019-11-04 03:37:52.908277: step 4400, total loss = 0.73, predict loss = 0.18 (86.0 examples/sec; 0.047 sec/batch; 77h:27m:03s remains)
INFO - root - 2019-11-04 03:37:53.394403: step 4410, total loss = 0.68, predict loss = 0.15 (87.7 examples/sec; 0.046 sec/batch; 75h:58m:14s remains)
INFO - root - 2019-11-04 03:37:53.875424: step 4420, total loss = 0.89, predict loss = 0.19 (89.4 examples/sec; 0.045 sec/batch; 74h:29m:24s remains)
INFO - root - 2019-11-04 03:37:54.359228: step 4430, total loss = 0.90, predict loss = 0.25 (88.8 examples/sec; 0.045 sec/batch; 75h:01m:44s remains)
INFO - root - 2019-11-04 03:37:54.846511: step 4440, total loss = 0.58, predict loss = 0.14 (90.7 examples/sec; 0.044 sec/batch; 73h:29m:01s remains)
INFO - root - 2019-11-04 03:37:55.346555: step 4450, total loss = 0.77, predict loss = 0.20 (88.1 examples/sec; 0.045 sec/batch; 75h:34m:53s remains)
INFO - root - 2019-11-04 03:37:55.834227: step 4460, total loss = 0.82, predict loss = 0.22 (85.7 examples/sec; 0.047 sec/batch; 77h:42m:18s remains)
INFO - root - 2019-11-04 03:37:56.318304: step 4470, total loss = 0.52, predict loss = 0.11 (87.9 examples/sec; 0.046 sec/batch; 75h:48m:45s remains)
INFO - root - 2019-11-04 03:37:56.806305: step 4480, total loss = 0.56, predict loss = 0.13 (89.4 examples/sec; 0.045 sec/batch; 74h:31m:19s remains)
INFO - root - 2019-11-04 03:37:57.294498: step 4490, total loss = 0.50, predict loss = 0.12 (90.6 examples/sec; 0.044 sec/batch; 73h:30m:55s remains)
INFO - root - 2019-11-04 03:37:57.787078: step 4500, total loss = 0.46, predict loss = 0.11 (86.4 examples/sec; 0.046 sec/batch; 77h:06m:21s remains)
INFO - root - 2019-11-04 03:37:58.260552: step 4510, total loss = 0.70, predict loss = 0.18 (86.9 examples/sec; 0.046 sec/batch; 76h:42m:05s remains)
INFO - root - 2019-11-04 03:37:58.747904: step 4520, total loss = 0.51, predict loss = 0.11 (90.0 examples/sec; 0.044 sec/batch; 74h:03m:09s remains)
INFO - root - 2019-11-04 03:37:59.229301: step 4530, total loss = 0.53, predict loss = 0.13 (88.6 examples/sec; 0.045 sec/batch; 75h:09m:49s remains)
INFO - root - 2019-11-04 03:37:59.862715: step 4540, total loss = 0.59, predict loss = 0.14 (88.7 examples/sec; 0.045 sec/batch; 75h:07m:16s remains)
INFO - root - 2019-11-04 03:38:00.737913: step 4550, total loss = 0.61, predict loss = 0.13 (69.8 examples/sec; 0.057 sec/batch; 95h:25m:34s remains)
INFO - root - 2019-11-04 03:38:01.317266: step 4560, total loss = 0.61, predict loss = 0.15 (74.1 examples/sec; 0.054 sec/batch; 89h:51m:21s remains)
INFO - root - 2019-11-04 03:38:01.961811: step 4570, total loss = 0.55, predict loss = 0.13 (91.6 examples/sec; 0.044 sec/batch; 72h:41m:11s remains)
INFO - root - 2019-11-04 03:38:02.489325: step 4580, total loss = 0.55, predict loss = 0.13 (80.6 examples/sec; 0.050 sec/batch; 82h:39m:00s remains)
INFO - root - 2019-11-04 03:38:03.046394: step 4590, total loss = 0.45, predict loss = 0.10 (83.0 examples/sec; 0.048 sec/batch; 80h:16m:06s remains)
INFO - root - 2019-11-04 03:38:03.646735: step 4600, total loss = 0.79, predict loss = 0.21 (74.3 examples/sec; 0.054 sec/batch; 89h:36m:00s remains)
INFO - root - 2019-11-04 03:38:04.242248: step 4610, total loss = 0.83, predict loss = 0.19 (72.2 examples/sec; 0.055 sec/batch; 92h:16m:21s remains)
INFO - root - 2019-11-04 03:38:04.821766: step 4620, total loss = 0.73, predict loss = 0.17 (77.5 examples/sec; 0.052 sec/batch; 85h:54m:25s remains)
INFO - root - 2019-11-04 03:38:05.414559: step 4630, total loss = 0.52, predict loss = 0.12 (76.7 examples/sec; 0.052 sec/batch; 86h:52m:02s remains)
INFO - root - 2019-11-04 03:38:05.998714: step 4640, total loss = 0.71, predict loss = 0.16 (76.8 examples/sec; 0.052 sec/batch; 86h:46m:27s remains)
INFO - root - 2019-11-04 03:38:06.608276: step 4650, total loss = 0.78, predict loss = 0.16 (74.0 examples/sec; 0.054 sec/batch; 90h:01m:08s remains)
INFO - root - 2019-11-04 03:38:07.195752: step 4660, total loss = 0.70, predict loss = 0.18 (77.5 examples/sec; 0.052 sec/batch; 86h:00m:35s remains)
INFO - root - 2019-11-04 03:38:07.792763: step 4670, total loss = 0.48, predict loss = 0.10 (73.5 examples/sec; 0.054 sec/batch; 90h:38m:47s remains)
INFO - root - 2019-11-04 03:38:08.392723: step 4680, total loss = 0.60, predict loss = 0.15 (70.9 examples/sec; 0.056 sec/batch; 93h:56m:15s remains)
INFO - root - 2019-11-04 03:38:08.997765: step 4690, total loss = 0.76, predict loss = 0.18 (77.9 examples/sec; 0.051 sec/batch; 85h:28m:28s remains)
INFO - root - 2019-11-04 03:38:09.595871: step 4700, total loss = 0.52, predict loss = 0.12 (78.0 examples/sec; 0.051 sec/batch; 85h:25m:12s remains)
INFO - root - 2019-11-04 03:38:10.193274: step 4710, total loss = 0.69, predict loss = 0.18 (70.7 examples/sec; 0.057 sec/batch; 94h:10m:35s remains)
INFO - root - 2019-11-04 03:38:10.799599: step 4720, total loss = 0.46, predict loss = 0.11 (73.6 examples/sec; 0.054 sec/batch; 90h:32m:42s remains)
INFO - root - 2019-11-04 03:38:11.383374: step 4730, total loss = 0.57, predict loss = 0.12 (72.8 examples/sec; 0.055 sec/batch; 91h:28m:41s remains)
INFO - root - 2019-11-04 03:38:11.998483: step 4740, total loss = 0.64, predict loss = 0.16 (72.9 examples/sec; 0.055 sec/batch; 91h:23m:22s remains)
INFO - root - 2019-11-04 03:38:12.599260: step 4750, total loss = 0.77, predict loss = 0.17 (72.2 examples/sec; 0.055 sec/batch; 92h:15m:49s remains)
INFO - root - 2019-11-04 03:38:13.198976: step 4760, total loss = 0.51, predict loss = 0.10 (74.2 examples/sec; 0.054 sec/batch; 89h:44m:23s remains)
INFO - root - 2019-11-04 03:38:13.794168: step 4770, total loss = 0.74, predict loss = 0.16 (79.3 examples/sec; 0.050 sec/batch; 83h:59m:31s remains)
INFO - root - 2019-11-04 03:38:14.392387: step 4780, total loss = 0.49, predict loss = 0.11 (74.4 examples/sec; 0.054 sec/batch; 89h:32m:57s remains)
INFO - root - 2019-11-04 03:38:14.977179: step 4790, total loss = 0.63, predict loss = 0.15 (80.8 examples/sec; 0.049 sec/batch; 82h:24m:14s remains)
INFO - root - 2019-11-04 03:38:15.545902: step 4800, total loss = 0.51, predict loss = 0.11 (75.4 examples/sec; 0.053 sec/batch; 88h:23m:49s remains)
INFO - root - 2019-11-04 03:38:16.095477: step 4810, total loss = 0.48, predict loss = 0.10 (79.3 examples/sec; 0.050 sec/batch; 83h:58m:03s remains)
INFO - root - 2019-11-04 03:38:16.659436: step 4820, total loss = 0.67, predict loss = 0.15 (81.7 examples/sec; 0.049 sec/batch; 81h:34m:41s remains)
INFO - root - 2019-11-04 03:38:17.211857: step 4830, total loss = 0.63, predict loss = 0.15 (74.0 examples/sec; 0.054 sec/batch; 90h:04m:00s remains)
INFO - root - 2019-11-04 03:38:17.797972: step 4840, total loss = 0.77, predict loss = 0.19 (74.4 examples/sec; 0.054 sec/batch; 89h:30m:28s remains)
INFO - root - 2019-11-04 03:38:18.384694: step 4850, total loss = 0.81, predict loss = 0.17 (75.1 examples/sec; 0.053 sec/batch; 88h:40m:55s remains)
INFO - root - 2019-11-04 03:38:18.963819: step 4860, total loss = 0.63, predict loss = 0.16 (75.1 examples/sec; 0.053 sec/batch; 88h:43m:51s remains)
INFO - root - 2019-11-04 03:38:19.531052: step 4870, total loss = 0.53, predict loss = 0.12 (77.1 examples/sec; 0.052 sec/batch; 86h:25m:55s remains)
INFO - root - 2019-11-04 03:38:20.115362: step 4880, total loss = 0.61, predict loss = 0.14 (74.7 examples/sec; 0.054 sec/batch; 89h:13m:34s remains)
INFO - root - 2019-11-04 03:38:20.695395: step 4890, total loss = 0.55, predict loss = 0.13 (78.9 examples/sec; 0.051 sec/batch; 84h:26m:26s remains)
INFO - root - 2019-11-04 03:38:21.276715: step 4900, total loss = 0.49, predict loss = 0.12 (77.6 examples/sec; 0.052 sec/batch; 85h:50m:18s remains)
INFO - root - 2019-11-04 03:38:21.868167: step 4910, total loss = 0.58, predict loss = 0.13 (72.8 examples/sec; 0.055 sec/batch; 91h:29m:53s remains)
INFO - root - 2019-11-04 03:38:22.445021: step 4920, total loss = 0.53, predict loss = 0.12 (77.0 examples/sec; 0.052 sec/batch; 86h:33m:54s remains)
INFO - root - 2019-11-04 03:38:23.030272: step 4930, total loss = 0.60, predict loss = 0.15 (82.1 examples/sec; 0.049 sec/batch; 81h:07m:56s remains)
INFO - root - 2019-11-04 03:38:23.605660: step 4940, total loss = 0.68, predict loss = 0.15 (74.5 examples/sec; 0.054 sec/batch; 89h:21m:34s remains)
INFO - root - 2019-11-04 03:38:24.203648: step 4950, total loss = 0.53, predict loss = 0.12 (74.3 examples/sec; 0.054 sec/batch; 89h:40m:57s remains)
INFO - root - 2019-11-04 03:38:24.776528: step 4960, total loss = 0.74, predict loss = 0.18 (78.4 examples/sec; 0.051 sec/batch; 84h:58m:27s remains)
INFO - root - 2019-11-04 03:38:25.360060: step 4970, total loss = 0.57, predict loss = 0.14 (80.2 examples/sec; 0.050 sec/batch; 83h:03m:12s remains)
INFO - root - 2019-11-04 03:38:25.943874: step 4980, total loss = 0.53, predict loss = 0.12 (77.1 examples/sec; 0.052 sec/batch; 86h:25m:58s remains)
INFO - root - 2019-11-04 03:38:26.522533: step 4990, total loss = 0.60, predict loss = 0.14 (73.8 examples/sec; 0.054 sec/batch; 90h:14m:30s remains)
INFO - root - 2019-11-04 03:38:27.121609: step 5000, total loss = 0.58, predict loss = 0.13 (68.3 examples/sec; 0.059 sec/batch; 97h:31m:33s remains)
INFO - root - 2019-11-04 03:38:27.671397: step 5010, total loss = 0.61, predict loss = 0.15 (79.1 examples/sec; 0.051 sec/batch; 84h:12m:03s remains)
INFO - root - 2019-11-04 03:38:28.213079: step 5020, total loss = 0.50, predict loss = 0.11 (87.4 examples/sec; 0.046 sec/batch; 76h:13m:35s remains)
INFO - root - 2019-11-04 03:38:28.767481: step 5030, total loss = 0.63, predict loss = 0.15 (85.7 examples/sec; 0.047 sec/batch; 77h:41m:54s remains)
INFO - root - 2019-11-04 03:38:29.347432: step 5040, total loss = 0.63, predict loss = 0.15 (80.9 examples/sec; 0.049 sec/batch; 82h:22m:47s remains)
INFO - root - 2019-11-04 03:38:29.953664: step 5050, total loss = 0.58, predict loss = 0.13 (68.3 examples/sec; 0.059 sec/batch; 97h:31m:05s remains)
INFO - root - 2019-11-04 03:38:30.523140: step 5060, total loss = 0.74, predict loss = 0.16 (75.7 examples/sec; 0.053 sec/batch; 88h:00m:34s remains)
INFO - root - 2019-11-04 03:38:31.066123: step 5070, total loss = 0.46, predict loss = 0.10 (83.3 examples/sec; 0.048 sec/batch; 79h:56m:27s remains)
INFO - root - 2019-11-04 03:38:31.581999: step 5080, total loss = 0.63, predict loss = 0.16 (88.4 examples/sec; 0.045 sec/batch; 75h:18m:59s remains)
INFO - root - 2019-11-04 03:38:32.155874: step 5090, total loss = 0.67, predict loss = 0.15 (81.0 examples/sec; 0.049 sec/batch; 82h:14m:23s remains)
INFO - root - 2019-11-04 03:38:32.705620: step 5100, total loss = 0.64, predict loss = 0.14 (84.9 examples/sec; 0.047 sec/batch; 78h:26m:05s remains)
INFO - root - 2019-11-04 03:38:33.270011: step 5110, total loss = 0.67, predict loss = 0.17 (70.2 examples/sec; 0.057 sec/batch; 94h:52m:05s remains)
INFO - root - 2019-11-04 03:38:33.928212: step 5120, total loss = 0.64, predict loss = 0.14 (71.2 examples/sec; 0.056 sec/batch; 93h:32m:22s remains)
INFO - root - 2019-11-04 03:38:34.558474: step 5130, total loss = 0.52, predict loss = 0.14 (68.4 examples/sec; 0.058 sec/batch; 97h:20m:10s remains)
INFO - root - 2019-11-04 03:38:35.192310: step 5140, total loss = 0.62, predict loss = 0.15 (69.5 examples/sec; 0.058 sec/batch; 95h:50m:11s remains)
INFO - root - 2019-11-04 03:38:35.844076: step 5150, total loss = 0.95, predict loss = 0.21 (72.9 examples/sec; 0.055 sec/batch; 91h:23m:55s remains)
INFO - root - 2019-11-04 03:38:36.479606: step 5160, total loss = 0.72, predict loss = 0.17 (68.0 examples/sec; 0.059 sec/batch; 97h:54m:20s remains)
INFO - root - 2019-11-04 03:38:37.116083: step 5170, total loss = 0.62, predict loss = 0.15 (81.9 examples/sec; 0.049 sec/batch; 81h:19m:52s remains)
INFO - root - 2019-11-04 03:38:37.726094: step 5180, total loss = 0.61, predict loss = 0.15 (78.7 examples/sec; 0.051 sec/batch; 84h:39m:50s remains)
INFO - root - 2019-11-04 03:38:38.309758: step 5190, total loss = 0.52, predict loss = 0.12 (78.8 examples/sec; 0.051 sec/batch; 84h:30m:58s remains)
INFO - root - 2019-11-04 03:38:38.897965: step 5200, total loss = 0.60, predict loss = 0.14 (79.5 examples/sec; 0.050 sec/batch; 83h:46m:26s remains)
INFO - root - 2019-11-04 03:38:39.490694: step 5210, total loss = 0.68, predict loss = 0.16 (75.0 examples/sec; 0.053 sec/batch; 88h:46m:26s remains)
INFO - root - 2019-11-04 03:38:40.095241: step 5220, total loss = 0.59, predict loss = 0.13 (76.1 examples/sec; 0.053 sec/batch; 87h:35m:06s remains)
INFO - root - 2019-11-04 03:38:40.687149: step 5230, total loss = 0.90, predict loss = 0.22 (70.7 examples/sec; 0.057 sec/batch; 94h:12m:13s remains)
INFO - root - 2019-11-04 03:38:41.279607: step 5240, total loss = 0.57, predict loss = 0.13 (77.7 examples/sec; 0.051 sec/batch; 85h:43m:53s remains)
INFO - root - 2019-11-04 03:38:41.873911: step 5250, total loss = 0.54, predict loss = 0.12 (75.6 examples/sec; 0.053 sec/batch; 88h:08m:04s remains)
INFO - root - 2019-11-04 03:38:42.461622: step 5260, total loss = 0.80, predict loss = 0.16 (74.4 examples/sec; 0.054 sec/batch; 89h:28m:28s remains)
INFO - root - 2019-11-04 03:38:43.049851: step 5270, total loss = 0.52, predict loss = 0.12 (81.4 examples/sec; 0.049 sec/batch; 81h:52m:20s remains)
INFO - root - 2019-11-04 03:38:43.628283: step 5280, total loss = 0.66, predict loss = 0.16 (75.8 examples/sec; 0.053 sec/batch; 87h:49m:56s remains)
INFO - root - 2019-11-04 03:38:44.210284: step 5290, total loss = 0.59, predict loss = 0.14 (74.9 examples/sec; 0.053 sec/batch; 88h:58m:43s remains)
INFO - root - 2019-11-04 03:38:44.798719: step 5300, total loss = 0.83, predict loss = 0.20 (77.5 examples/sec; 0.052 sec/batch; 85h:53m:59s remains)
INFO - root - 2019-11-04 03:38:45.382122: step 5310, total loss = 0.82, predict loss = 0.20 (76.6 examples/sec; 0.052 sec/batch; 86h:56m:51s remains)
INFO - root - 2019-11-04 03:38:45.963633: step 5320, total loss = 0.53, predict loss = 0.14 (75.0 examples/sec; 0.053 sec/batch; 88h:48m:44s remains)
INFO - root - 2019-11-04 03:38:46.543582: step 5330, total loss = 0.43, predict loss = 0.09 (76.0 examples/sec; 0.053 sec/batch; 87h:35m:29s remains)
INFO - root - 2019-11-04 03:38:47.125116: step 5340, total loss = 0.39, predict loss = 0.09 (75.7 examples/sec; 0.053 sec/batch; 88h:01m:45s remains)
INFO - root - 2019-11-04 03:38:47.703204: step 5350, total loss = 0.55, predict loss = 0.15 (74.1 examples/sec; 0.054 sec/batch; 89h:55m:21s remains)
INFO - root - 2019-11-04 03:38:48.295340: step 5360, total loss = 0.72, predict loss = 0.18 (78.2 examples/sec; 0.051 sec/batch; 85h:09m:07s remains)
INFO - root - 2019-11-04 03:38:48.882503: step 5370, total loss = 0.61, predict loss = 0.14 (74.7 examples/sec; 0.054 sec/batch; 89h:07m:22s remains)
INFO - root - 2019-11-04 03:38:49.475510: step 5380, total loss = 0.52, predict loss = 0.11 (73.9 examples/sec; 0.054 sec/batch; 90h:06m:24s remains)
INFO - root - 2019-11-04 03:38:50.054132: step 5390, total loss = 0.59, predict loss = 0.14 (75.5 examples/sec; 0.053 sec/batch; 88h:13m:32s remains)
INFO - root - 2019-11-04 03:38:50.629747: step 5400, total loss = 0.54, predict loss = 0.12 (72.2 examples/sec; 0.055 sec/batch; 92h:14m:43s remains)
INFO - root - 2019-11-04 03:38:51.216445: step 5410, total loss = 0.52, predict loss = 0.11 (77.2 examples/sec; 0.052 sec/batch; 86h:15m:46s remains)
INFO - root - 2019-11-04 03:38:51.791067: step 5420, total loss = 0.79, predict loss = 0.23 (81.9 examples/sec; 0.049 sec/batch; 81h:22m:34s remains)
INFO - root - 2019-11-04 03:38:52.350477: step 5430, total loss = 0.61, predict loss = 0.15 (91.2 examples/sec; 0.044 sec/batch; 72h:59m:37s remains)
INFO - root - 2019-11-04 03:38:52.805810: step 5440, total loss = 0.44, predict loss = 0.10 (97.4 examples/sec; 0.041 sec/batch; 68h:21m:09s remains)
INFO - root - 2019-11-04 03:38:53.234948: step 5450, total loss = 0.46, predict loss = 0.10 (96.4 examples/sec; 0.041 sec/batch; 69h:05m:45s remains)
INFO - root - 2019-11-04 03:38:54.018451: step 5460, total loss = 0.31, predict loss = 0.07 (68.1 examples/sec; 0.059 sec/batch; 97h:44m:27s remains)
INFO - root - 2019-11-04 03:38:54.670456: step 5470, total loss = 0.45, predict loss = 0.09 (70.8 examples/sec; 0.056 sec/batch; 94h:01m:03s remains)
INFO - root - 2019-11-04 03:38:55.284956: step 5480, total loss = 0.60, predict loss = 0.12 (70.4 examples/sec; 0.057 sec/batch; 94h:39m:13s remains)
INFO - root - 2019-11-04 03:38:55.836357: step 5490, total loss = 0.46, predict loss = 0.10 (86.5 examples/sec; 0.046 sec/batch; 76h:58m:29s remains)
INFO - root - 2019-11-04 03:38:56.350815: step 5500, total loss = 0.77, predict loss = 0.22 (86.7 examples/sec; 0.046 sec/batch; 76h:46m:51s remains)
INFO - root - 2019-11-04 03:38:56.871709: step 5510, total loss = 0.93, predict loss = 0.21 (87.3 examples/sec; 0.046 sec/batch; 76h:15m:20s remains)
INFO - root - 2019-11-04 03:38:57.392307: step 5520, total loss = 0.69, predict loss = 0.15 (81.4 examples/sec; 0.049 sec/batch; 81h:48m:35s remains)
INFO - root - 2019-11-04 03:38:57.911191: step 5530, total loss = 0.51, predict loss = 0.09 (84.3 examples/sec; 0.047 sec/batch; 79h:02m:35s remains)
INFO - root - 2019-11-04 03:38:58.426774: step 5540, total loss = 0.49, predict loss = 0.10 (82.1 examples/sec; 0.049 sec/batch; 81h:07m:16s remains)
INFO - root - 2019-11-04 03:38:58.941244: step 5550, total loss = 0.50, predict loss = 0.10 (88.1 examples/sec; 0.045 sec/batch; 75h:35m:44s remains)
INFO - root - 2019-11-04 03:38:59.454418: step 5560, total loss = 0.57, predict loss = 0.14 (83.7 examples/sec; 0.048 sec/batch; 79h:32m:04s remains)
INFO - root - 2019-11-04 03:38:59.970388: step 5570, total loss = 0.44, predict loss = 0.09 (84.6 examples/sec; 0.047 sec/batch; 78h:43m:28s remains)
INFO - root - 2019-11-04 03:39:00.501853: step 5580, total loss = 1.17, predict loss = 0.17 (86.3 examples/sec; 0.046 sec/batch; 77h:10m:44s remains)
INFO - root - 2019-11-04 03:39:01.024137: step 5590, total loss = 0.85, predict loss = 0.09 (82.9 examples/sec; 0.048 sec/batch; 80h:21m:24s remains)
INFO - root - 2019-11-04 03:39:01.545055: step 5600, total loss = 0.46, predict loss = 0.09 (86.6 examples/sec; 0.046 sec/batch; 76h:54m:32s remains)
INFO - root - 2019-11-04 03:39:02.117453: step 5610, total loss = 0.42, predict loss = 0.09 (87.7 examples/sec; 0.046 sec/batch; 75h:57m:41s remains)
INFO - root - 2019-11-04 03:39:02.610085: step 5620, total loss = 0.40, predict loss = 0.07 (89.4 examples/sec; 0.045 sec/batch; 74h:31m:45s remains)
INFO - root - 2019-11-04 03:39:03.096526: step 5630, total loss = 0.39, predict loss = 0.08 (84.9 examples/sec; 0.047 sec/batch; 78h:25m:02s remains)
INFO - root - 2019-11-04 03:39:03.600317: step 5640, total loss = 0.40, predict loss = 0.08 (86.3 examples/sec; 0.046 sec/batch; 77h:12m:41s remains)
INFO - root - 2019-11-04 03:39:04.093088: step 5650, total loss = 0.52, predict loss = 0.13 (87.4 examples/sec; 0.046 sec/batch; 76h:13m:15s remains)
INFO - root - 2019-11-04 03:39:04.588330: step 5660, total loss = 0.63, predict loss = 0.16 (87.7 examples/sec; 0.046 sec/batch; 75h:57m:21s remains)
INFO - root - 2019-11-04 03:39:05.077029: step 5670, total loss = 0.60, predict loss = 0.14 (88.9 examples/sec; 0.045 sec/batch; 74h:55m:31s remains)
INFO - root - 2019-11-04 03:39:05.570227: step 5680, total loss = 0.34, predict loss = 0.06 (93.1 examples/sec; 0.043 sec/batch; 71h:33m:35s remains)
INFO - root - 2019-11-04 03:39:06.056643: step 5690, total loss = 0.45, predict loss = 0.11 (87.7 examples/sec; 0.046 sec/batch; 75h:58m:53s remains)
INFO - root - 2019-11-04 03:39:06.564047: step 5700, total loss = 0.56, predict loss = 0.15 (85.9 examples/sec; 0.047 sec/batch; 77h:31m:19s remains)
INFO - root - 2019-11-04 03:39:07.063630: step 5710, total loss = 0.63, predict loss = 0.13 (94.4 examples/sec; 0.042 sec/batch; 70h:34m:14s remains)
INFO - root - 2019-11-04 03:39:07.561796: step 5720, total loss = 0.54, predict loss = 0.12 (89.0 examples/sec; 0.045 sec/batch; 74h:50m:51s remains)
INFO - root - 2019-11-04 03:39:08.050326: step 5730, total loss = 0.59, predict loss = 0.13 (93.1 examples/sec; 0.043 sec/batch; 71h:33m:22s remains)
INFO - root - 2019-11-04 03:39:08.567812: step 5740, total loss = 0.52, predict loss = 0.11 (85.4 examples/sec; 0.047 sec/batch; 77h:58m:23s remains)
INFO - root - 2019-11-04 03:39:09.059080: step 5750, total loss = 0.46, predict loss = 0.10 (83.3 examples/sec; 0.048 sec/batch; 79h:55m:07s remains)
INFO - root - 2019-11-04 03:39:09.566794: step 5760, total loss = 1.34, predict loss = 0.30 (86.4 examples/sec; 0.046 sec/batch; 77h:06m:18s remains)
INFO - root - 2019-11-04 03:39:10.066595: step 5770, total loss = 0.62, predict loss = 0.15 (84.7 examples/sec; 0.047 sec/batch; 78h:38m:41s remains)
INFO - root - 2019-11-04 03:39:10.581441: step 5780, total loss = 0.54, predict loss = 0.11 (89.1 examples/sec; 0.045 sec/batch; 74h:45m:58s remains)
INFO - root - 2019-11-04 03:39:11.083892: step 5790, total loss = 0.58, predict loss = 0.14 (82.5 examples/sec; 0.048 sec/batch; 80h:43m:16s remains)
INFO - root - 2019-11-04 03:39:11.611501: step 5800, total loss = 0.39, predict loss = 0.08 (84.8 examples/sec; 0.047 sec/batch; 78h:31m:50s remains)
INFO - root - 2019-11-04 03:39:12.141979: step 5810, total loss = 0.56, predict loss = 0.12 (79.2 examples/sec; 0.050 sec/batch; 84h:05m:04s remains)
INFO - root - 2019-11-04 03:39:12.667307: step 5820, total loss = 0.43, predict loss = 0.09 (94.1 examples/sec; 0.043 sec/batch; 70h:47m:44s remains)
INFO - root - 2019-11-04 03:39:13.203196: step 5830, total loss = 0.47, predict loss = 0.10 (82.1 examples/sec; 0.049 sec/batch; 81h:04m:32s remains)
INFO - root - 2019-11-04 03:39:13.746755: step 5840, total loss = 0.56, predict loss = 0.15 (86.9 examples/sec; 0.046 sec/batch; 76h:39m:31s remains)
INFO - root - 2019-11-04 03:39:14.304406: step 5850, total loss = 0.59, predict loss = 0.14 (71.8 examples/sec; 0.056 sec/batch; 92h:42m:07s remains)
INFO - root - 2019-11-04 03:39:14.917328: step 5860, total loss = 0.49, predict loss = 0.12 (78.0 examples/sec; 0.051 sec/batch; 85h:24m:43s remains)
INFO - root - 2019-11-04 03:39:15.516499: step 5870, total loss = 0.68, predict loss = 0.14 (71.1 examples/sec; 0.056 sec/batch; 93h:41m:41s remains)
INFO - root - 2019-11-04 03:39:16.103810: step 5880, total loss = 0.61, predict loss = 0.14 (76.0 examples/sec; 0.053 sec/batch; 87h:34m:40s remains)
INFO - root - 2019-11-04 03:39:16.707031: step 5890, total loss = 0.54, predict loss = 0.12 (79.3 examples/sec; 0.050 sec/batch; 83h:59m:16s remains)
INFO - root - 2019-11-04 03:39:17.297779: step 5900, total loss = 0.52, predict loss = 0.13 (71.7 examples/sec; 0.056 sec/batch; 92h:55m:04s remains)
INFO - root - 2019-11-04 03:39:17.896206: step 5910, total loss = 0.64, predict loss = 0.16 (78.1 examples/sec; 0.051 sec/batch; 85h:19m:01s remains)
INFO - root - 2019-11-04 03:39:18.482251: step 5920, total loss = 0.64, predict loss = 0.15 (71.4 examples/sec; 0.056 sec/batch; 93h:18m:07s remains)
INFO - root - 2019-11-04 03:39:19.076261: step 5930, total loss = 0.43, predict loss = 0.09 (74.6 examples/sec; 0.054 sec/batch; 89h:17m:26s remains)
INFO - root - 2019-11-04 03:39:19.665488: step 5940, total loss = 0.48, predict loss = 0.11 (78.1 examples/sec; 0.051 sec/batch; 85h:17m:11s remains)
INFO - root - 2019-11-04 03:39:20.263277: step 5950, total loss = 0.34, predict loss = 0.08 (76.4 examples/sec; 0.052 sec/batch; 87h:13m:18s remains)
INFO - root - 2019-11-04 03:39:20.886990: step 5960, total loss = 0.35, predict loss = 0.08 (68.6 examples/sec; 0.058 sec/batch; 97h:02m:25s remains)
INFO - root - 2019-11-04 03:39:21.498619: step 5970, total loss = 0.39, predict loss = 0.07 (70.4 examples/sec; 0.057 sec/batch; 94h:39m:56s remains)
INFO - root - 2019-11-04 03:39:22.079892: step 5980, total loss = 0.34, predict loss = 0.08 (79.3 examples/sec; 0.050 sec/batch; 84h:00m:45s remains)
INFO - root - 2019-11-04 03:39:22.639730: step 5990, total loss = 0.50, predict loss = 0.11 (81.6 examples/sec; 0.049 sec/batch; 81h:34m:29s remains)
INFO - root - 2019-11-04 03:39:23.191848: step 6000, total loss = 0.40, predict loss = 0.09 (86.1 examples/sec; 0.046 sec/batch; 77h:23m:15s remains)
INFO - root - 2019-11-04 03:39:23.741919: step 6010, total loss = 0.56, predict loss = 0.12 (80.6 examples/sec; 0.050 sec/batch; 82h:35m:39s remains)
INFO - root - 2019-11-04 03:39:24.299930: step 6020, total loss = 0.31, predict loss = 0.07 (83.5 examples/sec; 0.048 sec/batch; 79h:46m:50s remains)
INFO - root - 2019-11-04 03:39:24.852239: step 6030, total loss = 0.39, predict loss = 0.08 (77.3 examples/sec; 0.052 sec/batch; 86h:09m:03s remains)
INFO - root - 2019-11-04 03:39:25.383188: step 6040, total loss = 0.40, predict loss = 0.09 (82.5 examples/sec; 0.048 sec/batch; 80h:43m:34s remains)
INFO - root - 2019-11-04 03:39:25.967117: step 6050, total loss = 0.56, predict loss = 0.12 (77.5 examples/sec; 0.052 sec/batch; 85h:56m:07s remains)
INFO - root - 2019-11-04 03:39:26.540949: step 6060, total loss = 0.39, predict loss = 0.08 (77.9 examples/sec; 0.051 sec/batch; 85h:27m:00s remains)
INFO - root - 2019-11-04 03:39:27.113785: step 6070, total loss = 0.39, predict loss = 0.10 (84.9 examples/sec; 0.047 sec/batch; 78h:28m:43s remains)
INFO - root - 2019-11-04 03:39:27.690996: step 6080, total loss = 0.43, predict loss = 0.08 (77.8 examples/sec; 0.051 sec/batch; 85h:33m:29s remains)
INFO - root - 2019-11-04 03:39:28.254732: step 6090, total loss = 0.37, predict loss = 0.08 (81.4 examples/sec; 0.049 sec/batch; 81h:46m:57s remains)
INFO - root - 2019-11-04 03:39:28.825313: step 6100, total loss = 0.33, predict loss = 0.07 (75.7 examples/sec; 0.053 sec/batch; 87h:58m:39s remains)
INFO - root - 2019-11-04 03:39:29.396301: step 6110, total loss = 0.44, predict loss = 0.09 (84.5 examples/sec; 0.047 sec/batch; 78h:48m:31s remains)
INFO - root - 2019-11-04 03:39:29.974468: step 6120, total loss = 0.42, predict loss = 0.08 (76.2 examples/sec; 0.052 sec/batch; 87h:23m:13s remains)
INFO - root - 2019-11-04 03:39:30.556506: step 6130, total loss = 0.36, predict loss = 0.08 (77.4 examples/sec; 0.052 sec/batch; 86h:02m:30s remains)
INFO - root - 2019-11-04 03:39:31.140771: step 6140, total loss = 0.41, predict loss = 0.08 (80.4 examples/sec; 0.050 sec/batch; 82h:52m:49s remains)
INFO - root - 2019-11-04 03:39:31.740854: step 6150, total loss = 0.37, predict loss = 0.07 (59.6 examples/sec; 0.067 sec/batch; 111h:45m:07s remains)
INFO - root - 2019-11-04 03:39:32.349438: step 6160, total loss = 0.42, predict loss = 0.09 (78.2 examples/sec; 0.051 sec/batch; 85h:08m:58s remains)
INFO - root - 2019-11-04 03:39:32.952699: step 6170, total loss = 0.45, predict loss = 0.11 (78.4 examples/sec; 0.051 sec/batch; 84h:58m:33s remains)
INFO - root - 2019-11-04 03:39:33.556207: step 6180, total loss = 0.41, predict loss = 0.08 (80.5 examples/sec; 0.050 sec/batch; 82h:42m:52s remains)
INFO - root - 2019-11-04 03:39:34.148003: step 6190, total loss = 0.37, predict loss = 0.09 (74.5 examples/sec; 0.054 sec/batch; 89h:23m:55s remains)
INFO - root - 2019-11-04 03:39:34.738236: step 6200, total loss = 0.45, predict loss = 0.11 (76.7 examples/sec; 0.052 sec/batch; 86h:46m:33s remains)
INFO - root - 2019-11-04 03:39:35.336961: step 6210, total loss = 0.43, predict loss = 0.08 (78.7 examples/sec; 0.051 sec/batch; 84h:37m:09s remains)
INFO - root - 2019-11-04 03:39:35.925434: step 6220, total loss = 0.43, predict loss = 0.10 (73.6 examples/sec; 0.054 sec/batch; 90h:26m:49s remains)
INFO - root - 2019-11-04 03:39:36.497362: step 6230, total loss = 0.36, predict loss = 0.08 (88.2 examples/sec; 0.045 sec/batch; 75h:29m:42s remains)
INFO - root - 2019-11-04 03:39:37.092041: step 6240, total loss = 0.31, predict loss = 0.07 (72.2 examples/sec; 0.055 sec/batch; 92h:13m:46s remains)
INFO - root - 2019-11-04 03:39:37.673803: step 6250, total loss = 0.41, predict loss = 0.07 (75.0 examples/sec; 0.053 sec/batch; 88h:48m:50s remains)
INFO - root - 2019-11-04 03:39:38.275301: step 6260, total loss = 0.63, predict loss = 0.12 (72.6 examples/sec; 0.055 sec/batch; 91h:40m:51s remains)
INFO - root - 2019-11-04 03:39:38.850433: step 6270, total loss = 0.44, predict loss = 0.09 (74.7 examples/sec; 0.054 sec/batch; 89h:10m:58s remains)
INFO - root - 2019-11-04 03:39:39.417958: step 6280, total loss = 0.47, predict loss = 0.09 (81.8 examples/sec; 0.049 sec/batch; 81h:25m:26s remains)
INFO - root - 2019-11-04 03:39:40.005924: step 6290, total loss = 0.42, predict loss = 0.10 (73.3 examples/sec; 0.055 sec/batch; 90h:53m:19s remains)
INFO - root - 2019-11-04 03:39:40.591226: step 6300, total loss = 0.43, predict loss = 0.09 (74.8 examples/sec; 0.054 sec/batch; 89h:05m:02s remains)
INFO - root - 2019-11-04 03:39:41.174363: step 6310, total loss = 0.44, predict loss = 0.11 (82.5 examples/sec; 0.048 sec/batch; 80h:41m:08s remains)
INFO - root - 2019-11-04 03:39:41.760942: step 6320, total loss = 0.34, predict loss = 0.06 (74.7 examples/sec; 0.054 sec/batch; 89h:11m:53s remains)
INFO - root - 2019-11-04 03:39:42.353259: step 6330, total loss = 0.49, predict loss = 0.12 (80.4 examples/sec; 0.050 sec/batch; 82h:48m:18s remains)
INFO - root - 2019-11-04 03:39:42.934845: step 6340, total loss = 0.47, predict loss = 0.11 (76.0 examples/sec; 0.053 sec/batch; 87h:40m:10s remains)
INFO - root - 2019-11-04 03:39:43.525248: step 6350, total loss = 0.54, predict loss = 0.13 (78.0 examples/sec; 0.051 sec/batch; 85h:22m:01s remains)
INFO - root - 2019-11-04 03:39:44.103074: step 6360, total loss = 0.43, predict loss = 0.09 (80.3 examples/sec; 0.050 sec/batch; 82h:58m:11s remains)
INFO - root - 2019-11-04 03:39:44.679985: step 6370, total loss = 0.35, predict loss = 0.07 (74.9 examples/sec; 0.053 sec/batch; 88h:57m:31s remains)
INFO - root - 2019-11-04 03:39:45.266055: step 6380, total loss = 0.37, predict loss = 0.09 (78.9 examples/sec; 0.051 sec/batch; 84h:27m:03s remains)
INFO - root - 2019-11-04 03:39:45.858569: step 6390, total loss = 0.41, predict loss = 0.10 (75.6 examples/sec; 0.053 sec/batch; 88h:02m:50s remains)
INFO - root - 2019-11-04 03:39:46.446959: step 6400, total loss = 0.35, predict loss = 0.07 (81.8 examples/sec; 0.049 sec/batch; 81h:26m:20s remains)
INFO - root - 2019-11-04 03:39:47.015196: step 6410, total loss = 0.41, predict loss = 0.09 (74.0 examples/sec; 0.054 sec/batch; 90h:01m:44s remains)
INFO - root - 2019-11-04 03:39:47.595841: step 6420, total loss = 0.49, predict loss = 0.10 (78.7 examples/sec; 0.051 sec/batch; 84h:35m:04s remains)
INFO - root - 2019-11-04 03:39:48.194197: step 6430, total loss = 0.42, predict loss = 0.09 (72.5 examples/sec; 0.055 sec/batch; 91h:51m:49s remains)
INFO - root - 2019-11-04 03:39:48.794302: step 6440, total loss = 0.36, predict loss = 0.08 (73.2 examples/sec; 0.055 sec/batch; 91h:02m:11s remains)
INFO - root - 2019-11-04 03:39:49.387417: step 6450, total loss = 0.53, predict loss = 0.12 (77.2 examples/sec; 0.052 sec/batch; 86h:14m:37s remains)
INFO - root - 2019-11-04 03:39:49.978081: step 6460, total loss = 0.49, predict loss = 0.13 (78.6 examples/sec; 0.051 sec/batch; 84h:41m:52s remains)
INFO - root - 2019-11-04 03:39:50.558325: step 6470, total loss = 0.56, predict loss = 0.12 (80.1 examples/sec; 0.050 sec/batch; 83h:07m:01s remains)
INFO - root - 2019-11-04 03:39:51.138439: step 6480, total loss = 0.51, predict loss = 0.10 (73.7 examples/sec; 0.054 sec/batch; 90h:20m:18s remains)
INFO - root - 2019-11-04 03:39:51.726030: step 6490, total loss = 0.43, predict loss = 0.09 (80.6 examples/sec; 0.050 sec/batch; 82h:34m:50s remains)
INFO - root - 2019-11-04 03:39:52.318413: step 6500, total loss = 0.58, predict loss = 0.11 (76.5 examples/sec; 0.052 sec/batch; 87h:04m:25s remains)
INFO - root - 2019-11-04 03:39:52.892208: step 6510, total loss = 0.47, predict loss = 0.10 (77.0 examples/sec; 0.052 sec/batch; 86h:26m:17s remains)
INFO - root - 2019-11-04 03:39:53.472802: step 6520, total loss = 0.39, predict loss = 0.08 (82.9 examples/sec; 0.048 sec/batch; 80h:20m:53s remains)
INFO - root - 2019-11-04 03:39:54.049329: step 6530, total loss = 0.33, predict loss = 0.07 (79.8 examples/sec; 0.050 sec/batch; 83h:28m:23s remains)
INFO - root - 2019-11-04 03:39:54.631072: step 6540, total loss = 0.34, predict loss = 0.07 (77.6 examples/sec; 0.052 sec/batch; 85h:46m:06s remains)
INFO - root - 2019-11-04 03:39:55.211894: step 6550, total loss = 0.35, predict loss = 0.07 (75.0 examples/sec; 0.053 sec/batch; 88h:48m:56s remains)
INFO - root - 2019-11-04 03:39:55.789531: step 6560, total loss = 0.34, predict loss = 0.06 (75.1 examples/sec; 0.053 sec/batch; 88h:38m:43s remains)
INFO - root - 2019-11-04 03:39:56.335371: step 6570, total loss = 0.25, predict loss = 0.05 (95.1 examples/sec; 0.042 sec/batch; 70h:00m:07s remains)
INFO - root - 2019-11-04 03:39:56.863976: step 6580, total loss = 0.70, predict loss = 0.13 (83.1 examples/sec; 0.048 sec/batch; 80h:05m:46s remains)
INFO - root - 2019-11-04 03:39:57.397883: step 6590, total loss = 0.90, predict loss = 0.20 (82.6 examples/sec; 0.048 sec/batch; 80h:37m:02s remains)
INFO - root - 2019-11-04 03:39:57.937640: step 6600, total loss = 0.41, predict loss = 0.09 (83.9 examples/sec; 0.048 sec/batch; 79h:24m:50s remains)
INFO - root - 2019-11-04 03:39:58.485170: step 6610, total loss = 0.38, predict loss = 0.10 (88.2 examples/sec; 0.045 sec/batch; 75h:30m:52s remains)
INFO - root - 2019-11-04 03:39:59.019589: step 6620, total loss = 0.51, predict loss = 0.11 (83.5 examples/sec; 0.048 sec/batch; 79h:46m:58s remains)
INFO - root - 2019-11-04 03:39:59.550222: step 6630, total loss = 0.40, predict loss = 0.08 (82.4 examples/sec; 0.049 sec/batch; 80h:47m:30s remains)
INFO - root - 2019-11-04 03:40:00.090863: step 6640, total loss = 0.37, predict loss = 0.09 (77.8 examples/sec; 0.051 sec/batch; 85h:38m:08s remains)
INFO - root - 2019-11-04 03:40:00.627700: step 6650, total loss = 0.30, predict loss = 0.06 (83.5 examples/sec; 0.048 sec/batch; 79h:43m:06s remains)
INFO - root - 2019-11-04 03:40:01.177847: step 6660, total loss = 0.47, predict loss = 0.09 (82.2 examples/sec; 0.049 sec/batch; 81h:03m:37s remains)
INFO - root - 2019-11-04 03:40:01.755813: step 6670, total loss = 0.43, predict loss = 0.09 (64.5 examples/sec; 0.062 sec/batch; 103h:16m:56s remains)
INFO - root - 2019-11-04 03:40:02.331156: step 6680, total loss = 0.35, predict loss = 0.08 (75.0 examples/sec; 0.053 sec/batch; 88h:49m:24s remains)
INFO - root - 2019-11-04 03:40:02.892009: step 6690, total loss = 0.50, predict loss = 0.09 (78.0 examples/sec; 0.051 sec/batch; 85h:24m:41s remains)
INFO - root - 2019-11-04 03:40:03.484379: step 6700, total loss = 0.44, predict loss = 0.09 (70.8 examples/sec; 0.056 sec/batch; 93h:59m:43s remains)
INFO - root - 2019-11-04 03:40:04.105068: step 6710, total loss = 0.55, predict loss = 0.12 (71.5 examples/sec; 0.056 sec/batch; 93h:06m:46s remains)
INFO - root - 2019-11-04 03:40:04.750901: step 6720, total loss = 0.60, predict loss = 0.13 (73.6 examples/sec; 0.054 sec/batch; 90h:28m:32s remains)
INFO - root - 2019-11-04 03:40:05.380635: step 6730, total loss = 0.42, predict loss = 0.10 (64.5 examples/sec; 0.062 sec/batch; 103h:16m:02s remains)
INFO - root - 2019-11-04 03:40:06.020071: step 6740, total loss = 0.43, predict loss = 0.10 (73.0 examples/sec; 0.055 sec/batch; 91h:16m:52s remains)
INFO - root - 2019-11-04 03:40:06.648243: step 6750, total loss = 0.46, predict loss = 0.09 (75.2 examples/sec; 0.053 sec/batch; 88h:35m:08s remains)
INFO - root - 2019-11-04 03:40:07.300759: step 6760, total loss = 0.39, predict loss = 0.08 (70.1 examples/sec; 0.057 sec/batch; 95h:02m:02s remains)
INFO - root - 2019-11-04 03:40:07.941317: step 6770, total loss = 0.42, predict loss = 0.08 (70.2 examples/sec; 0.057 sec/batch; 94h:50m:13s remains)
INFO - root - 2019-11-04 03:40:08.596194: step 6780, total loss = 0.62, predict loss = 0.16 (74.8 examples/sec; 0.053 sec/batch; 88h:58m:59s remains)
INFO - root - 2019-11-04 03:40:09.240360: step 6790, total loss = 0.37, predict loss = 0.08 (71.9 examples/sec; 0.056 sec/batch; 92h:37m:54s remains)
INFO - root - 2019-11-04 03:40:09.847033: step 6800, total loss = 0.37, predict loss = 0.09 (72.0 examples/sec; 0.056 sec/batch; 92h:28m:52s remains)
INFO - root - 2019-11-04 03:40:10.459447: step 6810, total loss = 0.35, predict loss = 0.07 (73.3 examples/sec; 0.055 sec/batch; 90h:53m:59s remains)
INFO - root - 2019-11-04 03:40:11.060892: step 6820, total loss = 0.27, predict loss = 0.06 (80.8 examples/sec; 0.049 sec/batch; 82h:23m:46s remains)
INFO - root - 2019-11-04 03:40:11.627088: step 6830, total loss = 0.20, predict loss = 0.05 (82.6 examples/sec; 0.048 sec/batch; 80h:37m:19s remains)
INFO - root - 2019-11-04 03:40:12.181127: step 6840, total loss = 0.38, predict loss = 0.07 (82.1 examples/sec; 0.049 sec/batch; 81h:04m:37s remains)
INFO - root - 2019-11-04 03:40:12.712628: step 6850, total loss = 0.36, predict loss = 0.08 (85.7 examples/sec; 0.047 sec/batch; 77h:40m:20s remains)
INFO - root - 2019-11-04 03:40:13.248089: step 6860, total loss = 0.35, predict loss = 0.07 (84.1 examples/sec; 0.048 sec/batch; 79h:12m:55s remains)
INFO - root - 2019-11-04 03:40:13.782602: step 6870, total loss = 0.39, predict loss = 0.08 (83.0 examples/sec; 0.048 sec/batch; 80h:16m:28s remains)
INFO - root - 2019-11-04 03:40:14.328039: step 6880, total loss = 0.71, predict loss = 0.18 (79.4 examples/sec; 0.050 sec/batch; 83h:52m:47s remains)
INFO - root - 2019-11-04 03:40:14.889687: step 6890, total loss = 0.91, predict loss = 0.22 (79.2 examples/sec; 0.051 sec/batch; 84h:07m:40s remains)
INFO - root - 2019-11-04 03:40:15.448823: step 6900, total loss = 0.76, predict loss = 0.17 (80.2 examples/sec; 0.050 sec/batch; 83h:01m:15s remains)
INFO - root - 2019-11-04 03:40:16.004696: step 6910, total loss = 0.90, predict loss = 0.22 (85.6 examples/sec; 0.047 sec/batch; 77h:45m:55s remains)
INFO - root - 2019-11-04 03:40:16.560872: step 6920, total loss = 0.76, predict loss = 0.18 (77.8 examples/sec; 0.051 sec/batch; 85h:36m:44s remains)
INFO - root - 2019-11-04 03:40:17.137557: step 6930, total loss = 0.85, predict loss = 0.23 (72.1 examples/sec; 0.055 sec/batch; 92h:17m:59s remains)
INFO - root - 2019-11-04 03:40:17.754721: step 6940, total loss = 1.03, predict loss = 0.27 (70.2 examples/sec; 0.057 sec/batch; 94h:48m:55s remains)
INFO - root - 2019-11-04 03:40:18.376785: step 6950, total loss = 0.81, predict loss = 0.19 (75.7 examples/sec; 0.053 sec/batch; 87h:56m:16s remains)
INFO - root - 2019-11-04 03:40:19.003895: step 6960, total loss = 0.68, predict loss = 0.16 (76.6 examples/sec; 0.052 sec/batch; 86h:53m:10s remains)
INFO - root - 2019-11-04 03:40:19.629758: step 6970, total loss = 0.73, predict loss = 0.17 (74.7 examples/sec; 0.054 sec/batch; 89h:11m:11s remains)
INFO - root - 2019-11-04 03:40:20.257247: step 6980, total loss = 0.76, predict loss = 0.19 (68.9 examples/sec; 0.058 sec/batch; 96h:37m:44s remains)
INFO - root - 2019-11-04 03:40:20.891434: step 6990, total loss = 0.96, predict loss = 0.21 (66.2 examples/sec; 0.060 sec/batch; 100h:35m:52s remains)
INFO - root - 2019-11-04 03:40:21.501210: step 7000, total loss = 0.85, predict loss = 0.19 (83.0 examples/sec; 0.048 sec/batch; 80h:13m:16s remains)
INFO - root - 2019-11-04 03:40:22.039674: step 7010, total loss = 0.53, predict loss = 0.13 (87.2 examples/sec; 0.046 sec/batch; 76h:19m:58s remains)
INFO - root - 2019-11-04 03:40:22.535025: step 7020, total loss = 0.62, predict loss = 0.14 (85.9 examples/sec; 0.047 sec/batch; 77h:31m:54s remains)
INFO - root - 2019-11-04 03:40:23.031343: step 7030, total loss = 0.43, predict loss = 0.10 (95.7 examples/sec; 0.042 sec/batch; 69h:36m:30s remains)
INFO - root - 2019-11-04 03:40:23.529837: step 7040, total loss = 0.58, predict loss = 0.14 (89.4 examples/sec; 0.045 sec/batch; 74h:30m:36s remains)
INFO - root - 2019-11-04 03:40:24.017343: step 7050, total loss = 0.56, predict loss = 0.13 (95.2 examples/sec; 0.042 sec/batch; 69h:55m:39s remains)
INFO - root - 2019-11-04 03:40:24.520379: step 7060, total loss = 0.46, predict loss = 0.11 (85.8 examples/sec; 0.047 sec/batch; 77h:38m:25s remains)
INFO - root - 2019-11-04 03:40:25.019966: step 7070, total loss = 0.44, predict loss = 0.10 (88.4 examples/sec; 0.045 sec/batch; 75h:17m:21s remains)
INFO - root - 2019-11-04 03:40:25.516106: step 7080, total loss = 0.71, predict loss = 0.13 (94.5 examples/sec; 0.042 sec/batch; 70h:27m:06s remains)
INFO - root - 2019-11-04 03:40:26.011458: step 7090, total loss = 0.54, predict loss = 0.13 (91.0 examples/sec; 0.044 sec/batch; 73h:11m:48s remains)
INFO - root - 2019-11-04 03:40:26.504267: step 7100, total loss = 0.61, predict loss = 0.13 (92.9 examples/sec; 0.043 sec/batch; 71h:41m:47s remains)
INFO - root - 2019-11-04 03:40:27.000018: step 7110, total loss = 0.61, predict loss = 0.14 (89.6 examples/sec; 0.045 sec/batch; 74h:20m:08s remains)
INFO - root - 2019-11-04 03:40:27.488968: step 7120, total loss = 0.57, predict loss = 0.13 (95.7 examples/sec; 0.042 sec/batch; 69h:36m:23s remains)
INFO - root - 2019-11-04 03:40:27.982431: step 7130, total loss = 0.45, predict loss = 0.11 (88.1 examples/sec; 0.045 sec/batch; 75h:33m:19s remains)
INFO - root - 2019-11-04 03:40:28.474970: step 7140, total loss = 0.52, predict loss = 0.12 (91.1 examples/sec; 0.044 sec/batch; 73h:06m:29s remains)
INFO - root - 2019-11-04 03:40:28.969195: step 7150, total loss = 0.48, predict loss = 0.12 (87.9 examples/sec; 0.045 sec/batch; 75h:44m:23s remains)
INFO - root - 2019-11-04 03:40:29.469116: step 7160, total loss = 0.47, predict loss = 0.11 (91.0 examples/sec; 0.044 sec/batch; 73h:08m:21s remains)
INFO - root - 2019-11-04 03:40:29.959357: step 7170, total loss = 0.42, predict loss = 0.10 (87.0 examples/sec; 0.046 sec/batch; 76h:33m:53s remains)
INFO - root - 2019-11-04 03:40:30.445668: step 7180, total loss = 0.48, predict loss = 0.12 (87.9 examples/sec; 0.046 sec/batch; 75h:47m:17s remains)
INFO - root - 2019-11-04 03:40:30.936473: step 7190, total loss = 0.64, predict loss = 0.17 (95.3 examples/sec; 0.042 sec/batch; 69h:51m:38s remains)
INFO - root - 2019-11-04 03:40:31.440446: step 7200, total loss = 0.56, predict loss = 0.12 (89.8 examples/sec; 0.045 sec/batch; 74h:10m:36s remains)
INFO - root - 2019-11-04 03:40:31.965170: step 7210, total loss = 0.59, predict loss = 0.15 (91.2 examples/sec; 0.044 sec/batch; 73h:02m:57s remains)
INFO - root - 2019-11-04 03:40:32.457297: step 7220, total loss = 0.56, predict loss = 0.14 (93.3 examples/sec; 0.043 sec/batch; 71h:23m:15s remains)
INFO - root - 2019-11-04 03:40:32.942108: step 7230, total loss = 0.42, predict loss = 0.11 (91.8 examples/sec; 0.044 sec/batch; 72h:32m:36s remains)
INFO - root - 2019-11-04 03:40:33.423987: step 7240, total loss = 0.46, predict loss = 0.10 (87.5 examples/sec; 0.046 sec/batch; 76h:06m:42s remains)
INFO - root - 2019-11-04 03:40:33.918646: step 7250, total loss = 0.47, predict loss = 0.12 (90.5 examples/sec; 0.044 sec/batch; 73h:32m:34s remains)
INFO - root - 2019-11-04 03:40:34.404172: step 7260, total loss = 0.50, predict loss = 0.11 (99.9 examples/sec; 0.040 sec/batch; 66h:40m:03s remains)
INFO - root - 2019-11-04 03:40:34.900940: step 7270, total loss = 0.62, predict loss = 0.16 (85.9 examples/sec; 0.047 sec/batch; 77h:29m:04s remains)
INFO - root - 2019-11-04 03:40:35.398472: step 7280, total loss = 0.51, predict loss = 0.12 (87.1 examples/sec; 0.046 sec/batch; 76h:25m:03s remains)
INFO - root - 2019-11-04 03:40:35.890622: step 7290, total loss = 0.43, predict loss = 0.10 (87.7 examples/sec; 0.046 sec/batch; 75h:57m:14s remains)
INFO - root - 2019-11-04 03:40:36.382681: step 7300, total loss = 0.57, predict loss = 0.12 (93.9 examples/sec; 0.043 sec/batch; 70h:55m:54s remains)
INFO - root - 2019-11-04 03:40:36.868951: step 7310, total loss = 0.55, predict loss = 0.13 (90.9 examples/sec; 0.044 sec/batch; 73h:13m:10s remains)
INFO - root - 2019-11-04 03:40:37.366392: step 7320, total loss = 0.47, predict loss = 0.11 (91.2 examples/sec; 0.044 sec/batch; 72h:58m:51s remains)
INFO - root - 2019-11-04 03:40:37.864588: step 7330, total loss = 0.59, predict loss = 0.15 (93.4 examples/sec; 0.043 sec/batch; 71h:16m:11s remains)
INFO - root - 2019-11-04 03:40:38.370376: step 7340, total loss = 0.63, predict loss = 0.14 (87.1 examples/sec; 0.046 sec/batch; 76h:25m:23s remains)
INFO - root - 2019-11-04 03:40:38.882165: step 7350, total loss = 0.77, predict loss = 0.22 (85.9 examples/sec; 0.047 sec/batch; 77h:31m:53s remains)
INFO - root - 2019-11-04 03:40:39.385821: step 7360, total loss = 0.63, predict loss = 0.14 (90.0 examples/sec; 0.044 sec/batch; 73h:56m:34s remains)
INFO - root - 2019-11-04 03:40:39.890311: step 7370, total loss = 0.51, predict loss = 0.13 (86.2 examples/sec; 0.046 sec/batch; 77h:13m:07s remains)
INFO - root - 2019-11-04 03:40:40.403795: step 7380, total loss = 0.46, predict loss = 0.11 (88.9 examples/sec; 0.045 sec/batch; 74h:53m:05s remains)
INFO - root - 2019-11-04 03:40:40.912867: step 7390, total loss = 0.63, predict loss = 0.16 (87.1 examples/sec; 0.046 sec/batch; 76h:25m:28s remains)
INFO - root - 2019-11-04 03:40:41.409275: step 7400, total loss = 0.59, predict loss = 0.13 (86.7 examples/sec; 0.046 sec/batch; 76h:45m:53s remains)
INFO - root - 2019-11-04 03:40:41.909469: step 7410, total loss = 0.52, predict loss = 0.12 (89.9 examples/sec; 0.044 sec/batch; 74h:02m:20s remains)
INFO - root - 2019-11-04 03:40:42.399716: step 7420, total loss = 0.50, predict loss = 0.12 (97.4 examples/sec; 0.041 sec/batch; 68h:19m:43s remains)
INFO - root - 2019-11-04 03:40:42.899018: step 7430, total loss = 0.48, predict loss = 0.11 (86.2 examples/sec; 0.046 sec/batch; 77h:12m:27s remains)
INFO - root - 2019-11-04 03:40:43.389719: step 7440, total loss = 0.66, predict loss = 0.15 (91.4 examples/sec; 0.044 sec/batch; 72h:49m:56s remains)
INFO - root - 2019-11-04 03:40:43.873727: step 7450, total loss = 0.52, predict loss = 0.12 (91.7 examples/sec; 0.044 sec/batch; 72h:38m:22s remains)
INFO - root - 2019-11-04 03:40:44.372020: step 7460, total loss = 0.54, predict loss = 0.11 (90.4 examples/sec; 0.044 sec/batch; 73h:37m:07s remains)
INFO - root - 2019-11-04 03:40:44.855375: step 7470, total loss = 0.67, predict loss = 0.16 (90.7 examples/sec; 0.044 sec/batch; 73h:25m:25s remains)
INFO - root - 2019-11-04 03:40:45.358624: step 7480, total loss = 0.46, predict loss = 0.09 (88.0 examples/sec; 0.045 sec/batch; 75h:39m:32s remains)
INFO - root - 2019-11-04 03:40:45.865386: step 7490, total loss = 0.63, predict loss = 0.17 (86.8 examples/sec; 0.046 sec/batch; 76h:43m:25s remains)
INFO - root - 2019-11-04 03:40:46.358824: step 7500, total loss = 0.56, predict loss = 0.13 (91.4 examples/sec; 0.044 sec/batch; 72h:49m:30s remains)
INFO - root - 2019-11-04 03:40:46.852388: step 7510, total loss = 0.70, predict loss = 0.21 (88.0 examples/sec; 0.045 sec/batch; 75h:37m:38s remains)
INFO - root - 2019-11-04 03:40:47.351706: step 7520, total loss = 0.66, predict loss = 0.14 (89.2 examples/sec; 0.045 sec/batch; 74h:37m:00s remains)
INFO - root - 2019-11-04 03:40:47.852087: step 7530, total loss = 0.85, predict loss = 0.20 (87.8 examples/sec; 0.046 sec/batch; 75h:49m:13s remains)
INFO - root - 2019-11-04 03:40:48.363919: step 7540, total loss = 1.04, predict loss = 0.30 (92.3 examples/sec; 0.043 sec/batch; 72h:10m:13s remains)
INFO - root - 2019-11-04 03:40:48.879761: step 7550, total loss = 0.61, predict loss = 0.13 (87.9 examples/sec; 0.045 sec/batch; 75h:43m:10s remains)
INFO - root - 2019-11-04 03:40:49.387292: step 7560, total loss = 0.51, predict loss = 0.11 (82.4 examples/sec; 0.049 sec/batch; 80h:49m:39s remains)
INFO - root - 2019-11-04 03:40:49.873244: step 7570, total loss = 0.89, predict loss = 0.18 (93.8 examples/sec; 0.043 sec/batch; 71h:00m:49s remains)
INFO - root - 2019-11-04 03:40:50.375208: step 7580, total loss = 0.60, predict loss = 0.14 (88.6 examples/sec; 0.045 sec/batch; 75h:10m:53s remains)
INFO - root - 2019-11-04 03:40:50.865389: step 7590, total loss = 0.61, predict loss = 0.14 (91.1 examples/sec; 0.044 sec/batch; 73h:06m:49s remains)
INFO - root - 2019-11-04 03:40:51.360582: step 7600, total loss = 0.52, predict loss = 0.12 (92.3 examples/sec; 0.043 sec/batch; 72h:09m:06s remains)
INFO - root - 2019-11-04 03:40:51.842798: step 7610, total loss = 0.67, predict loss = 0.16 (89.7 examples/sec; 0.045 sec/batch; 74h:15m:59s remains)
INFO - root - 2019-11-04 03:40:52.335828: step 7620, total loss = 0.71, predict loss = 0.17 (90.7 examples/sec; 0.044 sec/batch; 73h:26m:35s remains)
INFO - root - 2019-11-04 03:40:52.827680: step 7630, total loss = 0.62, predict loss = 0.13 (88.2 examples/sec; 0.045 sec/batch; 75h:27m:07s remains)
INFO - root - 2019-11-04 03:40:53.331695: step 7640, total loss = 0.42, predict loss = 0.09 (87.4 examples/sec; 0.046 sec/batch; 76h:12m:18s remains)
INFO - root - 2019-11-04 03:40:53.823672: step 7650, total loss = 0.68, predict loss = 0.16 (91.5 examples/sec; 0.044 sec/batch; 72h:45m:35s remains)
INFO - root - 2019-11-04 03:40:54.322653: step 7660, total loss = 0.52, predict loss = 0.11 (85.9 examples/sec; 0.047 sec/batch; 77h:28m:59s remains)
INFO - root - 2019-11-04 03:40:54.817554: step 7670, total loss = 0.48, predict loss = 0.10 (88.5 examples/sec; 0.045 sec/batch; 75h:12m:22s remains)
INFO - root - 2019-11-04 03:40:55.312398: step 7680, total loss = 0.54, predict loss = 0.12 (94.5 examples/sec; 0.042 sec/batch; 70h:26m:30s remains)
INFO - root - 2019-11-04 03:40:55.803728: step 7690, total loss = 0.51, predict loss = 0.12 (88.0 examples/sec; 0.045 sec/batch; 75h:40m:18s remains)
INFO - root - 2019-11-04 03:40:56.299281: step 7700, total loss = 0.37, predict loss = 0.07 (88.3 examples/sec; 0.045 sec/batch; 75h:22m:06s remains)
INFO - root - 2019-11-04 03:40:56.792959: step 7710, total loss = 0.58, predict loss = 0.13 (86.7 examples/sec; 0.046 sec/batch; 76h:47m:28s remains)
INFO - root - 2019-11-04 03:40:57.295666: step 7720, total loss = 0.67, predict loss = 0.15 (93.0 examples/sec; 0.043 sec/batch; 71h:33m:16s remains)
INFO - root - 2019-11-04 03:40:57.785799: step 7730, total loss = 0.57, predict loss = 0.13 (98.6 examples/sec; 0.041 sec/batch; 67h:30m:00s remains)
INFO - root - 2019-11-04 03:40:58.289502: step 7740, total loss = 0.47, predict loss = 0.10 (89.5 examples/sec; 0.045 sec/batch; 74h:24m:20s remains)
INFO - root - 2019-11-04 03:40:58.785926: step 7750, total loss = 0.49, predict loss = 0.11 (95.5 examples/sec; 0.042 sec/batch; 69h:42m:59s remains)
INFO - root - 2019-11-04 03:40:59.272889: step 7760, total loss = 0.46, predict loss = 0.10 (87.5 examples/sec; 0.046 sec/batch; 76h:03m:32s remains)
INFO - root - 2019-11-04 03:40:59.760307: step 7770, total loss = 0.52, predict loss = 0.10 (92.5 examples/sec; 0.043 sec/batch; 71h:58m:28s remains)
INFO - root - 2019-11-04 03:41:00.265218: step 7780, total loss = 0.38, predict loss = 0.09 (88.2 examples/sec; 0.045 sec/batch; 75h:30m:09s remains)
INFO - root - 2019-11-04 03:41:00.756825: step 7790, total loss = 0.64, predict loss = 0.15 (90.7 examples/sec; 0.044 sec/batch; 73h:24m:59s remains)
INFO - root - 2019-11-04 03:41:01.255037: step 7800, total loss = 0.69, predict loss = 0.15 (88.6 examples/sec; 0.045 sec/batch; 75h:09m:36s remains)
INFO - root - 2019-11-04 03:41:01.792229: step 7810, total loss = 0.62, predict loss = 0.15 (66.1 examples/sec; 0.061 sec/batch; 100h:47m:49s remains)
INFO - root - 2019-11-04 03:41:02.381929: step 7820, total loss = 0.63, predict loss = 0.14 (70.5 examples/sec; 0.057 sec/batch; 94h:25m:10s remains)
INFO - root - 2019-11-04 03:41:03.034840: step 7830, total loss = 0.61, predict loss = 0.14 (70.9 examples/sec; 0.056 sec/batch; 93h:58m:05s remains)
INFO - root - 2019-11-04 03:41:03.648608: step 7840, total loss = 0.45, predict loss = 0.10 (73.9 examples/sec; 0.054 sec/batch; 90h:07m:01s remains)
INFO - root - 2019-11-04 03:41:04.229890: step 7850, total loss = 0.58, predict loss = 0.15 (76.5 examples/sec; 0.052 sec/batch; 87h:03m:50s remains)
INFO - root - 2019-11-04 03:41:04.830721: step 7860, total loss = 0.42, predict loss = 0.08 (81.8 examples/sec; 0.049 sec/batch; 81h:22m:29s remains)
INFO - root - 2019-11-04 03:41:05.435423: step 7870, total loss = 0.66, predict loss = 0.16 (77.3 examples/sec; 0.052 sec/batch; 86h:09m:33s remains)
INFO - root - 2019-11-04 03:41:06.010736: step 7880, total loss = 0.55, predict loss = 0.11 (75.5 examples/sec; 0.053 sec/batch; 88h:08m:45s remains)
INFO - root - 2019-11-04 03:41:06.605195: step 7890, total loss = 0.55, predict loss = 0.12 (75.2 examples/sec; 0.053 sec/batch; 88h:30m:54s remains)
INFO - root - 2019-11-04 03:41:07.192625: step 7900, total loss = 0.48, predict loss = 0.11 (76.9 examples/sec; 0.052 sec/batch; 86h:35m:09s remains)
INFO - root - 2019-11-04 03:41:07.803338: step 7910, total loss = 0.73, predict loss = 0.16 (73.8 examples/sec; 0.054 sec/batch; 90h:10m:00s remains)
INFO - root - 2019-11-04 03:41:08.375726: step 7920, total loss = 0.69, predict loss = 0.16 (77.3 examples/sec; 0.052 sec/batch; 86h:11m:04s remains)
INFO - root - 2019-11-04 03:41:08.961556: step 7930, total loss = 0.74, predict loss = 0.17 (80.3 examples/sec; 0.050 sec/batch; 82h:56m:37s remains)
INFO - root - 2019-11-04 03:41:09.550678: step 7940, total loss = 0.68, predict loss = 0.15 (75.4 examples/sec; 0.053 sec/batch; 88h:17m:04s remains)
INFO - root - 2019-11-04 03:41:10.161654: step 7950, total loss = 0.78, predict loss = 0.15 (72.7 examples/sec; 0.055 sec/batch; 91h:37m:41s remains)
INFO - root - 2019-11-04 03:41:10.773935: step 7960, total loss = 0.53, predict loss = 0.12 (78.8 examples/sec; 0.051 sec/batch; 84h:30m:26s remains)
INFO - root - 2019-11-04 03:41:11.390206: step 7970, total loss = 0.86, predict loss = 0.20 (74.5 examples/sec; 0.054 sec/batch; 89h:24m:13s remains)
INFO - root - 2019-11-04 03:41:11.988509: step 7980, total loss = 0.73, predict loss = 0.18 (71.4 examples/sec; 0.056 sec/batch; 93h:16m:20s remains)
INFO - root - 2019-11-04 03:41:12.592656: step 7990, total loss = 0.68, predict loss = 0.16 (79.2 examples/sec; 0.051 sec/batch; 84h:04m:28s remains)
INFO - root - 2019-11-04 03:41:13.209048: step 8000, total loss = 0.67, predict loss = 0.17 (72.0 examples/sec; 0.056 sec/batch; 92h:27m:27s remains)
INFO - root - 2019-11-04 03:41:13.811859: step 8010, total loss = 0.64, predict loss = 0.15 (73.4 examples/sec; 0.055 sec/batch; 90h:43m:18s remains)
INFO - root - 2019-11-04 03:41:14.438272: step 8020, total loss = 0.54, predict loss = 0.13 (65.4 examples/sec; 0.061 sec/batch; 101h:49m:42s remains)
INFO - root - 2019-11-04 03:41:15.084012: step 8030, total loss = 0.32, predict loss = 0.07 (71.8 examples/sec; 0.056 sec/batch; 92h:40m:13s remains)
INFO - root - 2019-11-04 03:41:15.729315: step 8040, total loss = 0.46, predict loss = 0.11 (75.5 examples/sec; 0.053 sec/batch; 88h:09m:50s remains)
INFO - root - 2019-11-04 03:41:16.370974: step 8050, total loss = 0.36, predict loss = 0.08 (74.6 examples/sec; 0.054 sec/batch; 89h:11m:57s remains)
INFO - root - 2019-11-04 03:41:16.999245: step 8060, total loss = 0.37, predict loss = 0.09 (72.3 examples/sec; 0.055 sec/batch; 92h:06m:58s remains)
INFO - root - 2019-11-04 03:41:17.638687: step 8070, total loss = 0.42, predict loss = 0.09 (74.4 examples/sec; 0.054 sec/batch; 89h:28m:20s remains)
INFO - root - 2019-11-04 03:41:18.277143: step 8080, total loss = 0.49, predict loss = 0.10 (58.8 examples/sec; 0.068 sec/batch; 113h:15m:13s remains)
INFO - root - 2019-11-04 03:41:18.893086: step 8090, total loss = 0.66, predict loss = 0.14 (73.8 examples/sec; 0.054 sec/batch; 90h:16m:13s remains)
INFO - root - 2019-11-04 03:41:19.490346: step 8100, total loss = 0.48, predict loss = 0.10 (71.3 examples/sec; 0.056 sec/batch; 93h:21m:34s remains)
INFO - root - 2019-11-04 03:41:20.102561: step 8110, total loss = 0.61, predict loss = 0.13 (74.0 examples/sec; 0.054 sec/batch; 90h:01m:08s remains)
INFO - root - 2019-11-04 03:41:20.706209: step 8120, total loss = 0.49, predict loss = 0.12 (78.5 examples/sec; 0.051 sec/batch; 84h:46m:56s remains)
INFO - root - 2019-11-04 03:41:21.261105: step 8130, total loss = 0.55, predict loss = 0.13 (80.6 examples/sec; 0.050 sec/batch; 82h:37m:13s remains)
INFO - root - 2019-11-04 03:41:21.798732: step 8140, total loss = 0.64, predict loss = 0.13 (79.5 examples/sec; 0.050 sec/batch; 83h:46m:28s remains)
INFO - root - 2019-11-04 03:41:22.340548: step 8150, total loss = 0.45, predict loss = 0.10 (80.8 examples/sec; 0.050 sec/batch; 82h:26m:27s remains)
INFO - root - 2019-11-04 03:41:22.849545: step 8160, total loss = 0.35, predict loss = 0.07 (100.6 examples/sec; 0.040 sec/batch; 66h:12m:16s remains)
INFO - root - 2019-11-04 03:41:23.286589: step 8170, total loss = 0.44, predict loss = 0.09 (94.1 examples/sec; 0.042 sec/batch; 70h:43m:28s remains)
INFO - root - 2019-11-04 03:41:23.738312: step 8180, total loss = 0.73, predict loss = 0.15 (90.8 examples/sec; 0.044 sec/batch; 73h:18m:23s remains)
INFO - root - 2019-11-04 03:41:24.604945: step 8190, total loss = 0.43, predict loss = 0.10 (69.9 examples/sec; 0.057 sec/batch; 95h:13m:08s remains)
INFO - root - 2019-11-04 03:41:25.253593: step 8200, total loss = 0.32, predict loss = 0.07 (67.0 examples/sec; 0.060 sec/batch; 99h:23m:13s remains)
INFO - root - 2019-11-04 03:41:25.900652: step 8210, total loss = 0.38, predict loss = 0.09 (71.8 examples/sec; 0.056 sec/batch; 92h:44m:44s remains)
INFO - root - 2019-11-04 03:41:26.538531: step 8220, total loss = 0.53, predict loss = 0.11 (69.7 examples/sec; 0.057 sec/batch; 95h:28m:36s remains)
INFO - root - 2019-11-04 03:41:27.153733: step 8230, total loss = 0.38, predict loss = 0.09 (74.8 examples/sec; 0.053 sec/batch; 88h:58m:17s remains)
INFO - root - 2019-11-04 03:41:27.802500: step 8240, total loss = 0.48, predict loss = 0.10 (65.1 examples/sec; 0.061 sec/batch; 102h:17m:32s remains)
INFO - root - 2019-11-04 03:41:28.396888: step 8250, total loss = 0.46, predict loss = 0.10 (81.0 examples/sec; 0.049 sec/batch; 82h:11m:52s remains)
INFO - root - 2019-11-04 03:41:28.983365: step 8260, total loss = 0.42, predict loss = 0.09 (79.8 examples/sec; 0.050 sec/batch; 83h:24m:00s remains)
INFO - root - 2019-11-04 03:41:29.564691: step 8270, total loss = 0.37, predict loss = 0.08 (75.5 examples/sec; 0.053 sec/batch; 88h:07m:37s remains)
INFO - root - 2019-11-04 03:41:30.154097: step 8280, total loss = 0.58, predict loss = 0.15 (78.2 examples/sec; 0.051 sec/batch; 85h:09m:41s remains)
INFO - root - 2019-11-04 03:41:30.745765: step 8290, total loss = 0.48, predict loss = 0.08 (75.0 examples/sec; 0.053 sec/batch; 88h:48m:57s remains)
INFO - root - 2019-11-04 03:41:31.339505: step 8300, total loss = 0.47, predict loss = 0.10 (72.4 examples/sec; 0.055 sec/batch; 92h:00m:03s remains)
INFO - root - 2019-11-04 03:41:31.972684: step 8310, total loss = 1.00, predict loss = 0.11 (87.8 examples/sec; 0.046 sec/batch; 75h:47m:23s remains)
INFO - root - 2019-11-04 03:41:32.519013: step 8320, total loss = 0.51, predict loss = 0.11 (75.9 examples/sec; 0.053 sec/batch; 87h:44m:51s remains)
INFO - root - 2019-11-04 03:41:33.096732: step 8330, total loss = 0.37, predict loss = 0.07 (81.1 examples/sec; 0.049 sec/batch; 82h:05m:44s remains)
INFO - root - 2019-11-04 03:41:33.648725: step 8340, total loss = 0.48, predict loss = 0.11 (81.4 examples/sec; 0.049 sec/batch; 81h:47m:02s remains)
INFO - root - 2019-11-04 03:41:34.208259: step 8350, total loss = 0.36, predict loss = 0.07 (80.1 examples/sec; 0.050 sec/batch; 83h:05m:02s remains)
INFO - root - 2019-11-04 03:41:34.756040: step 8360, total loss = 0.46, predict loss = 0.11 (82.8 examples/sec; 0.048 sec/batch; 80h:22m:24s remains)
INFO - root - 2019-11-04 03:41:35.335396: step 8370, total loss = 0.39, predict loss = 0.10 (75.6 examples/sec; 0.053 sec/batch; 88h:03m:31s remains)
INFO - root - 2019-11-04 03:41:35.899387: step 8380, total loss = 0.40, predict loss = 0.09 (82.8 examples/sec; 0.048 sec/batch; 80h:21m:35s remains)
INFO - root - 2019-11-04 03:41:36.464982: step 8390, total loss = 0.47, predict loss = 0.10 (80.8 examples/sec; 0.050 sec/batch; 82h:25m:48s remains)
INFO - root - 2019-11-04 03:41:37.019894: step 8400, total loss = 0.33, predict loss = 0.07 (76.6 examples/sec; 0.052 sec/batch; 86h:52m:09s remains)
INFO - root - 2019-11-04 03:41:37.597602: step 8410, total loss = 0.35, predict loss = 0.07 (77.5 examples/sec; 0.052 sec/batch; 85h:53m:15s remains)
INFO - root - 2019-11-04 03:41:38.182878: step 8420, total loss = 0.29, predict loss = 0.06 (78.2 examples/sec; 0.051 sec/batch; 85h:10m:45s remains)
INFO - root - 2019-11-04 03:41:38.749135: step 8430, total loss = 0.41, predict loss = 0.08 (75.2 examples/sec; 0.053 sec/batch; 88h:30m:27s remains)
INFO - root - 2019-11-04 03:41:39.309218: step 8440, total loss = 0.51, predict loss = 0.11 (84.5 examples/sec; 0.047 sec/batch; 78h:49m:44s remains)
INFO - root - 2019-11-04 03:41:39.871982: step 8450, total loss = 0.49, predict loss = 0.10 (76.0 examples/sec; 0.053 sec/batch; 87h:35m:47s remains)
INFO - root - 2019-11-04 03:41:40.435977: step 8460, total loss = 0.36, predict loss = 0.08 (80.1 examples/sec; 0.050 sec/batch; 83h:06m:11s remains)
INFO - root - 2019-11-04 03:41:40.995471: step 8470, total loss = 0.41, predict loss = 0.08 (78.5 examples/sec; 0.051 sec/batch; 84h:45m:37s remains)
INFO - root - 2019-11-04 03:41:41.553904: step 8480, total loss = 0.42, predict loss = 0.09 (87.9 examples/sec; 0.046 sec/batch; 75h:45m:15s remains)
INFO - root - 2019-11-04 03:41:42.125545: step 8490, total loss = 0.44, predict loss = 0.10 (81.0 examples/sec; 0.049 sec/batch; 82h:09m:54s remains)
INFO - root - 2019-11-04 03:41:42.682882: step 8500, total loss = 0.49, predict loss = 0.11 (83.6 examples/sec; 0.048 sec/batch; 79h:39m:39s remains)
INFO - root - 2019-11-04 03:41:43.260737: step 8510, total loss = 0.55, predict loss = 0.10 (81.2 examples/sec; 0.049 sec/batch; 81h:58m:24s remains)
INFO - root - 2019-11-04 03:41:43.825549: step 8520, total loss = 0.40, predict loss = 0.08 (80.2 examples/sec; 0.050 sec/batch; 83h:01m:12s remains)
INFO - root - 2019-11-04 03:41:44.400212: step 8530, total loss = 0.52, predict loss = 0.12 (74.0 examples/sec; 0.054 sec/batch; 89h:58m:11s remains)
INFO - root - 2019-11-04 03:41:45.021754: step 8540, total loss = 0.50, predict loss = 0.11 (71.7 examples/sec; 0.056 sec/batch; 92h:53m:00s remains)
INFO - root - 2019-11-04 03:41:45.654419: step 8550, total loss = 0.56, predict loss = 0.11 (80.6 examples/sec; 0.050 sec/batch; 82h:36m:50s remains)
INFO - root - 2019-11-04 03:41:46.234110: step 8560, total loss = 0.36, predict loss = 0.08 (77.2 examples/sec; 0.052 sec/batch; 86h:11m:32s remains)
INFO - root - 2019-11-04 03:41:46.815432: step 8570, total loss = 0.54, predict loss = 0.13 (79.6 examples/sec; 0.050 sec/batch; 83h:40m:08s remains)
INFO - root - 2019-11-04 03:41:47.397345: step 8580, total loss = 0.41, predict loss = 0.08 (74.2 examples/sec; 0.054 sec/batch; 89h:43m:31s remains)
INFO - root - 2019-11-04 03:41:47.981660: step 8590, total loss = 0.82, predict loss = 0.23 (76.3 examples/sec; 0.052 sec/batch; 87h:16m:14s remains)
INFO - root - 2019-11-04 03:41:48.578179: step 8600, total loss = 0.64, predict loss = 0.16 (74.3 examples/sec; 0.054 sec/batch; 89h:35m:57s remains)
INFO - root - 2019-11-04 03:41:49.159668: step 8610, total loss = 0.66, predict loss = 0.16 (75.1 examples/sec; 0.053 sec/batch; 88h:41m:24s remains)
INFO - root - 2019-11-04 03:41:49.758272: step 8620, total loss = 0.76, predict loss = 0.21 (73.1 examples/sec; 0.055 sec/batch; 91h:07m:03s remains)
INFO - root - 2019-11-04 03:41:50.344339: step 8630, total loss = 0.52, predict loss = 0.11 (80.6 examples/sec; 0.050 sec/batch; 82h:36m:32s remains)
INFO - root - 2019-11-04 03:41:50.934738: step 8640, total loss = 0.45, predict loss = 0.11 (72.8 examples/sec; 0.055 sec/batch; 91h:26m:49s remains)
INFO - root - 2019-11-04 03:41:51.536465: step 8650, total loss = 0.44, predict loss = 0.10 (78.3 examples/sec; 0.051 sec/batch; 85h:04m:25s remains)
INFO - root - 2019-11-04 03:41:52.119077: step 8660, total loss = 0.23, predict loss = 0.05 (72.8 examples/sec; 0.055 sec/batch; 91h:28m:16s remains)
INFO - root - 2019-11-04 03:41:52.696661: step 8670, total loss = 0.37, predict loss = 0.07 (76.0 examples/sec; 0.053 sec/batch; 87h:33m:07s remains)
INFO - root - 2019-11-04 03:41:53.286856: step 8680, total loss = 0.60, predict loss = 0.13 (71.2 examples/sec; 0.056 sec/batch; 93h:29m:26s remains)
INFO - root - 2019-11-04 03:41:53.858582: step 8690, total loss = 0.36, predict loss = 0.07 (75.5 examples/sec; 0.053 sec/batch; 88h:07m:13s remains)
INFO - root - 2019-11-04 03:41:54.443719: step 8700, total loss = 0.37, predict loss = 0.08 (74.3 examples/sec; 0.054 sec/batch; 89h:32m:41s remains)
INFO - root - 2019-11-04 03:41:55.030452: step 8710, total loss = 0.36, predict loss = 0.07 (79.3 examples/sec; 0.050 sec/batch; 83h:59m:32s remains)
INFO - root - 2019-11-04 03:41:55.620256: step 8720, total loss = 0.30, predict loss = 0.07 (74.9 examples/sec; 0.053 sec/batch; 88h:55m:13s remains)
INFO - root - 2019-11-04 03:41:56.199529: step 8730, total loss = 0.41, predict loss = 0.10 (73.7 examples/sec; 0.054 sec/batch; 90h:21m:23s remains)
INFO - root - 2019-11-04 03:41:56.785809: step 8740, total loss = 0.31, predict loss = 0.06 (76.5 examples/sec; 0.052 sec/batch; 86h:58m:19s remains)
INFO - root - 2019-11-04 03:41:57.362634: step 8750, total loss = 0.42, predict loss = 0.10 (72.5 examples/sec; 0.055 sec/batch; 91h:47m:54s remains)
INFO - root - 2019-11-04 03:41:57.970936: step 8760, total loss = 0.37, predict loss = 0.08 (74.1 examples/sec; 0.054 sec/batch; 89h:48m:19s remains)
INFO - root - 2019-11-04 03:41:58.566744: step 8770, total loss = 0.37, predict loss = 0.08 (74.4 examples/sec; 0.054 sec/batch; 89h:25m:30s remains)
INFO - root - 2019-11-04 03:41:59.155757: step 8780, total loss = 0.87, predict loss = 0.26 (89.8 examples/sec; 0.045 sec/batch; 74h:09m:18s remains)
INFO - root - 2019-11-04 03:41:59.750657: step 8790, total loss = 0.32, predict loss = 0.07 (71.4 examples/sec; 0.056 sec/batch; 93h:13m:33s remains)
INFO - root - 2019-11-04 03:42:00.352834: step 8800, total loss = 0.33, predict loss = 0.07 (70.3 examples/sec; 0.057 sec/batch; 94h:38m:33s remains)
INFO - root - 2019-11-04 03:42:00.894386: step 8810, total loss = 0.84, predict loss = 0.27 (87.4 examples/sec; 0.046 sec/batch; 76h:10m:09s remains)
INFO - root - 2019-11-04 03:42:01.390432: step 8820, total loss = 0.22, predict loss = 0.05 (96.3 examples/sec; 0.042 sec/batch; 69h:08m:14s remains)
INFO - root - 2019-11-04 03:42:01.964958: step 8830, total loss = 0.41, predict loss = 0.08 (74.0 examples/sec; 0.054 sec/batch; 90h:00m:02s remains)
INFO - root - 2019-11-04 03:42:02.461332: step 8840, total loss = 0.40, predict loss = 0.08 (83.8 examples/sec; 0.048 sec/batch; 79h:26m:25s remains)
INFO - root - 2019-11-04 03:42:02.949412: step 8850, total loss = 0.59, predict loss = 0.15 (86.5 examples/sec; 0.046 sec/batch; 76h:55m:14s remains)
INFO - root - 2019-11-04 03:42:03.450475: step 8860, total loss = 0.35, predict loss = 0.08 (90.4 examples/sec; 0.044 sec/batch; 73h:36m:16s remains)
INFO - root - 2019-11-04 03:42:03.940153: step 8870, total loss = 0.36, predict loss = 0.09 (87.4 examples/sec; 0.046 sec/batch; 76h:11m:15s remains)
INFO - root - 2019-11-04 03:42:04.432508: step 8880, total loss = 0.39, predict loss = 0.08 (90.8 examples/sec; 0.044 sec/batch; 73h:19m:08s remains)
INFO - root - 2019-11-04 03:42:04.923194: step 8890, total loss = 0.42, predict loss = 0.12 (91.2 examples/sec; 0.044 sec/batch; 72h:59m:38s remains)
INFO - root - 2019-11-04 03:42:05.410318: step 8900, total loss = 0.31, predict loss = 0.07 (95.2 examples/sec; 0.042 sec/batch; 69h:57m:25s remains)
INFO - root - 2019-11-04 03:42:05.895495: step 8910, total loss = 0.46, predict loss = 0.11 (89.1 examples/sec; 0.045 sec/batch; 74h:42m:19s remains)
INFO - root - 2019-11-04 03:42:06.373674: step 8920, total loss = 0.48, predict loss = 0.10 (91.0 examples/sec; 0.044 sec/batch; 73h:11m:04s remains)
INFO - root - 2019-11-04 03:42:06.862611: step 8930, total loss = 0.34, predict loss = 0.08 (90.4 examples/sec; 0.044 sec/batch; 73h:38m:42s remains)
INFO - root - 2019-11-04 03:42:07.344047: step 8940, total loss = 0.41, predict loss = 0.09 (85.2 examples/sec; 0.047 sec/batch; 78h:05m:23s remains)
INFO - root - 2019-11-04 03:42:07.831656: step 8950, total loss = 0.64, predict loss = 0.17 (88.4 examples/sec; 0.045 sec/batch; 75h:17m:11s remains)
INFO - root - 2019-11-04 03:42:08.322045: step 8960, total loss = 0.36, predict loss = 0.07 (85.4 examples/sec; 0.047 sec/batch; 77h:57m:44s remains)
INFO - root - 2019-11-04 03:42:08.817856: step 8970, total loss = 0.46, predict loss = 0.11 (87.5 examples/sec; 0.046 sec/batch; 76h:05m:09s remains)
INFO - root - 2019-11-04 03:42:09.308361: step 8980, total loss = 0.39, predict loss = 0.07 (92.6 examples/sec; 0.043 sec/batch; 71h:52m:00s remains)
INFO - root - 2019-11-04 03:42:09.791240: step 8990, total loss = 0.40, predict loss = 0.09 (87.7 examples/sec; 0.046 sec/batch; 75h:55m:02s remains)
INFO - root - 2019-11-04 03:42:10.292348: step 9000, total loss = 0.36, predict loss = 0.07 (86.4 examples/sec; 0.046 sec/batch; 77h:00m:07s remains)
INFO - root - 2019-11-04 03:42:10.793284: step 9010, total loss = 0.37, predict loss = 0.08 (91.9 examples/sec; 0.044 sec/batch; 72h:25m:39s remains)
INFO - root - 2019-11-04 03:42:11.277117: step 9020, total loss = 0.41, predict loss = 0.09 (90.0 examples/sec; 0.044 sec/batch; 74h:00m:07s remains)
INFO - root - 2019-11-04 03:42:11.775725: step 9030, total loss = 0.34, predict loss = 0.07 (87.6 examples/sec; 0.046 sec/batch; 76h:01m:13s remains)
INFO - root - 2019-11-04 03:42:12.260008: step 9040, total loss = 0.37, predict loss = 0.08 (85.7 examples/sec; 0.047 sec/batch; 77h:42m:19s remains)
INFO - root - 2019-11-04 03:42:12.752412: step 9050, total loss = 0.25, predict loss = 0.05 (91.4 examples/sec; 0.044 sec/batch; 72h:48m:24s remains)
INFO - root - 2019-11-04 03:42:13.241756: step 9060, total loss = 0.39, predict loss = 0.09 (91.8 examples/sec; 0.044 sec/batch; 72h:29m:04s remains)
INFO - root - 2019-11-04 03:42:13.716758: step 9070, total loss = 0.26, predict loss = 0.06 (94.0 examples/sec; 0.043 sec/batch; 70h:49m:16s remains)
INFO - root - 2019-11-04 03:42:14.190082: step 9080, total loss = 0.36, predict loss = 0.07 (94.4 examples/sec; 0.042 sec/batch; 70h:32m:17s remains)
INFO - root - 2019-11-04 03:42:15.044855: step 9090, total loss = 0.30, predict loss = 0.06 (65.7 examples/sec; 0.061 sec/batch; 101h:19m:56s remains)
INFO - root - 2019-11-04 03:42:15.698074: step 9100, total loss = 0.39, predict loss = 0.09 (71.6 examples/sec; 0.056 sec/batch; 92h:56m:53s remains)
INFO - root - 2019-11-04 03:42:16.296036: step 9110, total loss = 0.31, predict loss = 0.06 (78.1 examples/sec; 0.051 sec/batch; 85h:16m:58s remains)
INFO - root - 2019-11-04 03:42:16.862248: step 9120, total loss = 0.29, predict loss = 0.07 (82.6 examples/sec; 0.048 sec/batch; 80h:33m:32s remains)
INFO - root - 2019-11-04 03:42:17.444986: step 9130, total loss = 0.36, predict loss = 0.08 (82.2 examples/sec; 0.049 sec/batch; 80h:57m:03s remains)
INFO - root - 2019-11-04 03:42:18.027454: step 9140, total loss = 0.35, predict loss = 0.08 (80.4 examples/sec; 0.050 sec/batch; 82h:47m:51s remains)
INFO - root - 2019-11-04 03:42:18.650671: step 9150, total loss = 0.44, predict loss = 0.12 (68.6 examples/sec; 0.058 sec/batch; 96h:57m:55s remains)
INFO - root - 2019-11-04 03:42:19.228247: step 9160, total loss = 0.37, predict loss = 0.10 (72.6 examples/sec; 0.055 sec/batch; 91h:39m:03s remains)
INFO - root - 2019-11-04 03:42:19.847630: step 9170, total loss = 0.34, predict loss = 0.06 (68.5 examples/sec; 0.058 sec/batch; 97h:09m:08s remains)
INFO - root - 2019-11-04 03:42:20.463205: step 9180, total loss = 0.39, predict loss = 0.09 (77.2 examples/sec; 0.052 sec/batch; 86h:14m:04s remains)
INFO - root - 2019-11-04 03:42:21.087263: step 9190, total loss = 0.47, predict loss = 0.10 (73.2 examples/sec; 0.055 sec/batch; 90h:57m:43s remains)
INFO - root - 2019-11-04 03:42:21.689682: step 9200, total loss = 0.34, predict loss = 0.07 (75.9 examples/sec; 0.053 sec/batch; 87h:43m:05s remains)
INFO - root - 2019-11-04 03:42:22.315365: step 9210, total loss = 0.41, predict loss = 0.09 (68.6 examples/sec; 0.058 sec/batch; 96h:59m:17s remains)
INFO - root - 2019-11-04 03:42:22.921310: step 9220, total loss = 0.40, predict loss = 0.09 (76.6 examples/sec; 0.052 sec/batch; 86h:56m:13s remains)
INFO - root - 2019-11-04 03:42:23.534602: step 9230, total loss = 0.28, predict loss = 0.06 (72.8 examples/sec; 0.055 sec/batch; 91h:22m:49s remains)
INFO - root - 2019-11-04 03:42:24.132759: step 9240, total loss = 0.29, predict loss = 0.06 (87.1 examples/sec; 0.046 sec/batch; 76h:23m:27s remains)
INFO - root - 2019-11-04 03:42:24.730473: step 9250, total loss = 0.38, predict loss = 0.09 (77.7 examples/sec; 0.051 sec/batch; 85h:41m:59s remains)
INFO - root - 2019-11-04 03:42:25.311183: step 9260, total loss = 0.31, predict loss = 0.06 (80.0 examples/sec; 0.050 sec/batch; 83h:15m:19s remains)
INFO - root - 2019-11-04 03:42:25.888707: step 9270, total loss = 0.25, predict loss = 0.05 (83.3 examples/sec; 0.048 sec/batch; 79h:57m:14s remains)
INFO - root - 2019-11-04 03:42:26.456219: step 9280, total loss = 0.36, predict loss = 0.06 (78.7 examples/sec; 0.051 sec/batch; 84h:37m:34s remains)
INFO - root - 2019-11-04 03:42:27.048891: step 9290, total loss = 0.44, predict loss = 0.09 (71.2 examples/sec; 0.056 sec/batch; 93h:31m:36s remains)
INFO - root - 2019-11-04 03:42:27.653863: step 9300, total loss = 0.40, predict loss = 0.07 (69.5 examples/sec; 0.058 sec/batch; 95h:48m:23s remains)
INFO - root - 2019-11-04 03:42:28.258984: step 9310, total loss = 0.44, predict loss = 0.09 (72.2 examples/sec; 0.055 sec/batch; 92h:08m:47s remains)
INFO - root - 2019-11-04 03:42:28.859217: step 9320, total loss = 0.36, predict loss = 0.07 (76.4 examples/sec; 0.052 sec/batch; 87h:08m:52s remains)
INFO - root - 2019-11-04 03:42:29.476890: step 9330, total loss = 0.24, predict loss = 0.04 (74.6 examples/sec; 0.054 sec/batch; 89h:10m:08s remains)
INFO - root - 2019-11-04 03:42:30.094632: step 9340, total loss = 0.46, predict loss = 0.11 (73.3 examples/sec; 0.055 sec/batch; 90h:47m:51s remains)
INFO - root - 2019-11-04 03:42:30.687839: step 9350, total loss = 0.52, predict loss = 0.12 (72.7 examples/sec; 0.055 sec/batch; 91h:35m:44s remains)
INFO - root - 2019-11-04 03:42:31.295397: step 9360, total loss = 0.42, predict loss = 0.10 (83.7 examples/sec; 0.048 sec/batch; 79h:33m:15s remains)
INFO - root - 2019-11-04 03:42:32.001495: step 9370, total loss = 0.53, predict loss = 0.10 (55.4 examples/sec; 0.072 sec/batch; 120h:11m:39s remains)
INFO - root - 2019-11-04 03:42:32.536551: step 9380, total loss = 0.38, predict loss = 0.08 (82.2 examples/sec; 0.049 sec/batch; 80h:58m:18s remains)
INFO - root - 2019-11-04 03:42:33.099248: step 9390, total loss = 0.25, predict loss = 0.05 (79.3 examples/sec; 0.050 sec/batch; 83h:56m:01s remains)
INFO - root - 2019-11-04 03:42:33.641815: step 9400, total loss = 0.34, predict loss = 0.08 (78.3 examples/sec; 0.051 sec/batch; 84h:58m:18s remains)
INFO - root - 2019-11-04 03:42:34.205373: step 9410, total loss = 0.30, predict loss = 0.06 (77.4 examples/sec; 0.052 sec/batch; 86h:03m:04s remains)
INFO - root - 2019-11-04 03:42:34.774464: step 9420, total loss = 0.36, predict loss = 0.07 (77.5 examples/sec; 0.052 sec/batch; 85h:55m:59s remains)
INFO - root - 2019-11-04 03:42:35.332920: step 9430, total loss = 0.47, predict loss = 0.10 (80.9 examples/sec; 0.049 sec/batch; 82h:19m:21s remains)
INFO - root - 2019-11-04 03:42:35.898345: step 9440, total loss = 0.38, predict loss = 0.08 (78.2 examples/sec; 0.051 sec/batch; 85h:06m:31s remains)
INFO - root - 2019-11-04 03:42:36.466532: step 9450, total loss = 0.40, predict loss = 0.08 (81.4 examples/sec; 0.049 sec/batch; 81h:43m:26s remains)
INFO - root - 2019-11-04 03:42:37.023125: step 9460, total loss = 0.47, predict loss = 0.09 (83.4 examples/sec; 0.048 sec/batch; 79h:47m:56s remains)
INFO - root - 2019-11-04 03:42:37.594228: step 9470, total loss = 0.40, predict loss = 0.08 (82.1 examples/sec; 0.049 sec/batch; 81h:02m:57s remains)
INFO - root - 2019-11-04 03:42:38.161711: step 9480, total loss = 0.41, predict loss = 0.08 (80.8 examples/sec; 0.050 sec/batch; 82h:25m:03s remains)
INFO - root - 2019-11-04 03:42:38.725744: step 9490, total loss = 0.44, predict loss = 0.10 (84.5 examples/sec; 0.047 sec/batch; 78h:48m:17s remains)
INFO - root - 2019-11-04 03:42:39.300873: step 9500, total loss = 0.42, predict loss = 0.09 (73.6 examples/sec; 0.054 sec/batch; 90h:25m:11s remains)
INFO - root - 2019-11-04 03:42:39.896736: step 9510, total loss = 0.45, predict loss = 0.10 (73.4 examples/sec; 0.054 sec/batch; 90h:39m:25s remains)
INFO - root - 2019-11-04 03:42:40.508000: step 9520, total loss = 0.20, predict loss = 0.05 (75.9 examples/sec; 0.053 sec/batch; 87h:41m:45s remains)
INFO - root - 2019-11-04 03:42:41.110890: step 9530, total loss = 0.26, predict loss = 0.05 (72.5 examples/sec; 0.055 sec/batch; 91h:51m:30s remains)
INFO - root - 2019-11-04 03:42:41.732073: step 9540, total loss = 0.38, predict loss = 0.09 (69.5 examples/sec; 0.058 sec/batch; 95h:47m:17s remains)
INFO - root - 2019-11-04 03:42:42.339198: step 9550, total loss = 0.40, predict loss = 0.09 (69.0 examples/sec; 0.058 sec/batch; 96h:25m:20s remains)
INFO - root - 2019-11-04 03:42:42.957315: step 9560, total loss = 0.46, predict loss = 0.11 (75.7 examples/sec; 0.053 sec/batch; 87h:57m:51s remains)
INFO - root - 2019-11-04 03:42:43.578041: step 9570, total loss = 0.37, predict loss = 0.07 (71.0 examples/sec; 0.056 sec/batch; 93h:44m:27s remains)
INFO - root - 2019-11-04 03:42:44.181679: step 9580, total loss = 0.35, predict loss = 0.07 (73.6 examples/sec; 0.054 sec/batch; 90h:24m:53s remains)
INFO - root - 2019-11-04 03:42:44.782377: step 9590, total loss = 0.42, predict loss = 0.10 (71.7 examples/sec; 0.056 sec/batch; 92h:49m:51s remains)
INFO - root - 2019-11-04 03:42:45.379745: step 9600, total loss = 0.58, predict loss = 0.13 (69.9 examples/sec; 0.057 sec/batch; 95h:12m:07s remains)
INFO - root - 2019-11-04 03:42:45.980366: step 9610, total loss = 0.51, predict loss = 0.13 (79.7 examples/sec; 0.050 sec/batch; 83h:28m:50s remains)
INFO - root - 2019-11-04 03:42:46.607033: step 9620, total loss = 0.69, predict loss = 0.17 (72.9 examples/sec; 0.055 sec/batch; 91h:19m:22s remains)
INFO - root - 2019-11-04 03:42:47.183584: step 9630, total loss = 0.79, predict loss = 0.18 (81.0 examples/sec; 0.049 sec/batch; 82h:12m:19s remains)
INFO - root - 2019-11-04 03:42:47.749911: step 9640, total loss = 0.59, predict loss = 0.14 (79.6 examples/sec; 0.050 sec/batch; 83h:37m:10s remains)
INFO - root - 2019-11-04 03:42:48.320159: step 9650, total loss = 0.75, predict loss = 0.17 (67.7 examples/sec; 0.059 sec/batch; 98h:19m:10s remains)
INFO - root - 2019-11-04 03:42:48.882521: step 9660, total loss = 0.85, predict loss = 0.20 (78.9 examples/sec; 0.051 sec/batch; 84h:22m:14s remains)
INFO - root - 2019-11-04 03:42:49.444572: step 9670, total loss = 0.69, predict loss = 0.16 (77.0 examples/sec; 0.052 sec/batch; 86h:26m:30s remains)
INFO - root - 2019-11-04 03:42:50.022298: step 9680, total loss = 0.55, predict loss = 0.13 (81.5 examples/sec; 0.049 sec/batch; 81h:42m:25s remains)
INFO - root - 2019-11-04 03:42:50.601447: step 9690, total loss = 0.55, predict loss = 0.12 (78.6 examples/sec; 0.051 sec/batch; 84h:39m:56s remains)
INFO - root - 2019-11-04 03:42:51.178241: step 9700, total loss = 0.58, predict loss = 0.14 (78.9 examples/sec; 0.051 sec/batch; 84h:18m:53s remains)
INFO - root - 2019-11-04 03:42:51.764616: step 9710, total loss = 0.64, predict loss = 0.15 (77.9 examples/sec; 0.051 sec/batch; 85h:25m:46s remains)
INFO - root - 2019-11-04 03:42:52.334061: step 9720, total loss = 0.67, predict loss = 0.16 (82.7 examples/sec; 0.048 sec/batch; 80h:26m:00s remains)
INFO - root - 2019-11-04 03:42:52.957696: step 9730, total loss = 0.78, predict loss = 0.16 (68.5 examples/sec; 0.058 sec/batch; 97h:07m:49s remains)
INFO - root - 2019-11-04 03:42:53.588585: step 9740, total loss = 0.54, predict loss = 0.12 (72.6 examples/sec; 0.055 sec/batch; 91h:41m:07s remains)
INFO - root - 2019-11-04 03:42:54.211994: step 9750, total loss = 0.81, predict loss = 0.18 (71.9 examples/sec; 0.056 sec/batch; 92h:37m:01s remains)
INFO - root - 2019-11-04 03:42:54.785595: step 9760, total loss = 0.58, predict loss = 0.14 (80.5 examples/sec; 0.050 sec/batch; 82h:41m:07s remains)
INFO - root - 2019-11-04 03:42:55.341807: step 9770, total loss = 0.40, predict loss = 0.09 (88.0 examples/sec; 0.045 sec/batch; 75h:39m:20s remains)
INFO - root - 2019-11-04 03:42:55.900071: step 9780, total loss = 0.39, predict loss = 0.09 (81.6 examples/sec; 0.049 sec/batch; 81h:36m:32s remains)
INFO - root - 2019-11-04 03:42:56.473901: step 9790, total loss = 0.46, predict loss = 0.11 (69.0 examples/sec; 0.058 sec/batch; 96h:27m:34s remains)
INFO - root - 2019-11-04 03:42:57.026838: step 9800, total loss = 0.63, predict loss = 0.15 (79.6 examples/sec; 0.050 sec/batch; 83h:38m:59s remains)
INFO - root - 2019-11-04 03:42:57.591723: step 9810, total loss = 0.53, predict loss = 0.12 (72.6 examples/sec; 0.055 sec/batch; 91h:39m:06s remains)
INFO - root - 2019-11-04 03:42:58.185232: step 9820, total loss = 0.59, predict loss = 0.13 (75.2 examples/sec; 0.053 sec/batch; 88h:28m:56s remains)
INFO - root - 2019-11-04 03:42:58.795950: step 9830, total loss = 0.46, predict loss = 0.11 (72.7 examples/sec; 0.055 sec/batch; 91h:32m:15s remains)
INFO - root - 2019-11-04 03:42:59.394300: step 9840, total loss = 0.63, predict loss = 0.15 (75.6 examples/sec; 0.053 sec/batch; 88h:00m:18s remains)
INFO - root - 2019-11-04 03:42:59.996718: step 9850, total loss = 0.63, predict loss = 0.15 (71.3 examples/sec; 0.056 sec/batch; 93h:23m:08s remains)
INFO - root - 2019-11-04 03:43:00.588678: step 9860, total loss = 0.38, predict loss = 0.10 (68.1 examples/sec; 0.059 sec/batch; 97h:41m:30s remains)
INFO - root - 2019-11-04 03:43:01.184589: step 9870, total loss = 0.41, predict loss = 0.09 (72.8 examples/sec; 0.055 sec/batch; 91h:24m:01s remains)
INFO - root - 2019-11-04 03:43:01.812015: step 9880, total loss = 0.45, predict loss = 0.11 (63.9 examples/sec; 0.063 sec/batch; 104h:09m:50s remains)
INFO - root - 2019-11-04 03:43:02.416527: step 9890, total loss = 0.52, predict loss = 0.12 (73.1 examples/sec; 0.055 sec/batch; 91h:06m:25s remains)
INFO - root - 2019-11-04 03:43:03.027588: step 9900, total loss = 0.45, predict loss = 0.12 (79.9 examples/sec; 0.050 sec/batch; 83h:20m:38s remains)
INFO - root - 2019-11-04 03:43:03.619908: step 9910, total loss = 0.58, predict loss = 0.14 (75.0 examples/sec; 0.053 sec/batch; 88h:44m:35s remains)
INFO - root - 2019-11-04 03:43:04.220641: step 9920, total loss = 0.48, predict loss = 0.10 (74.5 examples/sec; 0.054 sec/batch; 89h:17m:37s remains)
INFO - root - 2019-11-04 03:43:04.811171: step 9930, total loss = 0.48, predict loss = 0.11 (78.0 examples/sec; 0.051 sec/batch; 85h:22m:43s remains)
INFO - root - 2019-11-04 03:43:05.414511: step 9940, total loss = 0.44, predict loss = 0.09 (77.5 examples/sec; 0.052 sec/batch; 85h:55m:11s remains)
INFO - root - 2019-11-04 03:43:05.999443: step 9950, total loss = 0.38, predict loss = 0.10 (72.2 examples/sec; 0.055 sec/batch; 92h:14m:08s remains)
INFO - root - 2019-11-04 03:43:06.585173: step 9960, total loss = 0.34, predict loss = 0.08 (73.7 examples/sec; 0.054 sec/batch; 90h:16m:51s remains)
INFO - root - 2019-11-04 03:43:07.174102: step 9970, total loss = 0.52, predict loss = 0.13 (73.9 examples/sec; 0.054 sec/batch; 90h:02m:20s remains)
INFO - root - 2019-11-04 03:43:07.768513: step 9980, total loss = 0.41, predict loss = 0.10 (74.0 examples/sec; 0.054 sec/batch; 89h:55m:28s remains)
INFO - root - 2019-11-04 03:43:08.364301: step 9990, total loss = 0.52, predict loss = 0.12 (73.8 examples/sec; 0.054 sec/batch; 90h:14m:19s remains)
INFO - root - 2019-11-04 03:43:08.958122: step 10000, total loss = 0.45, predict loss = 0.11 (80.6 examples/sec; 0.050 sec/batch; 82h:32m:36s remains)
INFO - root - 2019-11-04 03:43:09.522133: step 10010, total loss = 0.47, predict loss = 0.11 (85.3 examples/sec; 0.047 sec/batch; 78h:01m:55s remains)
INFO - root - 2019-11-04 03:43:10.121707: step 10020, total loss = 0.44, predict loss = 0.11 (74.7 examples/sec; 0.054 sec/batch; 89h:06m:37s remains)
INFO - root - 2019-11-04 03:43:10.721800: step 10030, total loss = 0.48, predict loss = 0.11 (73.3 examples/sec; 0.055 sec/batch; 90h:50m:43s remains)
INFO - root - 2019-11-04 03:43:11.297361: step 10040, total loss = 0.63, predict loss = 0.16 (81.0 examples/sec; 0.049 sec/batch; 82h:11m:20s remains)
INFO - root - 2019-11-04 03:43:11.856593: step 10050, total loss = 0.59, predict loss = 0.14 (81.5 examples/sec; 0.049 sec/batch; 81h:39m:48s remains)
INFO - root - 2019-11-04 03:43:12.416421: step 10060, total loss = 0.57, predict loss = 0.14 (82.1 examples/sec; 0.049 sec/batch; 81h:05m:49s remains)
INFO - root - 2019-11-04 03:43:12.967872: step 10070, total loss = 0.49, predict loss = 0.11 (75.5 examples/sec; 0.053 sec/batch; 88h:06m:49s remains)
INFO - root - 2019-11-04 03:43:13.555137: step 10080, total loss = 0.50, predict loss = 0.13 (75.9 examples/sec; 0.053 sec/batch; 87h:44m:24s remains)
INFO - root - 2019-11-04 03:43:14.118537: step 10090, total loss = 0.63, predict loss = 0.15 (73.7 examples/sec; 0.054 sec/batch; 90h:19m:16s remains)
INFO - root - 2019-11-04 03:43:14.717504: step 10100, total loss = 0.53, predict loss = 0.13 (77.5 examples/sec; 0.052 sec/batch; 85h:54m:27s remains)
INFO - root - 2019-11-04 03:43:15.316211: step 10110, total loss = 0.59, predict loss = 0.14 (72.0 examples/sec; 0.056 sec/batch; 92h:23m:07s remains)
INFO - root - 2019-11-04 03:43:15.923768: step 10120, total loss = 0.50, predict loss = 0.12 (73.1 examples/sec; 0.055 sec/batch; 91h:04m:18s remains)
INFO - root - 2019-11-04 03:43:16.543110: step 10130, total loss = 0.44, predict loss = 0.10 (70.4 examples/sec; 0.057 sec/batch; 94h:29m:35s remains)
INFO - root - 2019-11-04 03:43:17.153325: step 10140, total loss = 0.45, predict loss = 0.10 (73.5 examples/sec; 0.054 sec/batch; 90h:34m:56s remains)
INFO - root - 2019-11-04 03:43:17.756160: step 10150, total loss = 0.44, predict loss = 0.10 (70.9 examples/sec; 0.056 sec/batch; 93h:50m:56s remains)
INFO - root - 2019-11-04 03:43:18.370497: step 10160, total loss = 0.47, predict loss = 0.11 (71.9 examples/sec; 0.056 sec/batch; 92h:31m:43s remains)
INFO - root - 2019-11-04 03:43:18.979941: step 10170, total loss = 0.58, predict loss = 0.13 (73.0 examples/sec; 0.055 sec/batch; 91h:10m:47s remains)
INFO - root - 2019-11-04 03:43:19.587871: step 10180, total loss = 0.48, predict loss = 0.10 (74.6 examples/sec; 0.054 sec/batch; 89h:09m:23s remains)
INFO - root - 2019-11-04 03:43:20.164169: step 10190, total loss = 0.43, predict loss = 0.10 (85.8 examples/sec; 0.047 sec/batch; 77h:33m:57s remains)
INFO - root - 2019-11-04 03:43:20.734003: step 10200, total loss = 0.49, predict loss = 0.11 (76.8 examples/sec; 0.052 sec/batch; 86h:38m:18s remains)
INFO - root - 2019-11-04 03:43:21.297352: step 10210, total loss = 0.56, predict loss = 0.13 (84.1 examples/sec; 0.048 sec/batch; 79h:06m:08s remains)
INFO - root - 2019-11-04 03:43:21.875592: step 10220, total loss = 0.48, predict loss = 0.10 (74.8 examples/sec; 0.053 sec/batch; 88h:59m:48s remains)
INFO - root - 2019-11-04 03:43:22.490712: step 10230, total loss = 0.44, predict loss = 0.10 (73.3 examples/sec; 0.055 sec/batch; 90h:45m:25s remains)
INFO - root - 2019-11-04 03:43:23.100490: step 10240, total loss = 0.62, predict loss = 0.15 (73.8 examples/sec; 0.054 sec/batch; 90h:07m:16s remains)
INFO - root - 2019-11-04 03:43:23.687583: step 10250, total loss = 0.48, predict loss = 0.11 (73.9 examples/sec; 0.054 sec/batch; 90h:01m:44s remains)
INFO - root - 2019-11-04 03:43:24.278330: step 10260, total loss = 0.55, predict loss = 0.13 (76.4 examples/sec; 0.052 sec/batch; 87h:04m:41s remains)
INFO - root - 2019-11-04 03:43:24.893939: step 10270, total loss = 0.58, predict loss = 0.13 (73.8 examples/sec; 0.054 sec/batch; 90h:10m:25s remains)
INFO - root - 2019-11-04 03:43:25.495850: step 10280, total loss = 0.47, predict loss = 0.12 (69.9 examples/sec; 0.057 sec/batch; 95h:10m:06s remains)
INFO - root - 2019-11-04 03:43:26.091741: step 10290, total loss = 0.53, predict loss = 0.12 (74.3 examples/sec; 0.054 sec/batch; 89h:37m:25s remains)
INFO - root - 2019-11-04 03:43:26.669764: step 10300, total loss = 0.41, predict loss = 0.09 (73.6 examples/sec; 0.054 sec/batch; 90h:26m:58s remains)
INFO - root - 2019-11-04 03:43:27.272018: step 10310, total loss = 0.48, predict loss = 0.11 (74.5 examples/sec; 0.054 sec/batch; 89h:22m:31s remains)
INFO - root - 2019-11-04 03:43:27.874518: step 10320, total loss = 0.65, predict loss = 0.15 (76.3 examples/sec; 0.052 sec/batch; 87h:11m:27s remains)
INFO - root - 2019-11-04 03:43:28.461803: step 10330, total loss = 0.64, predict loss = 0.15 (78.4 examples/sec; 0.051 sec/batch; 84h:52m:19s remains)
INFO - root - 2019-11-04 03:43:29.060506: step 10340, total loss = 0.37, predict loss = 0.09 (76.8 examples/sec; 0.052 sec/batch; 86h:41m:30s remains)
INFO - root - 2019-11-04 03:43:29.661972: step 10350, total loss = 0.41, predict loss = 0.09 (80.8 examples/sec; 0.050 sec/batch; 82h:23m:36s remains)
INFO - root - 2019-11-04 03:43:30.261049: step 10360, total loss = 0.59, predict loss = 0.14 (79.9 examples/sec; 0.050 sec/batch; 83h:18m:35s remains)
INFO - root - 2019-11-04 03:43:30.856171: step 10370, total loss = 0.60, predict loss = 0.13 (77.1 examples/sec; 0.052 sec/batch; 86h:16m:57s remains)
INFO - root - 2019-11-04 03:43:31.466931: step 10380, total loss = 0.38, predict loss = 0.08 (76.3 examples/sec; 0.052 sec/batch; 87h:11m:35s remains)
INFO - root - 2019-11-04 03:43:32.120661: step 10390, total loss = 0.57, predict loss = 0.14 (83.8 examples/sec; 0.048 sec/batch; 79h:27m:16s remains)
INFO - root - 2019-11-04 03:43:32.684949: step 10400, total loss = 0.66, predict loss = 0.14 (73.3 examples/sec; 0.055 sec/batch; 90h:46m:43s remains)
INFO - root - 2019-11-04 03:43:33.284023: step 10410, total loss = 0.56, predict loss = 0.13 (76.3 examples/sec; 0.052 sec/batch; 87h:11m:48s remains)
INFO - root - 2019-11-04 03:43:33.823418: step 10420, total loss = 0.47, predict loss = 0.10 (84.6 examples/sec; 0.047 sec/batch; 78h:38m:27s remains)
INFO - root - 2019-11-04 03:43:34.349667: step 10430, total loss = 0.50, predict loss = 0.11 (89.3 examples/sec; 0.045 sec/batch; 74h:32m:25s remains)
INFO - root - 2019-11-04 03:43:34.863583: step 10440, total loss = 0.51, predict loss = 0.11 (87.5 examples/sec; 0.046 sec/batch; 76h:04m:13s remains)
INFO - root - 2019-11-04 03:43:35.372464: step 10450, total loss = 0.48, predict loss = 0.11 (88.4 examples/sec; 0.045 sec/batch; 75h:16m:29s remains)
INFO - root - 2019-11-04 03:43:35.900279: step 10460, total loss = 0.47, predict loss = 0.10 (77.9 examples/sec; 0.051 sec/batch; 85h:24m:46s remains)
INFO - root - 2019-11-04 03:43:36.448909: step 10470, total loss = 0.48, predict loss = 0.12 (86.3 examples/sec; 0.046 sec/batch; 77h:07m:17s remains)
INFO - root - 2019-11-04 03:43:36.987372: step 10480, total loss = 0.53, predict loss = 0.13 (82.4 examples/sec; 0.049 sec/batch; 80h:44m:10s remains)
INFO - root - 2019-11-04 03:43:37.530392: step 10490, total loss = 0.64, predict loss = 0.13 (83.0 examples/sec; 0.048 sec/batch; 80h:09m:48s remains)
INFO - root - 2019-11-04 03:43:38.069787: step 10500, total loss = 0.50, predict loss = 0.12 (84.4 examples/sec; 0.047 sec/batch; 78h:49m:23s remains)
INFO - root - 2019-11-04 03:43:38.597464: step 10510, total loss = 0.38, predict loss = 0.09 (84.2 examples/sec; 0.047 sec/batch; 79h:01m:10s remains)
INFO - root - 2019-11-04 03:43:39.146043: step 10520, total loss = 0.43, predict loss = 0.09 (82.2 examples/sec; 0.049 sec/batch; 80h:59m:16s remains)
INFO - root - 2019-11-04 03:43:39.674102: step 10530, total loss = 0.61, predict loss = 0.14 (83.9 examples/sec; 0.048 sec/batch; 79h:19m:38s remains)
INFO - root - 2019-11-04 03:43:40.234858: step 10540, total loss = 0.53, predict loss = 0.12 (75.4 examples/sec; 0.053 sec/batch; 88h:18m:41s remains)
INFO - root - 2019-11-04 03:43:40.843827: step 10550, total loss = 0.57, predict loss = 0.13 (77.2 examples/sec; 0.052 sec/batch; 86h:11m:17s remains)
INFO - root - 2019-11-04 03:43:41.451126: step 10560, total loss = 0.57, predict loss = 0.14 (77.8 examples/sec; 0.051 sec/batch; 85h:30m:39s remains)
INFO - root - 2019-11-04 03:43:42.067082: step 10570, total loss = 0.57, predict loss = 0.13 (73.5 examples/sec; 0.054 sec/batch; 90h:32m:13s remains)
INFO - root - 2019-11-04 03:43:42.666942: step 10580, total loss = 0.39, predict loss = 0.08 (79.6 examples/sec; 0.050 sec/batch; 83h:39m:17s remains)
INFO - root - 2019-11-04 03:43:43.274081: step 10590, total loss = 0.41, predict loss = 0.09 (72.5 examples/sec; 0.055 sec/batch; 91h:50m:41s remains)
INFO - root - 2019-11-04 03:43:43.876685: step 10600, total loss = 0.50, predict loss = 0.12 (84.2 examples/sec; 0.048 sec/batch; 79h:04m:48s remains)
INFO - root - 2019-11-04 03:43:44.505728: step 10610, total loss = 0.55, predict loss = 0.14 (68.9 examples/sec; 0.058 sec/batch; 96h:32m:12s remains)
INFO - root - 2019-11-04 03:43:45.153967: step 10620, total loss = 0.36, predict loss = 0.08 (72.1 examples/sec; 0.055 sec/batch; 92h:16m:49s remains)
INFO - root - 2019-11-04 03:43:45.798392: step 10630, total loss = 0.52, predict loss = 0.11 (68.5 examples/sec; 0.058 sec/batch; 97h:10m:05s remains)
INFO - root - 2019-11-04 03:43:46.380728: step 10640, total loss = 0.54, predict loss = 0.12 (75.9 examples/sec; 0.053 sec/batch; 87h:40m:10s remains)
INFO - root - 2019-11-04 03:43:46.940142: step 10650, total loss = 0.80, predict loss = 0.19 (82.5 examples/sec; 0.049 sec/batch; 80h:41m:26s remains)
INFO - root - 2019-11-04 03:43:47.524395: step 10660, total loss = 0.63, predict loss = 0.15 (71.7 examples/sec; 0.056 sec/batch; 92h:46m:43s remains)
INFO - root - 2019-11-04 03:43:48.145948: step 10670, total loss = 0.49, predict loss = 0.12 (72.0 examples/sec; 0.056 sec/batch; 92h:24m:13s remains)
INFO - root - 2019-11-04 03:43:48.764310: step 10680, total loss = 0.48, predict loss = 0.11 (75.6 examples/sec; 0.053 sec/batch; 87h:59m:46s remains)
INFO - root - 2019-11-04 03:43:49.379401: step 10690, total loss = 0.58, predict loss = 0.13 (71.1 examples/sec; 0.056 sec/batch; 93h:36m:13s remains)
INFO - root - 2019-11-04 03:43:49.990173: step 10700, total loss = 0.53, predict loss = 0.13 (74.2 examples/sec; 0.054 sec/batch; 89h:38m:23s remains)
INFO - root - 2019-11-04 03:43:50.604124: step 10710, total loss = 0.48, predict loss = 0.10 (68.1 examples/sec; 0.059 sec/batch; 97h:43m:13s remains)
INFO - root - 2019-11-04 03:43:51.202208: step 10720, total loss = 0.69, predict loss = 0.17 (76.1 examples/sec; 0.053 sec/batch; 87h:25m:07s remains)
INFO - root - 2019-11-04 03:43:51.823000: step 10730, total loss = 0.71, predict loss = 0.16 (74.6 examples/sec; 0.054 sec/batch; 89h:12m:32s remains)
INFO - root - 2019-11-04 03:43:52.428237: step 10740, total loss = 0.76, predict loss = 0.19 (74.2 examples/sec; 0.054 sec/batch; 89h:43m:36s remains)
INFO - root - 2019-11-04 03:43:53.034917: step 10750, total loss = 0.50, predict loss = 0.12 (71.8 examples/sec; 0.056 sec/batch; 92h:42m:38s remains)
INFO - root - 2019-11-04 03:43:53.665026: step 10760, total loss = 0.54, predict loss = 0.13 (75.7 examples/sec; 0.053 sec/batch; 87h:51m:17s remains)
INFO - root - 2019-11-04 03:43:54.273397: step 10770, total loss = 0.36, predict loss = 0.09 (71.1 examples/sec; 0.056 sec/batch; 93h:32m:06s remains)
INFO - root - 2019-11-04 03:43:54.888157: step 10780, total loss = 0.27, predict loss = 0.06 (73.9 examples/sec; 0.054 sec/batch; 90h:00m:42s remains)
INFO - root - 2019-11-04 03:43:55.491894: step 10790, total loss = 0.27, predict loss = 0.06 (72.8 examples/sec; 0.055 sec/batch; 91h:24m:25s remains)
INFO - root - 2019-11-04 03:43:56.103840: step 10800, total loss = 0.43, predict loss = 0.09 (73.6 examples/sec; 0.054 sec/batch; 90h:23m:13s remains)
INFO - root - 2019-11-04 03:43:56.718228: step 10810, total loss = 0.41, predict loss = 0.09 (72.3 examples/sec; 0.055 sec/batch; 91h:59m:12s remains)
INFO - root - 2019-11-04 03:43:57.322819: step 10820, total loss = 0.38, predict loss = 0.09 (71.9 examples/sec; 0.056 sec/batch; 92h:34m:00s remains)
INFO - root - 2019-11-04 03:43:57.940005: step 10830, total loss = 0.43, predict loss = 0.11 (70.1 examples/sec; 0.057 sec/batch; 94h:57m:20s remains)
INFO - root - 2019-11-04 03:43:58.569889: step 10840, total loss = 0.42, predict loss = 0.09 (71.7 examples/sec; 0.056 sec/batch; 92h:45m:33s remains)
INFO - root - 2019-11-04 03:43:59.173336: step 10850, total loss = 0.54, predict loss = 0.11 (75.2 examples/sec; 0.053 sec/batch; 88h:27m:44s remains)
INFO - root - 2019-11-04 03:43:59.792333: step 10860, total loss = 0.40, predict loss = 0.09 (76.1 examples/sec; 0.053 sec/batch; 87h:29m:06s remains)
INFO - root - 2019-11-04 03:44:00.407898: step 10870, total loss = 0.58, predict loss = 0.12 (70.9 examples/sec; 0.056 sec/batch; 93h:47m:48s remains)
INFO - root - 2019-11-04 03:44:01.022047: step 10880, total loss = 0.44, predict loss = 0.09 (73.5 examples/sec; 0.054 sec/batch; 90h:33m:54s remains)
INFO - root - 2019-11-04 03:44:01.554402: step 10890, total loss = 0.58, predict loss = 0.14 (92.3 examples/sec; 0.043 sec/batch; 72h:05m:39s remains)
INFO - root - 2019-11-04 03:44:02.014456: step 10900, total loss = 0.32, predict loss = 0.06 (108.2 examples/sec; 0.037 sec/batch; 61h:30m:22s remains)
INFO - root - 2019-11-04 03:44:02.750056: step 10910, total loss = 0.32, predict loss = 0.06 (91.1 examples/sec; 0.044 sec/batch; 73h:01m:49s remains)
INFO - root - 2019-11-04 03:44:03.374382: step 10920, total loss = 0.32, predict loss = 0.07 (66.6 examples/sec; 0.060 sec/batch; 99h:51m:47s remains)
INFO - root - 2019-11-04 03:44:03.991992: step 10930, total loss = 0.40, predict loss = 0.09 (71.3 examples/sec; 0.056 sec/batch; 93h:17m:43s remains)
INFO - root - 2019-11-04 03:44:04.600924: step 10940, total loss = 0.29, predict loss = 0.05 (74.2 examples/sec; 0.054 sec/batch; 89h:39m:23s remains)
INFO - root - 2019-11-04 03:44:05.208013: step 10950, total loss = 0.42, predict loss = 0.09 (73.1 examples/sec; 0.055 sec/batch; 91h:00m:57s remains)
INFO - root - 2019-11-04 03:44:05.812002: step 10960, total loss = 0.31, predict loss = 0.07 (75.8 examples/sec; 0.053 sec/batch; 87h:50m:32s remains)
INFO - root - 2019-11-04 03:44:06.337592: step 10970, total loss = 0.48, predict loss = 0.12 (95.0 examples/sec; 0.042 sec/batch; 70h:02m:43s remains)
INFO - root - 2019-11-04 03:44:06.843501: step 10980, total loss = 0.40, predict loss = 0.08 (84.8 examples/sec; 0.047 sec/batch; 78h:30m:41s remains)
INFO - root - 2019-11-04 03:44:07.336088: step 10990, total loss = 0.40, predict loss = 0.10 (90.0 examples/sec; 0.044 sec/batch; 73h:58m:00s remains)
INFO - root - 2019-11-04 03:44:07.838656: step 11000, total loss = 0.48, predict loss = 0.11 (90.1 examples/sec; 0.044 sec/batch; 73h:53m:37s remains)
INFO - root - 2019-11-04 03:44:08.329316: step 11010, total loss = 0.42, predict loss = 0.10 (87.8 examples/sec; 0.046 sec/batch; 75h:48m:04s remains)
INFO - root - 2019-11-04 03:44:08.826045: step 11020, total loss = 0.64, predict loss = 0.13 (83.4 examples/sec; 0.048 sec/batch; 79h:49m:11s remains)
INFO - root - 2019-11-04 03:44:09.317127: step 11030, total loss = 0.59, predict loss = 0.08 (92.2 examples/sec; 0.043 sec/batch; 72h:08m:23s remains)
INFO - root - 2019-11-04 03:44:09.827977: step 11040, total loss = 0.38, predict loss = 0.06 (83.0 examples/sec; 0.048 sec/batch; 80h:07m:47s remains)
INFO - root - 2019-11-04 03:44:10.334354: step 11050, total loss = 0.54, predict loss = 0.10 (84.8 examples/sec; 0.047 sec/batch; 78h:30m:56s remains)
INFO - root - 2019-11-04 03:44:10.844635: step 11060, total loss = 0.33, predict loss = 0.07 (87.6 examples/sec; 0.046 sec/batch; 75h:56m:30s remains)
INFO - root - 2019-11-04 03:44:11.338681: step 11070, total loss = 0.43, predict loss = 0.10 (86.4 examples/sec; 0.046 sec/batch; 77h:03m:15s remains)
INFO - root - 2019-11-04 03:44:11.842887: step 11080, total loss = 0.45, predict loss = 0.11 (87.9 examples/sec; 0.045 sec/batch; 75h:41m:20s remains)
INFO - root - 2019-11-04 03:44:12.355514: step 11090, total loss = 0.47, predict loss = 0.11 (89.9 examples/sec; 0.045 sec/batch; 74h:02m:01s remains)
INFO - root - 2019-11-04 03:44:12.874335: step 11100, total loss = 0.39, predict loss = 0.09 (90.8 examples/sec; 0.044 sec/batch; 73h:16m:58s remains)
INFO - root - 2019-11-04 03:44:13.383101: step 11110, total loss = 0.37, predict loss = 0.09 (84.9 examples/sec; 0.047 sec/batch; 78h:22m:04s remains)
INFO - root - 2019-11-04 03:44:13.914602: step 11120, total loss = 0.36, predict loss = 0.07 (81.2 examples/sec; 0.049 sec/batch; 81h:55m:43s remains)
INFO - root - 2019-11-04 03:44:14.440837: step 11130, total loss = 0.40, predict loss = 0.10 (89.5 examples/sec; 0.045 sec/batch; 74h:22m:46s remains)
INFO - root - 2019-11-04 03:44:14.956725: step 11140, total loss = 0.41, predict loss = 0.08 (86.8 examples/sec; 0.046 sec/batch; 76h:41m:41s remains)
INFO - root - 2019-11-04 03:44:15.485533: step 11150, total loss = 0.72, predict loss = 0.16 (83.2 examples/sec; 0.048 sec/batch; 80h:01m:26s remains)
INFO - root - 2019-11-04 03:44:16.004028: step 11160, total loss = 0.47, predict loss = 0.11 (87.5 examples/sec; 0.046 sec/batch; 76h:03m:23s remains)
INFO - root - 2019-11-04 03:44:16.524241: step 11170, total loss = 0.44, predict loss = 0.10 (83.2 examples/sec; 0.048 sec/batch; 79h:58m:24s remains)
INFO - root - 2019-11-04 03:44:17.052009: step 11180, total loss = 0.68, predict loss = 0.16 (85.7 examples/sec; 0.047 sec/batch; 77h:36m:58s remains)
INFO - root - 2019-11-04 03:44:17.572319: step 11190, total loss = 0.43, predict loss = 0.08 (80.8 examples/sec; 0.050 sec/batch; 82h:22m:00s remains)
INFO - root - 2019-11-04 03:44:18.100940: step 11200, total loss = 0.38, predict loss = 0.08 (85.7 examples/sec; 0.047 sec/batch; 77h:38m:31s remains)
INFO - root - 2019-11-04 03:44:18.617657: step 11210, total loss = 0.65, predict loss = 0.12 (81.9 examples/sec; 0.049 sec/batch; 81h:11m:57s remains)
INFO - root - 2019-11-04 03:44:19.148111: step 11220, total loss = 0.53, predict loss = 0.12 (84.2 examples/sec; 0.048 sec/batch; 79h:02m:32s remains)
INFO - root - 2019-11-04 03:44:19.666024: step 11230, total loss = 0.50, predict loss = 0.11 (80.5 examples/sec; 0.050 sec/batch; 82h:37m:54s remains)
INFO - root - 2019-11-04 03:44:20.204029: step 11240, total loss = 0.50, predict loss = 0.11 (81.5 examples/sec; 0.049 sec/batch; 81h:39m:07s remains)
INFO - root - 2019-11-04 03:44:20.753921: step 11250, total loss = 0.50, predict loss = 0.12 (89.1 examples/sec; 0.045 sec/batch; 74h:43m:14s remains)
INFO - root - 2019-11-04 03:44:21.296640: step 11260, total loss = 0.58, predict loss = 0.12 (81.8 examples/sec; 0.049 sec/batch; 81h:23m:35s remains)
INFO - root - 2019-11-04 03:44:21.837653: step 11270, total loss = 0.90, predict loss = 0.21 (81.7 examples/sec; 0.049 sec/batch; 81h:28m:56s remains)
INFO - root - 2019-11-04 03:44:22.391831: step 11280, total loss = 0.35, predict loss = 0.06 (78.7 examples/sec; 0.051 sec/batch; 84h:31m:16s remains)
INFO - root - 2019-11-04 03:44:22.931263: step 11290, total loss = 0.32, predict loss = 0.06 (83.8 examples/sec; 0.048 sec/batch; 79h:22m:50s remains)
INFO - root - 2019-11-04 03:44:23.472400: step 11300, total loss = 0.35, predict loss = 0.07 (80.8 examples/sec; 0.050 sec/batch; 82h:22m:10s remains)
INFO - root - 2019-11-04 03:44:24.007334: step 11310, total loss = 0.33, predict loss = 0.07 (88.2 examples/sec; 0.045 sec/batch; 75h:29m:01s remains)
INFO - root - 2019-11-04 03:44:24.565340: step 11320, total loss = 0.42, predict loss = 0.09 (80.7 examples/sec; 0.050 sec/batch; 82h:24m:52s remains)
INFO - root - 2019-11-04 03:44:25.097986: step 11330, total loss = 0.47, predict loss = 0.09 (81.1 examples/sec; 0.049 sec/batch; 82h:01m:19s remains)
INFO - root - 2019-11-04 03:44:25.643318: step 11340, total loss = 0.49, predict loss = 0.12 (83.9 examples/sec; 0.048 sec/batch; 79h:21m:05s remains)
INFO - root - 2019-11-04 03:44:26.189306: step 11350, total loss = 0.29, predict loss = 0.07 (81.7 examples/sec; 0.049 sec/batch; 81h:29m:14s remains)
INFO - root - 2019-11-04 03:44:26.730257: step 11360, total loss = 0.36, predict loss = 0.08 (81.6 examples/sec; 0.049 sec/batch; 81h:34m:26s remains)
INFO - root - 2019-11-04 03:44:27.288521: step 11370, total loss = 0.48, predict loss = 0.11 (78.9 examples/sec; 0.051 sec/batch; 84h:20m:41s remains)
INFO - root - 2019-11-04 03:44:27.837815: step 11380, total loss = 0.36, predict loss = 0.08 (84.3 examples/sec; 0.047 sec/batch; 78h:55m:34s remains)
INFO - root - 2019-11-04 03:44:28.402939: step 11390, total loss = 0.41, predict loss = 0.07 (78.3 examples/sec; 0.051 sec/batch; 85h:01m:49s remains)
INFO - root - 2019-11-04 03:44:28.956287: step 11400, total loss = 0.42, predict loss = 0.09 (79.3 examples/sec; 0.050 sec/batch; 83h:53m:14s remains)
INFO - root - 2019-11-04 03:44:29.536897: step 11410, total loss = 0.50, predict loss = 0.10 (81.7 examples/sec; 0.049 sec/batch; 81h:23m:39s remains)
INFO - root - 2019-11-04 03:44:30.122102: step 11420, total loss = 0.36, predict loss = 0.07 (81.2 examples/sec; 0.049 sec/batch; 81h:54m:24s remains)
INFO - root - 2019-11-04 03:44:30.719239: step 11430, total loss = 0.40, predict loss = 0.08 (84.0 examples/sec; 0.048 sec/batch; 79h:11m:18s remains)
INFO - root - 2019-11-04 03:44:31.324801: step 11440, total loss = 0.52, predict loss = 0.10 (76.0 examples/sec; 0.053 sec/batch; 87h:30m:31s remains)
INFO - root - 2019-11-04 03:44:31.991385: step 11450, total loss = 0.43, predict loss = 0.08 (66.9 examples/sec; 0.060 sec/batch; 99h:27m:17s remains)
INFO - root - 2019-11-04 03:44:32.505049: step 11460, total loss = 0.41, predict loss = 0.09 (79.6 examples/sec; 0.050 sec/batch; 83h:33m:25s remains)
INFO - root - 2019-11-04 03:44:33.090858: step 11470, total loss = 0.29, predict loss = 0.06 (75.1 examples/sec; 0.053 sec/batch; 88h:35m:36s remains)
INFO - root - 2019-11-04 03:44:33.679275: step 11480, total loss = 0.54, predict loss = 0.12 (78.1 examples/sec; 0.051 sec/batch; 85h:08m:51s remains)
INFO - root - 2019-11-04 03:44:34.260007: step 11490, total loss = 0.41, predict loss = 0.11 (72.8 examples/sec; 0.055 sec/batch; 91h:26m:27s remains)
INFO - root - 2019-11-04 03:44:34.870670: step 11500, total loss = 0.33, predict loss = 0.07 (73.8 examples/sec; 0.054 sec/batch; 90h:08m:09s remains)
INFO - root - 2019-11-04 03:44:35.476316: step 11510, total loss = 0.34, predict loss = 0.07 (76.3 examples/sec; 0.052 sec/batch; 87h:11m:34s remains)
INFO - root - 2019-11-04 03:44:36.066255: step 11520, total loss = 0.37, predict loss = 0.08 (76.9 examples/sec; 0.052 sec/batch; 86h:34m:05s remains)
INFO - root - 2019-11-04 03:44:36.667818: step 11530, total loss = 0.31, predict loss = 0.05 (73.5 examples/sec; 0.054 sec/batch; 90h:33m:55s remains)
INFO - root - 2019-11-04 03:44:37.260227: step 11540, total loss = 0.31, predict loss = 0.07 (77.0 examples/sec; 0.052 sec/batch; 86h:23m:37s remains)
INFO - root - 2019-11-04 03:44:37.856339: step 11550, total loss = 0.35, predict loss = 0.07 (74.9 examples/sec; 0.053 sec/batch; 88h:51m:19s remains)
INFO - root - 2019-11-04 03:44:38.449255: step 11560, total loss = 0.30, predict loss = 0.06 (78.7 examples/sec; 0.051 sec/batch; 84h:32m:11s remains)
INFO - root - 2019-11-04 03:44:39.046472: step 11570, total loss = 0.28, predict loss = 0.06 (77.1 examples/sec; 0.052 sec/batch; 86h:20m:13s remains)
INFO - root - 2019-11-04 03:44:39.645968: step 11580, total loss = 0.41, predict loss = 0.09 (71.5 examples/sec; 0.056 sec/batch; 93h:00m:06s remains)
INFO - root - 2019-11-04 03:44:40.216656: step 11590, total loss = 0.32, predict loss = 0.06 (82.4 examples/sec; 0.049 sec/batch; 80h:46m:15s remains)
INFO - root - 2019-11-04 03:44:40.811833: step 11600, total loss = 0.38, predict loss = 0.09 (70.9 examples/sec; 0.056 sec/batch; 93h:52m:23s remains)
INFO - root - 2019-11-04 03:44:41.427669: step 11610, total loss = 0.38, predict loss = 0.08 (79.6 examples/sec; 0.050 sec/batch; 83h:38m:32s remains)
INFO - root - 2019-11-04 03:44:42.066712: step 11620, total loss = 0.51, predict loss = 0.11 (70.5 examples/sec; 0.057 sec/batch; 94h:23m:40s remains)
INFO - root - 2019-11-04 03:44:42.684181: step 11630, total loss = 0.35, predict loss = 0.09 (73.6 examples/sec; 0.054 sec/batch; 90h:21m:38s remains)
INFO - root - 2019-11-04 03:44:43.310785: step 11640, total loss = 0.27, predict loss = 0.05 (74.1 examples/sec; 0.054 sec/batch; 89h:47m:56s remains)
INFO - root - 2019-11-04 03:44:43.931505: step 11650, total loss = 0.41, predict loss = 0.09 (75.8 examples/sec; 0.053 sec/batch; 87h:49m:03s remains)
INFO - root - 2019-11-04 03:44:44.552052: step 11660, total loss = 0.32, predict loss = 0.07 (72.0 examples/sec; 0.056 sec/batch; 92h:28m:31s remains)
INFO - root - 2019-11-04 03:44:45.179972: step 11670, total loss = 0.42, predict loss = 0.10 (71.3 examples/sec; 0.056 sec/batch; 93h:15m:37s remains)
INFO - root - 2019-11-04 03:44:45.796131: step 11680, total loss = 0.32, predict loss = 0.07 (78.5 examples/sec; 0.051 sec/batch; 84h:44m:19s remains)
INFO - root - 2019-11-04 03:44:46.410758: step 11690, total loss = 0.29, predict loss = 0.07 (70.7 examples/sec; 0.057 sec/batch; 94h:09m:36s remains)
INFO - root - 2019-11-04 03:44:47.042235: step 11700, total loss = 0.34, predict loss = 0.07 (73.8 examples/sec; 0.054 sec/batch; 90h:12m:51s remains)
INFO - root - 2019-11-04 03:44:47.682676: step 11710, total loss = 0.47, predict loss = 0.12 (68.9 examples/sec; 0.058 sec/batch; 96h:35m:35s remains)
INFO - root - 2019-11-04 03:44:48.295706: step 11720, total loss = 0.48, predict loss = 0.10 (73.1 examples/sec; 0.055 sec/batch; 90h:58m:08s remains)
INFO - root - 2019-11-04 03:44:48.904803: step 11730, total loss = 0.32, predict loss = 0.07 (74.1 examples/sec; 0.054 sec/batch; 89h:46m:04s remains)
INFO - root - 2019-11-04 03:44:49.475697: step 11740, total loss = 0.38, predict loss = 0.08 (85.5 examples/sec; 0.047 sec/batch; 77h:51m:47s remains)
INFO - root - 2019-11-04 03:44:50.021461: step 11750, total loss = 0.36, predict loss = 0.08 (75.0 examples/sec; 0.053 sec/batch; 88h:40m:30s remains)
INFO - root - 2019-11-04 03:44:50.591842: step 11760, total loss = 0.20, predict loss = 0.04 (74.1 examples/sec; 0.054 sec/batch; 89h:49m:48s remains)
INFO - root - 2019-11-04 03:44:51.166706: step 11770, total loss = 0.32, predict loss = 0.07 (79.6 examples/sec; 0.050 sec/batch; 83h:33m:53s remains)
INFO - root - 2019-11-04 03:44:51.737229: step 11780, total loss = 0.35, predict loss = 0.07 (77.0 examples/sec; 0.052 sec/batch; 86h:23m:57s remains)
INFO - root - 2019-11-04 03:44:52.304600: step 11790, total loss = 0.23, predict loss = 0.04 (81.6 examples/sec; 0.049 sec/batch; 81h:31m:20s remains)
INFO - root - 2019-11-04 03:44:52.866464: step 11800, total loss = 0.39, predict loss = 0.09 (81.9 examples/sec; 0.049 sec/batch; 81h:14m:01s remains)
INFO - root - 2019-11-04 03:44:53.444014: step 11810, total loss = 0.41, predict loss = 0.10 (79.5 examples/sec; 0.050 sec/batch; 83h:42m:05s remains)
INFO - root - 2019-11-04 03:44:54.010997: step 11820, total loss = 0.42, predict loss = 0.09 (84.0 examples/sec; 0.048 sec/batch; 79h:12m:40s remains)
INFO - root - 2019-11-04 03:44:54.578726: step 11830, total loss = 0.59, predict loss = 0.16 (79.6 examples/sec; 0.050 sec/batch; 83h:32m:10s remains)
INFO - root - 2019-11-04 03:44:55.144507: step 11840, total loss = 0.31, predict loss = 0.07 (79.5 examples/sec; 0.050 sec/batch; 83h:42m:20s remains)
INFO - root - 2019-11-04 03:44:55.697983: step 11850, total loss = 0.41, predict loss = 0.09 (76.9 examples/sec; 0.052 sec/batch; 86h:30m:54s remains)
INFO - root - 2019-11-04 03:44:56.255493: step 11860, total loss = 0.30, predict loss = 0.06 (79.6 examples/sec; 0.050 sec/batch; 83h:37m:52s remains)
INFO - root - 2019-11-04 03:44:56.817402: step 11870, total loss = 0.29, predict loss = 0.06 (83.3 examples/sec; 0.048 sec/batch; 79h:51m:09s remains)
INFO - root - 2019-11-04 03:44:57.374665: step 11880, total loss = 0.33, predict loss = 0.06 (77.2 examples/sec; 0.052 sec/batch; 86h:12m:16s remains)
INFO - root - 2019-11-04 03:44:57.935018: step 11890, total loss = 0.50, predict loss = 0.10 (79.4 examples/sec; 0.050 sec/batch; 83h:49m:33s remains)
INFO - root - 2019-11-04 03:44:58.508414: step 11900, total loss = 0.35, predict loss = 0.08 (77.8 examples/sec; 0.051 sec/batch; 85h:33m:19s remains)
INFO - root - 2019-11-04 03:44:59.073697: step 11910, total loss = 0.37, predict loss = 0.08 (76.8 examples/sec; 0.052 sec/batch; 86h:35m:26s remains)
INFO - root - 2019-11-04 03:44:59.652028: step 11920, total loss = 0.37, predict loss = 0.08 (75.5 examples/sec; 0.053 sec/batch; 88h:10m:58s remains)
INFO - root - 2019-11-04 03:45:00.218876: step 11930, total loss = 0.39, predict loss = 0.09 (76.8 examples/sec; 0.052 sec/batch; 86h:36m:03s remains)
INFO - root - 2019-11-04 03:45:00.778719: step 11940, total loss = 0.25, predict loss = 0.05 (76.0 examples/sec; 0.053 sec/batch; 87h:29m:45s remains)
INFO - root - 2019-11-04 03:45:01.344711: step 11950, total loss = 0.38, predict loss = 0.10 (82.7 examples/sec; 0.048 sec/batch; 80h:24m:22s remains)
INFO - root - 2019-11-04 03:45:01.975616: step 11960, total loss = 0.54, predict loss = 0.13 (75.6 examples/sec; 0.053 sec/batch; 88h:02m:14s remains)
INFO - root - 2019-11-04 03:45:02.477421: step 11970, total loss = 0.33, predict loss = 0.06 (90.3 examples/sec; 0.044 sec/batch; 73h:41m:58s remains)
INFO - root - 2019-11-04 03:45:02.969389: step 11980, total loss = 0.31, predict loss = 0.06 (86.9 examples/sec; 0.046 sec/batch; 76h:33m:01s remains)
INFO - root - 2019-11-04 03:45:03.454321: step 11990, total loss = 0.25, predict loss = 0.04 (92.6 examples/sec; 0.043 sec/batch; 71h:50m:23s remains)
INFO - root - 2019-11-04 03:45:03.949088: step 12000, total loss = 0.18, predict loss = 0.04 (88.6 examples/sec; 0.045 sec/batch; 75h:07m:11s remains)
INFO - root - 2019-11-04 03:45:04.433869: step 12010, total loss = 0.26, predict loss = 0.05 (93.0 examples/sec; 0.043 sec/batch; 71h:32m:40s remains)
INFO - root - 2019-11-04 03:45:04.930935: step 12020, total loss = 0.38, predict loss = 0.08 (88.0 examples/sec; 0.045 sec/batch; 75h:38m:36s remains)
INFO - root - 2019-11-04 03:45:05.431304: step 12030, total loss = 0.27, predict loss = 0.06 (84.7 examples/sec; 0.047 sec/batch; 78h:32m:11s remains)
INFO - root - 2019-11-04 03:45:05.936418: step 12040, total loss = 0.49, predict loss = 0.09 (90.2 examples/sec; 0.044 sec/batch; 73h:47m:43s remains)
INFO - root - 2019-11-04 03:45:06.431030: step 12050, total loss = 0.24, predict loss = 0.05 (87.4 examples/sec; 0.046 sec/batch; 76h:07m:40s remains)
INFO - root - 2019-11-04 03:45:06.913282: step 12060, total loss = 0.58, predict loss = 0.15 (88.7 examples/sec; 0.045 sec/batch; 74h:58m:31s remains)
INFO - root - 2019-11-04 03:45:07.403605: step 12070, total loss = 0.41, predict loss = 0.10 (92.1 examples/sec; 0.043 sec/batch; 72h:16m:17s remains)
INFO - root - 2019-11-04 03:45:07.893006: step 12080, total loss = 0.35, predict loss = 0.07 (87.3 examples/sec; 0.046 sec/batch; 76h:13m:25s remains)
INFO - root - 2019-11-04 03:45:08.389703: step 12090, total loss = 0.30, predict loss = 0.07 (88.4 examples/sec; 0.045 sec/batch; 75h:16m:29s remains)
INFO - root - 2019-11-04 03:45:08.898552: step 12100, total loss = 0.29, predict loss = 0.07 (81.9 examples/sec; 0.049 sec/batch; 81h:11m:19s remains)
INFO - root - 2019-11-04 03:45:09.394669: step 12110, total loss = 0.23, predict loss = 0.04 (91.1 examples/sec; 0.044 sec/batch; 73h:04m:18s remains)
INFO - root - 2019-11-04 03:45:09.896966: step 12120, total loss = 0.26, predict loss = 0.06 (88.4 examples/sec; 0.045 sec/batch; 75h:17m:04s remains)
INFO - root - 2019-11-04 03:45:10.393123: step 12130, total loss = 0.52, predict loss = 0.11 (85.1 examples/sec; 0.047 sec/batch; 78h:10m:48s remains)
INFO - root - 2019-11-04 03:45:10.886663: step 12140, total loss = 0.38, predict loss = 0.06 (88.6 examples/sec; 0.045 sec/batch; 75h:06m:29s remains)
INFO - root - 2019-11-04 03:45:11.377728: step 12150, total loss = 0.26, predict loss = 0.06 (89.7 examples/sec; 0.045 sec/batch; 74h:12m:13s remains)
INFO - root - 2019-11-04 03:45:11.878916: step 12160, total loss = 0.23, predict loss = 0.04 (90.5 examples/sec; 0.044 sec/batch; 73h:33m:14s remains)
INFO - root - 2019-11-04 03:45:12.380291: step 12170, total loss = 0.44, predict loss = 0.09 (93.1 examples/sec; 0.043 sec/batch; 71h:28m:16s remains)
INFO - root - 2019-11-04 03:45:12.875335: step 12180, total loss = 0.38, predict loss = 0.07 (88.7 examples/sec; 0.045 sec/batch; 75h:01m:56s remains)
INFO - root - 2019-11-04 03:45:13.373480: step 12190, total loss = 0.39, predict loss = 0.08 (87.3 examples/sec; 0.046 sec/batch; 76h:14m:41s remains)
INFO - root - 2019-11-04 03:45:13.872463: step 12200, total loss = 0.46, predict loss = 0.09 (85.2 examples/sec; 0.047 sec/batch; 78h:04m:00s remains)
INFO - root - 2019-11-04 03:45:14.368858: step 12210, total loss = 0.53, predict loss = 0.13 (87.8 examples/sec; 0.046 sec/batch; 75h:48m:32s remains)
INFO - root - 2019-11-04 03:45:14.866782: step 12220, total loss = 0.49, predict loss = 0.11 (87.1 examples/sec; 0.046 sec/batch; 76h:25m:13s remains)
INFO - root - 2019-11-04 03:45:15.357798: step 12230, total loss = 0.42, predict loss = 0.10 (88.9 examples/sec; 0.045 sec/batch; 74h:48m:43s remains)
INFO - root - 2019-11-04 03:45:15.850468: step 12240, total loss = 0.26, predict loss = 0.06 (88.2 examples/sec; 0.045 sec/batch; 75h:26m:16s remains)
INFO - root - 2019-11-04 03:45:16.347341: step 12250, total loss = 0.27, predict loss = 0.06 (91.3 examples/sec; 0.044 sec/batch; 72h:54m:01s remains)
INFO - root - 2019-11-04 03:45:16.838486: step 12260, total loss = 0.32, predict loss = 0.06 (95.8 examples/sec; 0.042 sec/batch; 69h:28m:26s remains)
INFO - root - 2019-11-04 03:45:17.334726: step 12270, total loss = 0.18, predict loss = 0.04 (83.8 examples/sec; 0.048 sec/batch; 79h:25m:48s remains)
INFO - root - 2019-11-04 03:45:17.831379: step 12280, total loss = 0.28, predict loss = 0.07 (88.8 examples/sec; 0.045 sec/batch; 74h:55m:14s remains)
INFO - root - 2019-11-04 03:45:18.336621: step 12290, total loss = 0.22, predict loss = 0.05 (90.9 examples/sec; 0.044 sec/batch; 73h:12m:24s remains)
INFO - root - 2019-11-04 03:45:18.830665: step 12300, total loss = 0.23, predict loss = 0.05 (84.6 examples/sec; 0.047 sec/batch; 78h:40m:54s remains)
INFO - root - 2019-11-04 03:45:19.332235: step 12310, total loss = 0.35, predict loss = 0.08 (91.3 examples/sec; 0.044 sec/batch; 72h:53m:54s remains)
INFO - root - 2019-11-04 03:45:19.838756: step 12320, total loss = 0.28, predict loss = 0.06 (93.5 examples/sec; 0.043 sec/batch; 71h:07m:35s remains)
INFO - root - 2019-11-04 03:45:20.352430: step 12330, total loss = 0.83, predict loss = 0.19 (86.6 examples/sec; 0.046 sec/batch; 76h:47m:14s remains)
INFO - root - 2019-11-04 03:45:20.874076: step 12340, total loss = 0.78, predict loss = 0.19 (81.2 examples/sec; 0.049 sec/batch; 81h:55m:32s remains)
INFO - root - 2019-11-04 03:45:21.392631: step 12350, total loss = 0.84, predict loss = 0.22 (86.2 examples/sec; 0.046 sec/batch; 77h:13m:24s remains)
INFO - root - 2019-11-04 03:45:21.904260: step 12360, total loss = 0.70, predict loss = 0.16 (82.7 examples/sec; 0.048 sec/batch; 80h:26m:32s remains)
INFO - root - 2019-11-04 03:45:22.430544: step 12370, total loss = 0.70, predict loss = 0.15 (82.7 examples/sec; 0.048 sec/batch; 80h:28m:06s remains)
INFO - root - 2019-11-04 03:45:22.959654: step 12380, total loss = 0.78, predict loss = 0.20 (84.9 examples/sec; 0.047 sec/batch; 78h:19m:08s remains)
INFO - root - 2019-11-04 03:45:23.488331: step 12390, total loss = 0.96, predict loss = 0.18 (93.0 examples/sec; 0.043 sec/batch; 71h:32m:49s remains)
INFO - root - 2019-11-04 03:45:24.012183: step 12400, total loss = 0.69, predict loss = 0.15 (89.9 examples/sec; 0.044 sec/batch; 73h:58m:23s remains)
INFO - root - 2019-11-04 03:45:24.536760: step 12410, total loss = 0.80, predict loss = 0.19 (86.4 examples/sec; 0.046 sec/batch; 76h:57m:26s remains)
INFO - root - 2019-11-04 03:45:25.063226: step 12420, total loss = 0.59, predict loss = 0.11 (89.9 examples/sec; 0.044 sec/batch; 74h:00m:27s remains)
INFO - root - 2019-11-04 03:45:25.587672: step 12430, total loss = 0.77, predict loss = 0.15 (88.5 examples/sec; 0.045 sec/batch; 75h:09m:21s remains)
INFO - root - 2019-11-04 03:45:26.122170: step 12440, total loss = 0.75, predict loss = 0.17 (78.9 examples/sec; 0.051 sec/batch; 84h:19m:33s remains)
INFO - root - 2019-11-04 03:45:26.639450: step 12450, total loss = 0.49, predict loss = 0.12 (87.7 examples/sec; 0.046 sec/batch; 75h:50m:23s remains)
INFO - root - 2019-11-04 03:45:27.159575: step 12460, total loss = 0.68, predict loss = 0.16 (79.9 examples/sec; 0.050 sec/batch; 83h:15m:05s remains)
INFO - root - 2019-11-04 03:45:27.703418: step 12470, total loss = 0.69, predict loss = 0.17 (83.0 examples/sec; 0.048 sec/batch; 80h:09m:06s remains)
INFO - root - 2019-11-04 03:45:28.249195: step 12480, total loss = 0.40, predict loss = 0.10 (77.2 examples/sec; 0.052 sec/batch; 86h:12m:46s remains)
INFO - root - 2019-11-04 03:45:28.792936: step 12490, total loss = 0.65, predict loss = 0.16 (82.9 examples/sec; 0.048 sec/batch; 80h:12m:47s remains)
INFO - root - 2019-11-04 03:45:29.337899: step 12500, total loss = 0.50, predict loss = 0.11 (80.6 examples/sec; 0.050 sec/batch; 82h:30m:16s remains)
INFO - root - 2019-11-04 03:45:29.881298: step 12510, total loss = 0.78, predict loss = 0.24 (83.7 examples/sec; 0.048 sec/batch; 79h:28m:15s remains)
INFO - root - 2019-11-04 03:45:30.427716: step 12520, total loss = 0.59, predict loss = 0.12 (87.8 examples/sec; 0.046 sec/batch; 75h:46m:07s remains)
INFO - root - 2019-11-04 03:45:30.992052: step 12530, total loss = 0.51, predict loss = 0.12 (79.1 examples/sec; 0.051 sec/batch; 84h:07m:39s remains)
INFO - root - 2019-11-04 03:45:31.558224: step 12540, total loss = 0.44, predict loss = 0.10 (80.2 examples/sec; 0.050 sec/batch; 82h:57m:44s remains)
INFO - root - 2019-11-04 03:45:32.232265: step 12550, total loss = 0.61, predict loss = 0.14 (73.8 examples/sec; 0.054 sec/batch; 90h:08m:10s remains)
INFO - root - 2019-11-04 03:45:32.831601: step 12560, total loss = 0.69, predict loss = 0.16 (70.9 examples/sec; 0.056 sec/batch; 93h:49m:49s remains)
INFO - root - 2019-11-04 03:45:33.436935: step 12570, total loss = 0.53, predict loss = 0.13 (80.5 examples/sec; 0.050 sec/batch; 82h:40m:08s remains)
INFO - root - 2019-11-04 03:45:34.034221: step 12580, total loss = 0.54, predict loss = 0.13 (82.4 examples/sec; 0.049 sec/batch; 80h:42m:54s remains)
INFO - root - 2019-11-04 03:45:34.637309: step 12590, total loss = 0.45, predict loss = 0.11 (74.9 examples/sec; 0.053 sec/batch; 88h:52m:02s remains)
INFO - root - 2019-11-04 03:45:35.237939: step 12600, total loss = 0.44, predict loss = 0.10 (73.4 examples/sec; 0.055 sec/batch; 90h:41m:23s remains)
INFO - root - 2019-11-04 03:45:35.838617: step 12610, total loss = 0.42, predict loss = 0.10 (77.6 examples/sec; 0.052 sec/batch; 85h:46m:57s remains)
INFO - root - 2019-11-04 03:45:36.445693: step 12620, total loss = 0.56, predict loss = 0.13 (72.0 examples/sec; 0.056 sec/batch; 92h:23m:19s remains)
INFO - root - 2019-11-04 03:45:37.035027: step 12630, total loss = 0.45, predict loss = 0.10 (80.7 examples/sec; 0.050 sec/batch; 82h:24m:14s remains)
INFO - root - 2019-11-04 03:45:37.616856: step 12640, total loss = 0.41, predict loss = 0.09 (79.1 examples/sec; 0.051 sec/batch; 84h:03m:22s remains)
INFO - root - 2019-11-04 03:45:38.236484: step 12650, total loss = 0.51, predict loss = 0.11 (74.0 examples/sec; 0.054 sec/batch; 89h:56m:45s remains)
INFO - root - 2019-11-04 03:45:38.903611: step 12660, total loss = 0.51, predict loss = 0.13 (68.4 examples/sec; 0.058 sec/batch; 97h:14m:34s remains)
INFO - root - 2019-11-04 03:45:39.547607: step 12670, total loss = 0.49, predict loss = 0.12 (67.6 examples/sec; 0.059 sec/batch; 98h:21m:39s remains)
INFO - root - 2019-11-04 03:45:40.106712: step 12680, total loss = 0.44, predict loss = 0.09 (84.0 examples/sec; 0.048 sec/batch; 79h:13m:00s remains)
INFO - root - 2019-11-04 03:45:40.665882: step 12690, total loss = 0.38, predict loss = 0.08 (85.5 examples/sec; 0.047 sec/batch; 77h:48m:32s remains)
INFO - root - 2019-11-04 03:45:41.244787: step 12700, total loss = 0.44, predict loss = 0.10 (70.4 examples/sec; 0.057 sec/batch; 94h:31m:04s remains)
INFO - root - 2019-11-04 03:45:41.863196: step 12710, total loss = 0.41, predict loss = 0.09 (78.5 examples/sec; 0.051 sec/batch; 84h:43m:44s remains)
INFO - root - 2019-11-04 03:45:42.449646: step 12720, total loss = 0.39, predict loss = 0.09 (73.0 examples/sec; 0.055 sec/batch; 91h:04m:20s remains)
INFO - root - 2019-11-04 03:45:43.033780: step 12730, total loss = 0.51, predict loss = 0.10 (84.1 examples/sec; 0.048 sec/batch; 79h:07m:00s remains)
INFO - root - 2019-11-04 03:45:43.624619: step 12740, total loss = 0.40, predict loss = 0.09 (86.9 examples/sec; 0.046 sec/batch; 76h:34m:32s remains)
INFO - root - 2019-11-04 03:45:44.221845: step 12750, total loss = 0.45, predict loss = 0.09 (77.0 examples/sec; 0.052 sec/batch; 86h:26m:23s remains)
INFO - root - 2019-11-04 03:45:44.815544: step 12760, total loss = 0.49, predict loss = 0.13 (76.3 examples/sec; 0.052 sec/batch; 87h:13m:33s remains)
INFO - root - 2019-11-04 03:45:45.404238: step 12770, total loss = 0.43, predict loss = 0.09 (71.0 examples/sec; 0.056 sec/batch; 93h:42m:26s remains)
INFO - root - 2019-11-04 03:45:46.013253: step 12780, total loss = 0.52, predict loss = 0.13 (72.7 examples/sec; 0.055 sec/batch; 91h:30m:33s remains)
INFO - root - 2019-11-04 03:45:46.624881: step 12790, total loss = 0.52, predict loss = 0.12 (70.1 examples/sec; 0.057 sec/batch; 94h:55m:47s remains)
INFO - root - 2019-11-04 03:45:47.235959: step 12800, total loss = 0.70, predict loss = 0.17 (73.1 examples/sec; 0.055 sec/batch; 91h:01m:30s remains)
INFO - root - 2019-11-04 03:45:47.832146: step 12810, total loss = 0.69, predict loss = 0.15 (81.1 examples/sec; 0.049 sec/batch; 81h:59m:36s remains)
INFO - root - 2019-11-04 03:45:48.404958: step 12820, total loss = 0.61, predict loss = 0.15 (76.3 examples/sec; 0.052 sec/batch; 87h:13m:02s remains)
INFO - root - 2019-11-04 03:45:48.997685: step 12830, total loss = 0.51, predict loss = 0.13 (81.5 examples/sec; 0.049 sec/batch; 81h:39m:42s remains)
INFO - root - 2019-11-04 03:45:49.560455: step 12840, total loss = 0.53, predict loss = 0.10 (76.2 examples/sec; 0.052 sec/batch; 87h:18m:01s remains)
INFO - root - 2019-11-04 03:45:50.117702: step 12850, total loss = 0.46, predict loss = 0.10 (84.5 examples/sec; 0.047 sec/batch; 78h:42m:06s remains)
INFO - root - 2019-11-04 03:45:50.691855: step 12860, total loss = 0.58, predict loss = 0.14 (82.9 examples/sec; 0.048 sec/batch; 80h:16m:03s remains)
INFO - root - 2019-11-04 03:45:51.270594: step 12870, total loss = 0.38, predict loss = 0.08 (75.6 examples/sec; 0.053 sec/batch; 87h:58m:13s remains)
INFO - root - 2019-11-04 03:45:51.855704: step 12880, total loss = 0.30, predict loss = 0.07 (75.5 examples/sec; 0.053 sec/batch; 88h:05m:27s remains)
INFO - root - 2019-11-04 03:45:52.472739: step 12890, total loss = 0.38, predict loss = 0.08 (73.6 examples/sec; 0.054 sec/batch; 90h:25m:40s remains)
INFO - root - 2019-11-04 03:45:53.090772: step 12900, total loss = 0.40, predict loss = 0.09 (73.2 examples/sec; 0.055 sec/batch; 90h:53m:38s remains)
INFO - root - 2019-11-04 03:45:53.698493: step 12910, total loss = 0.42, predict loss = 0.09 (68.0 examples/sec; 0.059 sec/batch; 97h:50m:22s remains)
INFO - root - 2019-11-04 03:45:54.283679: step 12920, total loss = 0.41, predict loss = 0.10 (77.6 examples/sec; 0.052 sec/batch; 85h:41m:17s remains)
INFO - root - 2019-11-04 03:45:54.859608: step 12930, total loss = 0.46, predict loss = 0.10 (80.0 examples/sec; 0.050 sec/batch; 83h:08m:16s remains)
INFO - root - 2019-11-04 03:45:55.457467: step 12940, total loss = 0.58, predict loss = 0.14 (78.5 examples/sec; 0.051 sec/batch; 84h:45m:09s remains)
INFO - root - 2019-11-04 03:45:56.039094: step 12950, total loss = 0.56, predict loss = 0.14 (76.7 examples/sec; 0.052 sec/batch; 86h:45m:48s remains)
INFO - root - 2019-11-04 03:45:56.648359: step 12960, total loss = 0.65, predict loss = 0.15 (75.9 examples/sec; 0.053 sec/batch; 87h:35m:41s remains)
INFO - root - 2019-11-04 03:45:57.255157: step 12970, total loss = 0.45, predict loss = 0.10 (85.2 examples/sec; 0.047 sec/batch; 78h:07m:21s remains)
INFO - root - 2019-11-04 03:45:57.874197: step 12980, total loss = 0.66, predict loss = 0.17 (73.9 examples/sec; 0.054 sec/batch; 90h:02m:36s remains)
INFO - root - 2019-11-04 03:45:58.455388: step 12990, total loss = 0.48, predict loss = 0.12 (79.4 examples/sec; 0.050 sec/batch; 83h:46m:39s remains)
INFO - root - 2019-11-04 03:45:59.053674: step 13000, total loss = 0.44, predict loss = 0.10 (81.4 examples/sec; 0.049 sec/batch; 81h:41m:51s remains)
INFO - root - 2019-11-04 03:45:59.654332: step 13010, total loss = 0.51, predict loss = 0.12 (76.3 examples/sec; 0.052 sec/batch; 87h:10m:21s remains)
INFO - root - 2019-11-04 03:46:00.238451: step 13020, total loss = 0.48, predict loss = 0.12 (77.8 examples/sec; 0.051 sec/batch; 85h:32m:03s remains)
INFO - root - 2019-11-04 03:46:00.840423: step 13030, total loss = 0.57, predict loss = 0.14 (72.6 examples/sec; 0.055 sec/batch; 91h:35m:27s remains)
INFO - root - 2019-11-04 03:46:01.418878: step 13040, total loss = 0.70, predict loss = 0.17 (73.5 examples/sec; 0.054 sec/batch; 90h:31m:57s remains)
INFO - root - 2019-11-04 03:46:02.070261: step 13050, total loss = 0.61, predict loss = 0.14 (88.4 examples/sec; 0.045 sec/batch; 75h:14m:10s remains)
INFO - root - 2019-11-04 03:46:02.611602: step 13060, total loss = 0.55, predict loss = 0.13 (77.7 examples/sec; 0.051 sec/batch; 85h:35m:56s remains)
INFO - root - 2019-11-04 03:46:03.213957: step 13070, total loss = 0.46, predict loss = 0.11 (73.5 examples/sec; 0.054 sec/batch; 90h:29m:01s remains)
INFO - root - 2019-11-04 03:46:03.817880: step 13080, total loss = 0.58, predict loss = 0.13 (71.7 examples/sec; 0.056 sec/batch; 92h:46m:47s remains)
INFO - root - 2019-11-04 03:46:04.422042: step 13090, total loss = 0.48, predict loss = 0.10 (75.8 examples/sec; 0.053 sec/batch; 87h:47m:05s remains)
INFO - root - 2019-11-04 03:46:05.022626: step 13100, total loss = 0.44, predict loss = 0.10 (78.9 examples/sec; 0.051 sec/batch; 84h:16m:54s remains)
INFO - root - 2019-11-04 03:46:05.606507: step 13110, total loss = 0.50, predict loss = 0.11 (75.5 examples/sec; 0.053 sec/batch; 88h:07m:05s remains)
INFO - root - 2019-11-04 03:46:06.201166: step 13120, total loss = 0.43, predict loss = 0.10 (82.4 examples/sec; 0.049 sec/batch; 80h:46m:33s remains)
INFO - root - 2019-11-04 03:46:06.778729: step 13130, total loss = 0.45, predict loss = 0.10 (82.9 examples/sec; 0.048 sec/batch; 80h:13m:22s remains)
INFO - root - 2019-11-04 03:46:07.369899: step 13140, total loss = 0.62, predict loss = 0.16 (82.7 examples/sec; 0.048 sec/batch; 80h:24m:39s remains)
INFO - root - 2019-11-04 03:46:07.972975: step 13150, total loss = 0.55, predict loss = 0.13 (71.4 examples/sec; 0.056 sec/batch; 93h:06m:57s remains)
INFO - root - 2019-11-04 03:46:08.561451: step 13160, total loss = 0.40, predict loss = 0.09 (80.2 examples/sec; 0.050 sec/batch; 82h:53m:51s remains)
INFO - root - 2019-11-04 03:46:09.142791: step 13170, total loss = 0.42, predict loss = 0.10 (74.7 examples/sec; 0.054 sec/batch; 89h:00m:32s remains)
INFO - root - 2019-11-04 03:46:09.744538: step 13180, total loss = 0.50, predict loss = 0.11 (75.2 examples/sec; 0.053 sec/batch; 88h:28m:28s remains)
INFO - root - 2019-11-04 03:46:10.344519: step 13190, total loss = 0.47, predict loss = 0.11 (76.9 examples/sec; 0.052 sec/batch; 86h:27m:44s remains)
INFO - root - 2019-11-04 03:46:10.931147: step 13200, total loss = 0.49, predict loss = 0.11 (71.3 examples/sec; 0.056 sec/batch; 93h:21m:28s remains)
INFO - root - 2019-11-04 03:46:11.522153: step 13210, total loss = 0.42, predict loss = 0.09 (70.1 examples/sec; 0.057 sec/batch; 94h:56m:21s remains)
INFO - root - 2019-11-04 03:46:12.112084: step 13220, total loss = 0.49, predict loss = 0.12 (76.2 examples/sec; 0.053 sec/batch; 87h:20m:18s remains)
INFO - root - 2019-11-04 03:46:12.699064: step 13230, total loss = 0.61, predict loss = 0.13 (75.3 examples/sec; 0.053 sec/batch; 88h:23m:05s remains)
INFO - root - 2019-11-04 03:46:13.293642: step 13240, total loss = 0.38, predict loss = 0.09 (75.4 examples/sec; 0.053 sec/batch; 88h:10m:25s remains)
INFO - root - 2019-11-04 03:46:13.881995: step 13250, total loss = 0.59, predict loss = 0.13 (73.6 examples/sec; 0.054 sec/batch; 90h:24m:46s remains)
INFO - root - 2019-11-04 03:46:14.465875: step 13260, total loss = 0.48, predict loss = 0.11 (81.3 examples/sec; 0.049 sec/batch; 81h:47m:38s remains)
INFO - root - 2019-11-04 03:46:15.050870: step 13270, total loss = 0.53, predict loss = 0.13 (72.8 examples/sec; 0.055 sec/batch; 91h:19m:08s remains)
INFO - root - 2019-11-04 03:46:15.628346: step 13280, total loss = 0.55, predict loss = 0.13 (73.9 examples/sec; 0.054 sec/batch; 90h:00m:05s remains)
INFO - root - 2019-11-04 03:46:16.213855: step 13290, total loss = 0.39, predict loss = 0.09 (74.9 examples/sec; 0.053 sec/batch; 88h:51m:27s remains)
INFO - root - 2019-11-04 03:46:16.822600: step 13300, total loss = 0.41, predict loss = 0.10 (78.8 examples/sec; 0.051 sec/batch; 84h:21m:52s remains)
INFO - root - 2019-11-04 03:46:17.404853: step 13310, total loss = 0.34, predict loss = 0.07 (74.9 examples/sec; 0.053 sec/batch; 88h:47m:10s remains)
INFO - root - 2019-11-04 03:46:17.989792: step 13320, total loss = 0.48, predict loss = 0.11 (76.3 examples/sec; 0.052 sec/batch; 87h:08m:38s remains)
INFO - root - 2019-11-04 03:46:18.584338: step 13330, total loss = 0.33, predict loss = 0.06 (77.4 examples/sec; 0.052 sec/batch; 85h:54m:04s remains)
INFO - root - 2019-11-04 03:46:19.184037: step 13340, total loss = 0.40, predict loss = 0.09 (75.3 examples/sec; 0.053 sec/batch; 88h:17m:29s remains)
INFO - root - 2019-11-04 03:46:19.761151: step 13350, total loss = 0.60, predict loss = 0.13 (74.0 examples/sec; 0.054 sec/batch; 89h:53m:13s remains)
INFO - root - 2019-11-04 03:46:20.334920: step 13360, total loss = 0.39, predict loss = 0.09 (75.6 examples/sec; 0.053 sec/batch; 87h:58m:02s remains)
INFO - root - 2019-11-04 03:46:20.886930: step 13370, total loss = 0.63, predict loss = 0.14 (73.2 examples/sec; 0.055 sec/batch; 90h:55m:12s remains)
INFO - root - 2019-11-04 03:46:21.470145: step 13380, total loss = 0.65, predict loss = 0.16 (73.0 examples/sec; 0.055 sec/batch; 91h:09m:56s remains)
INFO - root - 2019-11-04 03:46:22.051240: step 13390, total loss = 0.58, predict loss = 0.13 (73.9 examples/sec; 0.054 sec/batch; 90h:00m:52s remains)
INFO - root - 2019-11-04 03:46:22.643726: step 13400, total loss = 0.57, predict loss = 0.13 (77.3 examples/sec; 0.052 sec/batch; 86h:02m:26s remains)
INFO - root - 2019-11-04 03:46:23.217548: step 13410, total loss = 0.53, predict loss = 0.12 (80.1 examples/sec; 0.050 sec/batch; 83h:05m:15s remains)
INFO - root - 2019-11-04 03:46:23.788364: step 13420, total loss = 0.56, predict loss = 0.13 (79.0 examples/sec; 0.051 sec/batch; 84h:12m:13s remains)
INFO - root - 2019-11-04 03:46:24.363177: step 13430, total loss = 0.48, predict loss = 0.10 (78.9 examples/sec; 0.051 sec/batch; 84h:15m:40s remains)
INFO - root - 2019-11-04 03:46:24.944893: step 13440, total loss = 0.52, predict loss = 0.11 (79.3 examples/sec; 0.050 sec/batch; 83h:55m:10s remains)
INFO - root - 2019-11-04 03:46:25.552825: step 13450, total loss = 0.63, predict loss = 0.16 (70.3 examples/sec; 0.057 sec/batch; 94h:33m:29s remains)
INFO - root - 2019-11-04 03:46:26.160925: step 13460, total loss = 0.73, predict loss = 0.18 (73.5 examples/sec; 0.054 sec/batch; 90h:32m:53s remains)
INFO - root - 2019-11-04 03:46:26.775575: step 13470, total loss = 0.45, predict loss = 0.10 (68.5 examples/sec; 0.058 sec/batch; 97h:07m:39s remains)
INFO - root - 2019-11-04 03:46:27.392314: step 13480, total loss = 0.51, predict loss = 0.12 (68.8 examples/sec; 0.058 sec/batch; 96h:37m:39s remains)
INFO - root - 2019-11-04 03:46:28.002601: step 13490, total loss = 0.59, predict loss = 0.13 (69.8 examples/sec; 0.057 sec/batch; 95h:21m:35s remains)
INFO - root - 2019-11-04 03:46:28.605377: step 13500, total loss = 0.25, predict loss = 0.06 (68.3 examples/sec; 0.059 sec/batch; 97h:25m:11s remains)
INFO - root - 2019-11-04 03:46:29.221289: step 13510, total loss = 0.39, predict loss = 0.08 (67.5 examples/sec; 0.059 sec/batch; 98h:34m:55s remains)
INFO - root - 2019-11-04 03:46:29.847094: step 13520, total loss = 0.47, predict loss = 0.11 (70.4 examples/sec; 0.057 sec/batch; 94h:29m:51s remains)
INFO - root - 2019-11-04 03:46:30.474005: step 13530, total loss = 0.49, predict loss = 0.10 (75.6 examples/sec; 0.053 sec/batch; 87h:58m:16s remains)
INFO - root - 2019-11-04 03:46:31.074301: step 13540, total loss = 0.35, predict loss = 0.08 (82.9 examples/sec; 0.048 sec/batch; 80h:15m:24s remains)
INFO - root - 2019-11-04 03:46:31.740426: step 13550, total loss = 0.40, predict loss = 0.09 (53.4 examples/sec; 0.075 sec/batch; 124h:31m:20s remains)
INFO - root - 2019-11-04 03:46:32.343364: step 13560, total loss = 0.46, predict loss = 0.10 (77.2 examples/sec; 0.052 sec/batch; 86h:06m:22s remains)
INFO - root - 2019-11-04 03:46:32.905606: step 13570, total loss = 0.53, predict loss = 0.11 (84.2 examples/sec; 0.047 sec/batch; 78h:58m:57s remains)
INFO - root - 2019-11-04 03:46:33.465304: step 13580, total loss = 0.41, predict loss = 0.11 (77.8 examples/sec; 0.051 sec/batch; 85h:27m:41s remains)
INFO - root - 2019-11-04 03:46:34.027178: step 13590, total loss = 0.47, predict loss = 0.10 (80.3 examples/sec; 0.050 sec/batch; 82h:50m:56s remains)
INFO - root - 2019-11-04 03:46:34.557598: step 13600, total loss = 0.45, predict loss = 0.10 (84.2 examples/sec; 0.047 sec/batch; 78h:57m:49s remains)
INFO - root - 2019-11-04 03:46:35.096030: step 13610, total loss = 0.46, predict loss = 0.10 (88.2 examples/sec; 0.045 sec/batch; 75h:26m:06s remains)
INFO - root - 2019-11-04 03:46:35.552221: step 13620, total loss = 0.43, predict loss = 0.09 (95.8 examples/sec; 0.042 sec/batch; 69h:25m:26s remains)
INFO - root - 2019-11-04 03:46:36.300830: step 13630, total loss = 0.40, predict loss = 0.09 (97.0 examples/sec; 0.041 sec/batch; 68h:32m:26s remains)
INFO - root - 2019-11-04 03:46:37.077380: step 13640, total loss = 0.23, predict loss = 0.05 (77.1 examples/sec; 0.052 sec/batch; 86h:13m:07s remains)
INFO - root - 2019-11-04 03:46:37.732815: step 13650, total loss = 0.29, predict loss = 0.07 (72.5 examples/sec; 0.055 sec/batch; 91h:46m:57s remains)
INFO - root - 2019-11-04 03:46:38.292068: step 13660, total loss = 0.28, predict loss = 0.06 (88.8 examples/sec; 0.045 sec/batch; 74h:55m:58s remains)
INFO - root - 2019-11-04 03:46:38.844505: step 13670, total loss = 0.47, predict loss = 0.11 (78.9 examples/sec; 0.051 sec/batch; 84h:17m:49s remains)
INFO - root - 2019-11-04 03:46:39.392384: step 13680, total loss = 0.32, predict loss = 0.06 (88.9 examples/sec; 0.045 sec/batch; 74h:49m:10s remains)
INFO - root - 2019-11-04 03:46:39.954137: step 13690, total loss = 0.40, predict loss = 0.09 (81.5 examples/sec; 0.049 sec/batch; 81h:38m:37s remains)
INFO - root - 2019-11-04 03:46:40.504205: step 13700, total loss = 0.50, predict loss = 0.14 (81.0 examples/sec; 0.049 sec/batch; 82h:07m:36s remains)
INFO - root - 2019-11-04 03:46:41.052234: step 13710, total loss = 0.32, predict loss = 0.06 (86.1 examples/sec; 0.046 sec/batch; 77h:14m:39s remains)
INFO - root - 2019-11-04 03:46:41.613826: step 13720, total loss = 0.43, predict loss = 0.11 (83.7 examples/sec; 0.048 sec/batch; 79h:28m:46s remains)
INFO - root - 2019-11-04 03:46:42.187290: step 13730, total loss = 0.49, predict loss = 0.15 (75.3 examples/sec; 0.053 sec/batch; 88h:21m:11s remains)
INFO - root - 2019-11-04 03:46:42.758959: step 13740, total loss = 0.41, predict loss = 0.09 (78.4 examples/sec; 0.051 sec/batch; 84h:53m:25s remains)
INFO - root - 2019-11-04 03:46:43.333353: step 13750, total loss = 0.32, predict loss = 0.07 (81.4 examples/sec; 0.049 sec/batch; 81h:42m:02s remains)
INFO - root - 2019-11-04 03:46:43.884808: step 13760, total loss = 0.33, predict loss = 0.06 (84.1 examples/sec; 0.048 sec/batch; 79h:03m:15s remains)
INFO - root - 2019-11-04 03:46:44.446423: step 13770, total loss = 0.37, predict loss = 0.07 (81.2 examples/sec; 0.049 sec/batch; 81h:54m:56s remains)
INFO - root - 2019-11-04 03:46:45.005940: step 13780, total loss = 0.34, predict loss = 0.08 (86.8 examples/sec; 0.046 sec/batch; 76h:39m:18s remains)
INFO - root - 2019-11-04 03:46:45.561967: step 13790, total loss = 0.29, predict loss = 0.06 (77.3 examples/sec; 0.052 sec/batch; 86h:01m:07s remains)
INFO - root - 2019-11-04 03:46:46.147742: step 13800, total loss = 0.32, predict loss = 0.07 (75.2 examples/sec; 0.053 sec/batch; 88h:25m:26s remains)
INFO - root - 2019-11-04 03:46:46.733107: step 13810, total loss = 0.33, predict loss = 0.06 (79.6 examples/sec; 0.050 sec/batch; 83h:31m:53s remains)
INFO - root - 2019-11-04 03:46:47.319499: step 13820, total loss = 0.43, predict loss = 0.09 (75.5 examples/sec; 0.053 sec/batch; 88h:06m:34s remains)
INFO - root - 2019-11-04 03:46:47.915281: step 13830, total loss = 0.29, predict loss = 0.06 (73.8 examples/sec; 0.054 sec/batch; 90h:08m:24s remains)
INFO - root - 2019-11-04 03:46:48.509047: step 13840, total loss = 0.42, predict loss = 0.10 (75.4 examples/sec; 0.053 sec/batch; 88h:10m:40s remains)
INFO - root - 2019-11-04 03:46:49.088888: step 13850, total loss = 0.28, predict loss = 0.05 (78.3 examples/sec; 0.051 sec/batch; 84h:54m:53s remains)
INFO - root - 2019-11-04 03:46:49.668874: step 13860, total loss = 0.40, predict loss = 0.09 (76.1 examples/sec; 0.053 sec/batch; 87h:25m:57s remains)
INFO - root - 2019-11-04 03:46:50.255779: step 13870, total loss = 0.39, predict loss = 0.08 (70.6 examples/sec; 0.057 sec/batch; 94h:13m:16s remains)
INFO - root - 2019-11-04 03:46:50.867219: step 13880, total loss = 0.39, predict loss = 0.07 (74.5 examples/sec; 0.054 sec/batch; 89h:13m:23s remains)
INFO - root - 2019-11-04 03:46:51.431918: step 13890, total loss = 0.60, predict loss = 0.12 (83.7 examples/sec; 0.048 sec/batch; 79h:28m:02s remains)
INFO - root - 2019-11-04 03:46:52.005431: step 13900, total loss = 0.32, predict loss = 0.07 (74.9 examples/sec; 0.053 sec/batch; 88h:49m:30s remains)
INFO - root - 2019-11-04 03:46:52.598790: step 13910, total loss = 0.36, predict loss = 0.07 (72.6 examples/sec; 0.055 sec/batch; 91h:34m:42s remains)
INFO - root - 2019-11-04 03:46:53.193324: step 13920, total loss = 0.33, predict loss = 0.07 (77.8 examples/sec; 0.051 sec/batch; 85h:27m:19s remains)
INFO - root - 2019-11-04 03:46:53.779520: step 13930, total loss = 0.50, predict loss = 0.11 (72.4 examples/sec; 0.055 sec/batch; 91h:52m:18s remains)
INFO - root - 2019-11-04 03:46:54.380237: step 13940, total loss = 0.43, predict loss = 0.09 (72.8 examples/sec; 0.055 sec/batch; 91h:24m:03s remains)
INFO - root - 2019-11-04 03:46:54.977166: step 13950, total loss = 0.42, predict loss = 0.10 (77.4 examples/sec; 0.052 sec/batch; 85h:52m:41s remains)
INFO - root - 2019-11-04 03:46:55.561194: step 13960, total loss = 0.40, predict loss = 0.08 (72.0 examples/sec; 0.056 sec/batch; 92h:22m:05s remains)
INFO - root - 2019-11-04 03:46:56.162273: step 13970, total loss = 0.44, predict loss = 0.10 (74.1 examples/sec; 0.054 sec/batch; 89h:42m:01s remains)
INFO - root - 2019-11-04 03:46:56.729461: step 13980, total loss = 0.57, predict loss = 0.12 (85.6 examples/sec; 0.047 sec/batch; 77h:44m:02s remains)
INFO - root - 2019-11-04 03:46:57.275706: step 13990, total loss = 0.48, predict loss = 0.08 (82.0 examples/sec; 0.049 sec/batch; 81h:05m:58s remains)
INFO - root - 2019-11-04 03:46:57.832571: step 14000, total loss = 0.39, predict loss = 0.08 (81.9 examples/sec; 0.049 sec/batch; 81h:13m:22s remains)
INFO - root - 2019-11-04 03:46:58.392241: step 14010, total loss = 0.37, predict loss = 0.07 (81.3 examples/sec; 0.049 sec/batch; 81h:49m:52s remains)
INFO - root - 2019-11-04 03:46:58.935642: step 14020, total loss = 0.48, predict loss = 0.10 (78.1 examples/sec; 0.051 sec/batch; 85h:10m:17s remains)
INFO - root - 2019-11-04 03:46:59.507831: step 14030, total loss = 0.39, predict loss = 0.08 (78.7 examples/sec; 0.051 sec/batch; 84h:31m:51s remains)
INFO - root - 2019-11-04 03:47:00.079797: step 14040, total loss = 0.38, predict loss = 0.07 (73.6 examples/sec; 0.054 sec/batch; 90h:19m:17s remains)
INFO - root - 2019-11-04 03:47:00.646339: step 14050, total loss = 0.40, predict loss = 0.09 (79.4 examples/sec; 0.050 sec/batch; 83h:48m:43s remains)
INFO - root - 2019-11-04 03:47:01.244370: step 14060, total loss = 0.45, predict loss = 0.10 (75.3 examples/sec; 0.053 sec/batch; 88h:20m:02s remains)
INFO - root - 2019-11-04 03:47:01.871614: step 14070, total loss = 0.42, predict loss = 0.09 (53.2 examples/sec; 0.075 sec/batch; 124h:55m:22s remains)
INFO - root - 2019-11-04 03:47:02.460850: step 14080, total loss = 0.29, predict loss = 0.06 (72.1 examples/sec; 0.056 sec/batch; 92h:18m:05s remains)
INFO - root - 2019-11-04 03:47:03.114035: step 14090, total loss = 0.31, predict loss = 0.06 (73.4 examples/sec; 0.054 sec/batch; 90h:33m:41s remains)
INFO - root - 2019-11-04 03:47:03.754599: step 14100, total loss = 0.38, predict loss = 0.09 (68.6 examples/sec; 0.058 sec/batch; 97h:00m:00s remains)
INFO - root - 2019-11-04 03:47:04.323758: step 14110, total loss = 0.30, predict loss = 0.06 (81.8 examples/sec; 0.049 sec/batch; 81h:17m:03s remains)
INFO - root - 2019-11-04 03:47:04.871946: step 14120, total loss = 0.33, predict loss = 0.07 (72.4 examples/sec; 0.055 sec/batch; 91h:48m:56s remains)
INFO - root - 2019-11-04 03:47:05.448824: step 14130, total loss = 0.31, predict loss = 0.06 (77.2 examples/sec; 0.052 sec/batch; 86h:10m:57s remains)
INFO - root - 2019-11-04 03:47:06.009962: step 14140, total loss = 0.28, predict loss = 0.05 (84.1 examples/sec; 0.048 sec/batch; 79h:02m:37s remains)
INFO - root - 2019-11-04 03:47:06.593491: step 14150, total loss = 0.34, predict loss = 0.07 (76.9 examples/sec; 0.052 sec/batch; 86h:30m:59s remains)
INFO - root - 2019-11-04 03:47:07.157943: step 14160, total loss = 0.32, predict loss = 0.07 (77.8 examples/sec; 0.051 sec/batch; 85h:29m:48s remains)
INFO - root - 2019-11-04 03:47:07.736853: step 14170, total loss = 0.44, predict loss = 0.09 (78.4 examples/sec; 0.051 sec/batch; 84h:50m:50s remains)
INFO - root - 2019-11-04 03:47:08.328740: step 14180, total loss = 0.95, predict loss = 0.28 (75.5 examples/sec; 0.053 sec/batch; 88h:07m:19s remains)
INFO - root - 2019-11-04 03:47:08.898246: step 14190, total loss = 0.29, predict loss = 0.06 (79.7 examples/sec; 0.050 sec/batch; 83h:28m:30s remains)
INFO - root - 2019-11-04 03:47:09.451460: step 14200, total loss = 0.33, predict loss = 0.06 (79.8 examples/sec; 0.050 sec/batch; 83h:22m:20s remains)
INFO - root - 2019-11-04 03:47:10.003811: step 14210, total loss = 0.41, predict loss = 0.07 (76.7 examples/sec; 0.052 sec/batch; 86h:43m:18s remains)
INFO - root - 2019-11-04 03:47:10.586141: step 14220, total loss = 0.39, predict loss = 0.08 (71.7 examples/sec; 0.056 sec/batch; 92h:49m:00s remains)
INFO - root - 2019-11-04 03:47:11.202382: step 14230, total loss = 0.42, predict loss = 0.08 (68.9 examples/sec; 0.058 sec/batch; 96h:31m:03s remains)
INFO - root - 2019-11-04 03:47:11.821218: step 14240, total loss = 0.33, predict loss = 0.08 (72.2 examples/sec; 0.055 sec/batch; 92h:03m:20s remains)
INFO - root - 2019-11-04 03:47:12.435401: step 14250, total loss = 0.45, predict loss = 0.12 (83.4 examples/sec; 0.048 sec/batch; 79h:45m:02s remains)
INFO - root - 2019-11-04 03:47:13.057341: step 14260, total loss = 0.25, predict loss = 0.06 (75.4 examples/sec; 0.053 sec/batch; 88h:10m:31s remains)
INFO - root - 2019-11-04 03:47:13.676377: step 14270, total loss = 0.29, predict loss = 0.08 (71.3 examples/sec; 0.056 sec/batch; 93h:19m:18s remains)
INFO - root - 2019-11-04 03:47:14.286140: step 14280, total loss = 0.24, predict loss = 0.05 (74.1 examples/sec; 0.054 sec/batch; 89h:43m:54s remains)
INFO - root - 2019-11-04 03:47:14.897074: step 14290, total loss = 0.28, predict loss = 0.06 (76.7 examples/sec; 0.052 sec/batch; 86h:42m:57s remains)
INFO - root - 2019-11-04 03:47:15.512789: step 14300, total loss = 0.43, predict loss = 0.09 (71.3 examples/sec; 0.056 sec/batch; 93h:14m:04s remains)
INFO - root - 2019-11-04 03:47:16.133930: step 14310, total loss = 0.30, predict loss = 0.07 (72.1 examples/sec; 0.055 sec/batch; 92h:15m:14s remains)
INFO - root - 2019-11-04 03:47:16.744829: step 14320, total loss = 0.37, predict loss = 0.08 (77.4 examples/sec; 0.052 sec/batch; 85h:52m:39s remains)
INFO - root - 2019-11-04 03:47:17.354821: step 14330, total loss = 0.33, predict loss = 0.07 (71.2 examples/sec; 0.056 sec/batch; 93h:25m:39s remains)
INFO - root - 2019-11-04 03:47:17.961965: step 14340, total loss = 0.30, predict loss = 0.07 (75.6 examples/sec; 0.053 sec/batch; 87h:55m:36s remains)
INFO - root - 2019-11-04 03:47:18.583464: step 14350, total loss = 0.37, predict loss = 0.07 (76.1 examples/sec; 0.053 sec/batch; 87h:21m:00s remains)
INFO - root - 2019-11-04 03:47:19.205291: step 14360, total loss = 0.21, predict loss = 0.04 (80.9 examples/sec; 0.049 sec/batch; 82h:10m:23s remains)
INFO - root - 2019-11-04 03:47:19.807400: step 14370, total loss = 0.36, predict loss = 0.09 (70.8 examples/sec; 0.056 sec/batch; 93h:54m:16s remains)
INFO - root - 2019-11-04 03:47:20.417659: step 14380, total loss = 0.32, predict loss = 0.07 (75.1 examples/sec; 0.053 sec/batch; 88h:35m:25s remains)
INFO - root - 2019-11-04 03:47:21.024543: step 14390, total loss = 0.42, predict loss = 0.09 (70.2 examples/sec; 0.057 sec/batch; 94h:41m:35s remains)
INFO - root - 2019-11-04 03:47:21.642020: step 14400, total loss = 0.43, predict loss = 0.09 (76.4 examples/sec; 0.052 sec/batch; 87h:06m:19s remains)
INFO - root - 2019-11-04 03:47:22.250260: step 14410, total loss = 0.31, predict loss = 0.07 (73.4 examples/sec; 0.055 sec/batch; 90h:38m:58s remains)
INFO - root - 2019-11-04 03:47:22.853735: step 14420, total loss = 0.41, predict loss = 0.08 (77.7 examples/sec; 0.051 sec/batch; 85h:33m:38s remains)
INFO - root - 2019-11-04 03:47:23.460239: step 14430, total loss = 0.29, predict loss = 0.06 (78.1 examples/sec; 0.051 sec/batch; 85h:09m:33s remains)
INFO - root - 2019-11-04 03:47:24.039508: step 14440, total loss = 0.30, predict loss = 0.06 (79.8 examples/sec; 0.050 sec/batch; 83h:19m:02s remains)
INFO - root - 2019-11-04 03:47:24.644023: step 14450, total loss = 0.28, predict loss = 0.06 (67.3 examples/sec; 0.059 sec/batch; 98h:46m:10s remains)
INFO - root - 2019-11-04 03:47:25.270961: step 14460, total loss = 0.34, predict loss = 0.07 (74.0 examples/sec; 0.054 sec/batch; 89h:53m:55s remains)
INFO - root - 2019-11-04 03:47:25.908524: step 14470, total loss = 0.30, predict loss = 0.06 (66.0 examples/sec; 0.061 sec/batch; 100h:43m:06s remains)
INFO - root - 2019-11-04 03:47:26.540701: step 14480, total loss = 0.25, predict loss = 0.04 (76.5 examples/sec; 0.052 sec/batch; 86h:55m:45s remains)
INFO - root - 2019-11-04 03:47:27.196714: step 14490, total loss = 0.28, predict loss = 0.06 (66.5 examples/sec; 0.060 sec/batch; 99h:56m:39s remains)
INFO - root - 2019-11-04 03:47:27.836229: step 14500, total loss = 0.23, predict loss = 0.04 (68.5 examples/sec; 0.058 sec/batch; 97h:02m:44s remains)
INFO - root - 2019-11-04 03:47:28.466406: step 14510, total loss = 0.43, predict loss = 0.13 (75.3 examples/sec; 0.053 sec/batch; 88h:20m:24s remains)
INFO - root - 2019-11-04 03:47:29.103465: step 14520, total loss = 0.41, predict loss = 0.09 (71.5 examples/sec; 0.056 sec/batch; 92h:57m:23s remains)
INFO - root - 2019-11-04 03:47:29.737000: step 14530, total loss = 0.40, predict loss = 0.09 (71.2 examples/sec; 0.056 sec/batch; 93h:26m:09s remains)
INFO - root - 2019-11-04 03:47:30.363880: step 14540, total loss = 0.26, predict loss = 0.05 (72.8 examples/sec; 0.055 sec/batch; 91h:23m:25s remains)
INFO - root - 2019-11-04 03:47:30.999349: step 14550, total loss = 0.86, predict loss = 0.25 (79.6 examples/sec; 0.050 sec/batch; 83h:33m:27s remains)
INFO - root - 2019-11-04 03:47:31.580744: step 14560, total loss = 0.37, predict loss = 0.08 (74.2 examples/sec; 0.054 sec/batch; 89h:36m:52s remains)
INFO - root - 2019-11-04 03:47:32.221319: step 14570, total loss = 0.33, predict loss = 0.07 (82.2 examples/sec; 0.049 sec/batch; 80h:55m:59s remains)
INFO - root - 2019-11-04 03:47:32.861947: step 14580, total loss = 0.37, predict loss = 0.08 (67.5 examples/sec; 0.059 sec/batch; 98h:30m:38s remains)
INFO - root - 2019-11-04 03:47:33.492381: step 14590, total loss = 0.34, predict loss = 0.06 (68.7 examples/sec; 0.058 sec/batch; 96h:47m:05s remains)
INFO - root - 2019-11-04 03:47:34.137520: step 14600, total loss = 0.30, predict loss = 0.06 (69.9 examples/sec; 0.057 sec/batch; 95h:07m:44s remains)
INFO - root - 2019-11-04 03:47:34.789542: step 14610, total loss = 0.32, predict loss = 0.08 (71.3 examples/sec; 0.056 sec/batch; 93h:15m:25s remains)
INFO - root - 2019-11-04 03:47:35.429928: step 14620, total loss = 0.33, predict loss = 0.09 (75.9 examples/sec; 0.053 sec/batch; 87h:36m:04s remains)
INFO - root - 2019-11-04 03:47:35.989498: step 14630, total loss = 0.33, predict loss = 0.06 (80.8 examples/sec; 0.050 sec/batch; 82h:21m:06s remains)
INFO - root - 2019-11-04 03:47:36.514335: step 14640, total loss = 0.38, predict loss = 0.08 (90.0 examples/sec; 0.044 sec/batch; 73h:55m:26s remains)
INFO - root - 2019-11-04 03:47:37.042945: step 14650, total loss = 0.39, predict loss = 0.08 (86.1 examples/sec; 0.046 sec/batch; 77h:15m:48s remains)
INFO - root - 2019-11-04 03:47:37.566932: step 14660, total loss = 0.44, predict loss = 0.09 (82.0 examples/sec; 0.049 sec/batch; 81h:08m:33s remains)
INFO - root - 2019-11-04 03:47:38.093894: step 14670, total loss = 0.38, predict loss = 0.08 (83.0 examples/sec; 0.048 sec/batch; 80h:07m:25s remains)
INFO - root - 2019-11-04 03:47:38.622319: step 14680, total loss = 0.35, predict loss = 0.07 (84.0 examples/sec; 0.048 sec/batch; 79h:08m:41s remains)
INFO - root - 2019-11-04 03:47:39.136709: step 14690, total loss = 0.26, predict loss = 0.05 (92.4 examples/sec; 0.043 sec/batch; 72h:00m:13s remains)
INFO - root - 2019-11-04 03:47:39.673995: step 14700, total loss = 0.25, predict loss = 0.05 (85.9 examples/sec; 0.047 sec/batch; 77h:26m:12s remains)
INFO - root - 2019-11-04 03:47:40.193115: step 14710, total loss = 0.29, predict loss = 0.06 (88.3 examples/sec; 0.045 sec/batch; 75h:19m:47s remains)
INFO - root - 2019-11-04 03:47:40.708559: step 14720, total loss = 0.34, predict loss = 0.06 (88.3 examples/sec; 0.045 sec/batch; 75h:18m:48s remains)
INFO - root - 2019-11-04 03:47:41.249313: step 14730, total loss = 0.30, predict loss = 0.07 (82.9 examples/sec; 0.048 sec/batch; 80h:14m:24s remains)
INFO - root - 2019-11-04 03:47:41.807783: step 14740, total loss = 0.27, predict loss = 0.05 (79.3 examples/sec; 0.050 sec/batch; 83h:54m:06s remains)
INFO - root - 2019-11-04 03:47:42.341990: step 14750, total loss = 0.20, predict loss = 0.04 (91.8 examples/sec; 0.044 sec/batch; 72h:27m:03s remains)
INFO - root - 2019-11-04 03:47:42.888450: step 14760, total loss = 0.28, predict loss = 0.06 (83.6 examples/sec; 0.048 sec/batch; 79h:34m:45s remains)
INFO - root - 2019-11-04 03:47:43.439560: step 14770, total loss = 0.30, predict loss = 0.06 (83.7 examples/sec; 0.048 sec/batch; 79h:29m:31s remains)
INFO - root - 2019-11-04 03:47:43.979715: step 14780, total loss = 0.43, predict loss = 0.08 (81.3 examples/sec; 0.049 sec/batch; 81h:48m:57s remains)
INFO - root - 2019-11-04 03:47:44.516558: step 14790, total loss = 0.36, predict loss = 0.07 (89.0 examples/sec; 0.045 sec/batch; 74h:44m:08s remains)
INFO - root - 2019-11-04 03:47:45.053697: step 14800, total loss = 0.36, predict loss = 0.08 (86.1 examples/sec; 0.046 sec/batch; 77h:11m:47s remains)
INFO - root - 2019-11-04 03:47:45.605223: step 14810, total loss = 0.54, predict loss = 0.12 (82.5 examples/sec; 0.049 sec/batch; 80h:39m:06s remains)
INFO - root - 2019-11-04 03:47:46.140356: step 14820, total loss = 0.31, predict loss = 0.07 (83.1 examples/sec; 0.048 sec/batch; 80h:01m:32s remains)
INFO - root - 2019-11-04 03:47:46.686345: step 14830, total loss = 0.38, predict loss = 0.06 (81.6 examples/sec; 0.049 sec/batch; 81h:27m:33s remains)
INFO - root - 2019-11-04 03:47:47.226053: step 14840, total loss = 0.31, predict loss = 0.06 (80.4 examples/sec; 0.050 sec/batch; 82h:45m:40s remains)
INFO - root - 2019-11-04 03:47:47.768269: step 14850, total loss = 0.25, predict loss = 0.05 (80.2 examples/sec; 0.050 sec/batch; 82h:52m:43s remains)
INFO - root - 2019-11-04 03:47:48.311258: step 14860, total loss = 0.35, predict loss = 0.07 (85.9 examples/sec; 0.047 sec/batch; 77h:24m:45s remains)
INFO - root - 2019-11-04 03:47:48.854928: step 14870, total loss = 0.35, predict loss = 0.07 (77.2 examples/sec; 0.052 sec/batch; 86h:06m:04s remains)
INFO - root - 2019-11-04 03:47:49.434482: step 14880, total loss = 0.38, predict loss = 0.08 (76.7 examples/sec; 0.052 sec/batch; 86h:42m:42s remains)
INFO - root - 2019-11-04 03:47:50.036731: step 14890, total loss = 0.32, predict loss = 0.07 (71.9 examples/sec; 0.056 sec/batch; 92h:32m:11s remains)
INFO - root - 2019-11-04 03:47:50.571522: step 14900, total loss = 0.34, predict loss = 0.06 (94.6 examples/sec; 0.042 sec/batch; 70h:17m:11s remains)
INFO - root - 2019-11-04 03:47:51.084334: step 14910, total loss = 0.35, predict loss = 0.06 (84.3 examples/sec; 0.047 sec/batch; 78h:51m:30s remains)
INFO - root - 2019-11-04 03:47:51.606907: step 14920, total loss = 0.40, predict loss = 0.08 (85.5 examples/sec; 0.047 sec/batch; 77h:49m:26s remains)
INFO - root - 2019-11-04 03:47:52.110423: step 14930, total loss = 0.55, predict loss = 0.14 (87.6 examples/sec; 0.046 sec/batch; 75h:55m:05s remains)
INFO - root - 2019-11-04 03:47:52.620439: step 14940, total loss = 0.50, predict loss = 0.10 (86.8 examples/sec; 0.046 sec/batch; 76h:39m:10s remains)
INFO - root - 2019-11-04 03:47:53.130348: step 14950, total loss = 0.34, predict loss = 0.07 (86.1 examples/sec; 0.046 sec/batch; 77h:15m:50s remains)
INFO - root - 2019-11-04 03:47:53.641003: step 14960, total loss = 0.31, predict loss = 0.07 (89.0 examples/sec; 0.045 sec/batch; 74h:40m:42s remains)
INFO - root - 2019-11-04 03:47:54.146537: step 14970, total loss = 0.31, predict loss = 0.07 (88.6 examples/sec; 0.045 sec/batch; 75h:02m:24s remains)
INFO - root - 2019-11-04 03:47:54.656704: step 14980, total loss = 0.39, predict loss = 0.07 (86.6 examples/sec; 0.046 sec/batch; 76h:49m:09s remains)
INFO - root - 2019-11-04 03:47:55.164726: step 14990, total loss = 0.21, predict loss = 0.04 (86.7 examples/sec; 0.046 sec/batch; 76h:41m:46s remains)
INFO - root - 2019-11-04 03:47:55.660853: step 15000, total loss = 0.13, predict loss = 0.02 (87.9 examples/sec; 0.046 sec/batch; 75h:39m:46s remains)
INFO - root - 2019-11-04 03:47:56.817222: step 15010, total loss = 0.19, predict loss = 0.04 (90.2 examples/sec; 0.044 sec/batch; 73h:45m:12s remains)
INFO - root - 2019-11-04 03:47:57.309111: step 15020, total loss = 0.30, predict loss = 0.08 (86.4 examples/sec; 0.046 sec/batch; 77h:00m:08s remains)
INFO - root - 2019-11-04 03:47:57.801554: step 15030, total loss = 0.25, predict loss = 0.06 (86.8 examples/sec; 0.046 sec/batch; 76h:38m:29s remains)
INFO - root - 2019-11-04 03:47:58.290615: step 15040, total loss = 0.39, predict loss = 0.07 (88.9 examples/sec; 0.045 sec/batch; 74h:46m:39s remains)
INFO - root - 2019-11-04 03:47:58.783573: step 15050, total loss = 0.36, predict loss = 0.07 (90.4 examples/sec; 0.044 sec/batch; 73h:32m:35s remains)
INFO - root - 2019-11-04 03:47:59.261933: step 15060, total loss = 0.60, predict loss = 0.13 (93.1 examples/sec; 0.043 sec/batch; 71h:26m:56s remains)
INFO - root - 2019-11-04 03:47:59.756725: step 15070, total loss = 0.57, predict loss = 0.13 (86.6 examples/sec; 0.046 sec/batch; 76h:49m:43s remains)
INFO - root - 2019-11-04 03:48:00.256319: step 15080, total loss = 0.88, predict loss = 0.23 (88.8 examples/sec; 0.045 sec/batch; 74h:54m:59s remains)
INFO - root - 2019-11-04 03:48:00.752777: step 15090, total loss = 0.64, predict loss = 0.15 (88.8 examples/sec; 0.045 sec/batch; 74h:55m:13s remains)
INFO - root - 2019-11-04 03:48:01.252586: step 15100, total loss = 0.67, predict loss = 0.16 (84.2 examples/sec; 0.048 sec/batch; 78h:58m:29s remains)
INFO - root - 2019-11-04 03:48:01.808908: step 15110, total loss = 0.62, predict loss = 0.14 (57.5 examples/sec; 0.070 sec/batch; 115h:35m:19s remains)
INFO - root - 2019-11-04 03:48:02.331135: step 15120, total loss = 0.57, predict loss = 0.13 (96.5 examples/sec; 0.041 sec/batch; 68h:55m:24s remains)
INFO - root - 2019-11-04 03:48:02.863427: step 15130, total loss = 0.57, predict loss = 0.13 (80.4 examples/sec; 0.050 sec/batch; 82h:40m:15s remains)
INFO - root - 2019-11-04 03:48:03.392846: step 15140, total loss = 0.50, predict loss = 0.11 (88.5 examples/sec; 0.045 sec/batch; 75h:08m:47s remains)
INFO - root - 2019-11-04 03:48:03.909145: step 15150, total loss = 0.45, predict loss = 0.10 (83.8 examples/sec; 0.048 sec/batch; 79h:21m:28s remains)
INFO - root - 2019-11-04 03:48:04.428892: step 15160, total loss = 0.52, predict loss = 0.12 (80.4 examples/sec; 0.050 sec/batch; 82h:45m:17s remains)
INFO - root - 2019-11-04 03:48:04.946053: step 15170, total loss = 0.52, predict loss = 0.11 (88.0 examples/sec; 0.045 sec/batch; 75h:31m:33s remains)
INFO - root - 2019-11-04 03:48:05.456811: step 15180, total loss = 0.48, predict loss = 0.11 (90.5 examples/sec; 0.044 sec/batch; 73h:30m:49s remains)
INFO - root - 2019-11-04 03:48:05.987580: step 15190, total loss = 0.51, predict loss = 0.11 (84.6 examples/sec; 0.047 sec/batch; 78h:35m:12s remains)
INFO - root - 2019-11-04 03:48:06.520509: step 15200, total loss = 0.42, predict loss = 0.09 (82.2 examples/sec; 0.049 sec/batch; 80h:51m:36s remains)
INFO - root - 2019-11-04 03:48:07.072783: step 15210, total loss = 0.52, predict loss = 0.12 (79.3 examples/sec; 0.050 sec/batch; 83h:54m:03s remains)
INFO - root - 2019-11-04 03:48:07.614407: step 15220, total loss = 0.51, predict loss = 0.12 (93.5 examples/sec; 0.043 sec/batch; 71h:09m:26s remains)
INFO - root - 2019-11-04 03:48:08.157347: step 15230, total loss = 0.42, predict loss = 0.09 (78.8 examples/sec; 0.051 sec/batch; 84h:23m:51s remains)
INFO - root - 2019-11-04 03:48:08.706368: step 15240, total loss = 0.50, predict loss = 0.11 (81.1 examples/sec; 0.049 sec/batch; 81h:57m:21s remains)
INFO - root - 2019-11-04 03:48:09.246228: step 15250, total loss = 0.48, predict loss = 0.12 (81.8 examples/sec; 0.049 sec/batch; 81h:16m:20s remains)
INFO - root - 2019-11-04 03:48:09.777220: step 15260, total loss = 0.56, predict loss = 0.13 (84.7 examples/sec; 0.047 sec/batch; 78h:32m:57s remains)
INFO - root - 2019-11-04 03:48:10.321634: step 15270, total loss = 0.52, predict loss = 0.12 (83.4 examples/sec; 0.048 sec/batch; 79h:46m:10s remains)
INFO - root - 2019-11-04 03:48:10.865665: step 15280, total loss = 0.65, predict loss = 0.15 (76.9 examples/sec; 0.052 sec/batch; 86h:28m:41s remains)
INFO - root - 2019-11-04 03:48:11.417391: step 15290, total loss = 0.56, predict loss = 0.13 (79.0 examples/sec; 0.051 sec/batch; 84h:10m:17s remains)
INFO - root - 2019-11-04 03:48:11.971360: step 15300, total loss = 0.35, predict loss = 0.08 (80.4 examples/sec; 0.050 sec/batch; 82h:42m:10s remains)
INFO - root - 2019-11-04 03:48:12.503900: step 15310, total loss = 0.32, predict loss = 0.07 (84.5 examples/sec; 0.047 sec/batch; 78h:41m:01s remains)
INFO - root - 2019-11-04 03:48:13.046773: step 15320, total loss = 0.51, predict loss = 0.13 (82.4 examples/sec; 0.049 sec/batch; 80h:42m:45s remains)
INFO - root - 2019-11-04 03:48:13.578901: step 15330, total loss = 0.38, predict loss = 0.08 (82.1 examples/sec; 0.049 sec/batch; 81h:01m:53s remains)
INFO - root - 2019-11-04 03:48:14.130631: step 15340, total loss = 0.39, predict loss = 0.09 (80.8 examples/sec; 0.049 sec/batch; 82h:16m:30s remains)
INFO - root - 2019-11-04 03:48:14.694108: step 15350, total loss = 0.44, predict loss = 0.10 (78.2 examples/sec; 0.051 sec/batch; 85h:01m:19s remains)
INFO - root - 2019-11-04 03:48:15.251194: step 15360, total loss = 0.41, predict loss = 0.09 (81.2 examples/sec; 0.049 sec/batch; 81h:50m:28s remains)
INFO - root - 2019-11-04 03:48:15.829113: step 15370, total loss = 0.35, predict loss = 0.08 (73.7 examples/sec; 0.054 sec/batch; 90h:12m:46s remains)
INFO - root - 2019-11-04 03:48:16.437835: step 15380, total loss = 0.52, predict loss = 0.12 (72.5 examples/sec; 0.055 sec/batch; 91h:41m:11s remains)
INFO - root - 2019-11-04 03:48:17.046102: step 15390, total loss = 0.66, predict loss = 0.17 (75.5 examples/sec; 0.053 sec/batch; 88h:05m:48s remains)
INFO - root - 2019-11-04 03:48:17.646675: step 15400, total loss = 0.42, predict loss = 0.10 (74.5 examples/sec; 0.054 sec/batch; 89h:18m:12s remains)
INFO - root - 2019-11-04 03:48:18.239444: step 15410, total loss = 0.46, predict loss = 0.11 (77.0 examples/sec; 0.052 sec/batch; 86h:22m:27s remains)
INFO - root - 2019-11-04 03:48:18.842244: step 15420, total loss = 0.47, predict loss = 0.11 (72.6 examples/sec; 0.055 sec/batch; 91h:33m:04s remains)
INFO - root - 2019-11-04 03:48:19.436963: step 15430, total loss = 0.46, predict loss = 0.10 (71.1 examples/sec; 0.056 sec/batch; 93h:31m:35s remains)
INFO - root - 2019-11-04 03:48:20.024285: step 15440, total loss = 0.39, predict loss = 0.09 (75.3 examples/sec; 0.053 sec/batch; 88h:20m:09s remains)
INFO - root - 2019-11-04 03:48:20.628371: step 15450, total loss = 0.55, predict loss = 0.14 (74.8 examples/sec; 0.054 sec/batch; 88h:56m:47s remains)
INFO - root - 2019-11-04 03:48:21.168066: step 15460, total loss = 0.41, predict loss = 0.09 (83.6 examples/sec; 0.048 sec/batch; 79h:33m:28s remains)
INFO - root - 2019-11-04 03:48:21.684151: step 15470, total loss = 0.47, predict loss = 0.10 (85.2 examples/sec; 0.047 sec/batch; 78h:00m:40s remains)
INFO - root - 2019-11-04 03:48:22.201163: step 15480, total loss = 0.49, predict loss = 0.12 (84.5 examples/sec; 0.047 sec/batch; 78h:42m:59s remains)
INFO - root - 2019-11-04 03:48:22.721000: step 15490, total loss = 0.51, predict loss = 0.13 (85.0 examples/sec; 0.047 sec/batch; 78h:12m:58s remains)
INFO - root - 2019-11-04 03:48:23.262584: step 15500, total loss = 0.38, predict loss = 0.09 (78.5 examples/sec; 0.051 sec/batch; 84h:44m:21s remains)
INFO - root - 2019-11-04 03:48:23.836265: step 15510, total loss = 0.49, predict loss = 0.12 (80.4 examples/sec; 0.050 sec/batch; 82h:42m:03s remains)
INFO - root - 2019-11-04 03:48:24.407708: step 15520, total loss = 0.56, predict loss = 0.13 (75.5 examples/sec; 0.053 sec/batch; 88h:06m:03s remains)
INFO - root - 2019-11-04 03:48:24.971844: step 15530, total loss = 0.48, predict loss = 0.12 (88.6 examples/sec; 0.045 sec/batch; 75h:03m:27s remains)
INFO - root - 2019-11-04 03:48:25.623528: step 15540, total loss = 0.47, predict loss = 0.11 (71.5 examples/sec; 0.056 sec/batch; 93h:01m:18s remains)
INFO - root - 2019-11-04 03:48:26.195350: step 15550, total loss = 0.50, predict loss = 0.11 (79.3 examples/sec; 0.050 sec/batch; 83h:48m:06s remains)
INFO - root - 2019-11-04 03:48:26.722339: step 15560, total loss = 0.45, predict loss = 0.11 (80.6 examples/sec; 0.050 sec/batch; 82h:31m:52s remains)
INFO - root - 2019-11-04 03:48:27.262369: step 15570, total loss = 0.45, predict loss = 0.08 (82.1 examples/sec; 0.049 sec/batch; 81h:00m:50s remains)
INFO - root - 2019-11-04 03:48:27.808810: step 15580, total loss = 0.59, predict loss = 0.14 (85.0 examples/sec; 0.047 sec/batch; 78h:14m:43s remains)
INFO - root - 2019-11-04 03:48:28.346152: step 15590, total loss = 0.73, predict loss = 0.20 (89.3 examples/sec; 0.045 sec/batch; 74h:26m:51s remains)
INFO - root - 2019-11-04 03:48:28.877057: step 15600, total loss = 0.33, predict loss = 0.07 (82.8 examples/sec; 0.048 sec/batch; 80h:15m:48s remains)
INFO - root - 2019-11-04 03:48:29.446059: step 15610, total loss = 0.56, predict loss = 0.12 (76.3 examples/sec; 0.052 sec/batch; 87h:10m:49s remains)
INFO - root - 2019-11-04 03:48:30.040703: step 15620, total loss = 0.42, predict loss = 0.08 (82.7 examples/sec; 0.048 sec/batch; 80h:23m:02s remains)
INFO - root - 2019-11-04 03:48:30.644696: step 15630, total loss = 0.44, predict loss = 0.10 (73.2 examples/sec; 0.055 sec/batch; 90h:47m:13s remains)
INFO - root - 2019-11-04 03:48:31.228402: step 15640, total loss = 0.44, predict loss = 0.09 (74.0 examples/sec; 0.054 sec/batch; 89h:51m:14s remains)
INFO - root - 2019-11-04 03:48:31.854986: step 15650, total loss = 0.45, predict loss = 0.10 (61.4 examples/sec; 0.065 sec/batch; 108h:14m:26s remains)
INFO - root - 2019-11-04 03:48:32.496917: step 15660, total loss = 0.45, predict loss = 0.10 (66.6 examples/sec; 0.060 sec/batch; 99h:51m:48s remains)
INFO - root - 2019-11-04 03:48:33.215466: step 15670, total loss = 0.53, predict loss = 0.12 (63.4 examples/sec; 0.063 sec/batch; 104h:50m:56s remains)
INFO - root - 2019-11-04 03:48:33.831993: step 15680, total loss = 0.53, predict loss = 0.12 (72.7 examples/sec; 0.055 sec/batch; 91h:30m:50s remains)
INFO - root - 2019-11-04 03:48:34.416056: step 15690, total loss = 0.46, predict loss = 0.10 (77.9 examples/sec; 0.051 sec/batch; 85h:21m:30s remains)
INFO - root - 2019-11-04 03:48:34.978892: step 15700, total loss = 0.53, predict loss = 0.12 (81.2 examples/sec; 0.049 sec/batch; 81h:55m:32s remains)
INFO - root - 2019-11-04 03:48:35.565396: step 15710, total loss = 0.51, predict loss = 0.12 (76.5 examples/sec; 0.052 sec/batch; 86h:56m:56s remains)
INFO - root - 2019-11-04 03:48:36.137210: step 15720, total loss = 0.45, predict loss = 0.11 (78.1 examples/sec; 0.051 sec/batch; 85h:05m:18s remains)
INFO - root - 2019-11-04 03:48:36.694435: step 15730, total loss = 0.53, predict loss = 0.12 (76.9 examples/sec; 0.052 sec/batch; 86h:29m:32s remains)
INFO - root - 2019-11-04 03:48:37.267905: step 15740, total loss = 0.59, predict loss = 0.13 (77.1 examples/sec; 0.052 sec/batch; 86h:14m:32s remains)
INFO - root - 2019-11-04 03:48:37.832562: step 15750, total loss = 0.53, predict loss = 0.12 (82.5 examples/sec; 0.049 sec/batch; 80h:37m:43s remains)
INFO - root - 2019-11-04 03:48:38.408123: step 15760, total loss = 0.54, predict loss = 0.14 (82.9 examples/sec; 0.048 sec/batch; 80h:12m:53s remains)
INFO - root - 2019-11-04 03:48:38.989407: step 15770, total loss = 0.41, predict loss = 0.09 (78.9 examples/sec; 0.051 sec/batch; 84h:19m:17s remains)
INFO - root - 2019-11-04 03:48:39.602045: step 15780, total loss = 0.42, predict loss = 0.09 (79.8 examples/sec; 0.050 sec/batch; 83h:17m:29s remains)
INFO - root - 2019-11-04 03:48:40.212081: step 15790, total loss = 0.41, predict loss = 0.09 (70.1 examples/sec; 0.057 sec/batch; 94h:48m:03s remains)
INFO - root - 2019-11-04 03:48:40.833127: step 15800, total loss = 0.45, predict loss = 0.10 (66.5 examples/sec; 0.060 sec/batch; 100h:00m:28s remains)
INFO - root - 2019-11-04 03:48:41.446039: step 15810, total loss = 0.42, predict loss = 0.10 (79.4 examples/sec; 0.050 sec/batch; 83h:47m:30s remains)
INFO - root - 2019-11-04 03:48:42.075525: step 15820, total loss = 0.55, predict loss = 0.12 (69.2 examples/sec; 0.058 sec/batch; 96h:07m:54s remains)
INFO - root - 2019-11-04 03:48:42.713852: step 15830, total loss = 0.46, predict loss = 0.10 (73.1 examples/sec; 0.055 sec/batch; 90h:58m:17s remains)
INFO - root - 2019-11-04 03:48:43.267732: step 15840, total loss = 0.47, predict loss = 0.11 (83.5 examples/sec; 0.048 sec/batch; 79h:35m:05s remains)
INFO - root - 2019-11-04 03:48:43.775055: step 15850, total loss = 0.43, predict loss = 0.11 (87.5 examples/sec; 0.046 sec/batch; 75h:58m:44s remains)
INFO - root - 2019-11-04 03:48:44.280097: step 15860, total loss = 0.47, predict loss = 0.10 (94.0 examples/sec; 0.043 sec/batch; 70h:42m:17s remains)
INFO - root - 2019-11-04 03:48:44.786934: step 15870, total loss = 0.47, predict loss = 0.10 (84.7 examples/sec; 0.047 sec/batch; 78h:29m:33s remains)
INFO - root - 2019-11-04 03:48:45.290601: step 15880, total loss = 0.46, predict loss = 0.11 (82.9 examples/sec; 0.048 sec/batch; 80h:12m:32s remains)
INFO - root - 2019-11-04 03:48:45.798050: step 15890, total loss = 0.45, predict loss = 0.10 (93.0 examples/sec; 0.043 sec/batch; 71h:28m:00s remains)
INFO - root - 2019-11-04 03:48:46.309416: step 15900, total loss = 0.41, predict loss = 0.10 (86.9 examples/sec; 0.046 sec/batch; 76h:31m:24s remains)
INFO - root - 2019-11-04 03:48:46.817997: step 15910, total loss = 0.47, predict loss = 0.11 (84.1 examples/sec; 0.048 sec/batch; 79h:02m:24s remains)
INFO - root - 2019-11-04 03:48:47.327128: step 15920, total loss = 0.42, predict loss = 0.08 (85.5 examples/sec; 0.047 sec/batch; 77h:47m:00s remains)
INFO - root - 2019-11-04 03:48:47.845890: step 15930, total loss = 0.39, predict loss = 0.08 (82.9 examples/sec; 0.048 sec/batch; 80h:11m:32s remains)
INFO - root - 2019-11-04 03:48:48.343571: step 15940, total loss = 0.44, predict loss = 0.09 (85.3 examples/sec; 0.047 sec/batch; 77h:54m:51s remains)
INFO - root - 2019-11-04 03:48:48.851964: step 15950, total loss = 0.46, predict loss = 0.11 (87.5 examples/sec; 0.046 sec/batch; 75h:59m:41s remains)
INFO - root - 2019-11-04 03:48:49.359309: step 15960, total loss = 0.61, predict loss = 0.13 (89.3 examples/sec; 0.045 sec/batch; 74h:28m:39s remains)
INFO - root - 2019-11-04 03:48:49.852453: step 15970, total loss = 0.52, predict loss = 0.12 (92.4 examples/sec; 0.043 sec/batch; 71h:58m:05s remains)
INFO - root - 2019-11-04 03:48:50.359174: step 15980, total loss = 0.47, predict loss = 0.11 (89.9 examples/sec; 0.044 sec/batch; 73h:58m:02s remains)
INFO - root - 2019-11-04 03:48:50.865259: step 15990, total loss = 0.46, predict loss = 0.09 (86.9 examples/sec; 0.046 sec/batch; 76h:28m:08s remains)
INFO - root - 2019-11-04 03:48:51.379368: step 16000, total loss = 0.52, predict loss = 0.11 (79.5 examples/sec; 0.050 sec/batch; 83h:37m:45s remains)
INFO - root - 2019-11-04 03:48:51.912998: step 16010, total loss = 0.45, predict loss = 0.10 (85.2 examples/sec; 0.047 sec/batch; 78h:03m:17s remains)
INFO - root - 2019-11-04 03:48:52.418739: step 16020, total loss = 0.46, predict loss = 0.10 (85.6 examples/sec; 0.047 sec/batch; 77h:39m:08s remains)
INFO - root - 2019-11-04 03:48:52.923689: step 16030, total loss = 0.34, predict loss = 0.07 (93.3 examples/sec; 0.043 sec/batch; 71h:16m:15s remains)
INFO - root - 2019-11-04 03:48:53.426678: step 16040, total loss = 0.42, predict loss = 0.09 (86.4 examples/sec; 0.046 sec/batch; 76h:57m:12s remains)
INFO - root - 2019-11-04 03:48:53.931992: step 16050, total loss = 0.60, predict loss = 0.15 (86.1 examples/sec; 0.046 sec/batch; 77h:11m:41s remains)
INFO - root - 2019-11-04 03:48:54.441065: step 16060, total loss = 0.39, predict loss = 0.08 (89.1 examples/sec; 0.045 sec/batch; 74h:35m:27s remains)
INFO - root - 2019-11-04 03:48:54.948361: step 16070, total loss = 0.41, predict loss = 0.09 (84.9 examples/sec; 0.047 sec/batch; 78h:20m:20s remains)
INFO - root - 2019-11-04 03:48:55.467881: step 16080, total loss = 0.48, predict loss = 0.12 (91.4 examples/sec; 0.044 sec/batch; 72h:45m:15s remains)
INFO - root - 2019-11-04 03:48:55.971838: step 16090, total loss = 0.55, predict loss = 0.13 (84.5 examples/sec; 0.047 sec/batch; 78h:39m:33s remains)
INFO - root - 2019-11-04 03:48:56.481253: step 16100, total loss = 0.59, predict loss = 0.12 (83.3 examples/sec; 0.048 sec/batch; 79h:47m:39s remains)
INFO - root - 2019-11-04 03:48:56.981203: step 16110, total loss = 0.52, predict loss = 0.11 (85.3 examples/sec; 0.047 sec/batch; 77h:57m:20s remains)
INFO - root - 2019-11-04 03:48:57.497406: step 16120, total loss = 0.51, predict loss = 0.11 (86.8 examples/sec; 0.046 sec/batch; 76h:36m:19s remains)
INFO - root - 2019-11-04 03:48:57.993232: step 16130, total loss = 0.51, predict loss = 0.13 (88.4 examples/sec; 0.045 sec/batch; 75h:14m:41s remains)
INFO - root - 2019-11-04 03:48:58.481487: step 16140, total loss = 0.64, predict loss = 0.15 (87.9 examples/sec; 0.045 sec/batch; 75h:36m:14s remains)
INFO - root - 2019-11-04 03:48:58.977901: step 16150, total loss = 0.66, predict loss = 0.18 (88.1 examples/sec; 0.045 sec/batch; 75h:29m:47s remains)
INFO - root - 2019-11-04 03:48:59.476346: step 16160, total loss = 0.78, predict loss = 0.19 (85.9 examples/sec; 0.047 sec/batch; 77h:24m:04s remains)
INFO - root - 2019-11-04 03:48:59.968449: step 16170, total loss = 0.59, predict loss = 0.13 (87.3 examples/sec; 0.046 sec/batch; 76h:10m:07s remains)
INFO - root - 2019-11-04 03:49:00.468139: step 16180, total loss = 0.52, predict loss = 0.12 (92.8 examples/sec; 0.043 sec/batch; 71h:40m:38s remains)
INFO - root - 2019-11-04 03:49:00.962405: step 16190, total loss = 0.59, predict loss = 0.13 (84.3 examples/sec; 0.047 sec/batch; 78h:52m:54s remains)
INFO - root - 2019-11-04 03:49:01.461874: step 16200, total loss = 0.28, predict loss = 0.06 (88.3 examples/sec; 0.045 sec/batch; 75h:16m:30s remains)
INFO - root - 2019-11-04 03:49:02.007779: step 16210, total loss = 0.45, predict loss = 0.10 (96.0 examples/sec; 0.042 sec/batch; 69h:13m:58s remains)
INFO - root - 2019-11-04 03:49:02.501670: step 16220, total loss = 0.48, predict loss = 0.11 (86.9 examples/sec; 0.046 sec/batch; 76h:30m:07s remains)
INFO - root - 2019-11-04 03:49:02.986475: step 16230, total loss = 0.36, predict loss = 0.08 (88.4 examples/sec; 0.045 sec/batch; 75h:10m:35s remains)
INFO - root - 2019-11-04 03:49:03.481261: step 16240, total loss = 0.80, predict loss = 0.22 (89.8 examples/sec; 0.045 sec/batch; 74h:00m:09s remains)
INFO - root - 2019-11-04 03:49:03.966709: step 16250, total loss = 0.54, predict loss = 0.12 (90.3 examples/sec; 0.044 sec/batch; 73h:35m:45s remains)
INFO - root - 2019-11-04 03:49:04.466289: step 16260, total loss = 0.43, predict loss = 0.10 (84.5 examples/sec; 0.047 sec/batch; 78h:38m:47s remains)
INFO - root - 2019-11-04 03:49:04.967851: step 16270, total loss = 0.45, predict loss = 0.10 (89.5 examples/sec; 0.045 sec/batch; 74h:19m:17s remains)
INFO - root - 2019-11-04 03:49:05.456358: step 16280, total loss = 0.50, predict loss = 0.12 (90.1 examples/sec; 0.044 sec/batch; 73h:47m:52s remains)
INFO - root - 2019-11-04 03:49:05.951271: step 16290, total loss = 0.36, predict loss = 0.08 (91.7 examples/sec; 0.044 sec/batch; 72h:29m:10s remains)
INFO - root - 2019-11-04 03:49:06.444996: step 16300, total loss = 0.37, predict loss = 0.08 (86.2 examples/sec; 0.046 sec/batch; 77h:05m:19s remains)
INFO - root - 2019-11-04 03:49:06.951903: step 16310, total loss = 0.52, predict loss = 0.11 (85.2 examples/sec; 0.047 sec/batch; 78h:03m:26s remains)
INFO - root - 2019-11-04 03:49:07.448215: step 16320, total loss = 0.47, predict loss = 0.11 (80.2 examples/sec; 0.050 sec/batch; 82h:54m:09s remains)
INFO - root - 2019-11-04 03:49:07.941660: step 16330, total loss = 0.36, predict loss = 0.08 (86.7 examples/sec; 0.046 sec/batch; 76h:42m:50s remains)
INFO - root - 2019-11-04 03:49:08.431892: step 16340, total loss = 0.46, predict loss = 0.10 (102.7 examples/sec; 0.039 sec/batch; 64h:43m:36s remains)
INFO - root - 2019-11-04 03:49:08.878246: step 16350, total loss = 0.52, predict loss = 0.10 (93.1 examples/sec; 0.043 sec/batch; 71h:24m:18s remains)
INFO - root - 2019-11-04 03:49:09.318685: step 16360, total loss = 0.54, predict loss = 0.12 (93.2 examples/sec; 0.043 sec/batch; 71h:19m:07s remains)
INFO - root - 2019-11-04 03:49:10.122955: step 16370, total loss = 0.28, predict loss = 0.06 (75.8 examples/sec; 0.053 sec/batch; 87h:45m:01s remains)
INFO - root - 2019-11-04 03:49:10.734932: step 16380, total loss = 0.31, predict loss = 0.08 (77.3 examples/sec; 0.052 sec/batch; 85h:58m:42s remains)
INFO - root - 2019-11-04 03:49:11.342646: step 16390, total loss = 0.35, predict loss = 0.06 (72.8 examples/sec; 0.055 sec/batch; 91h:15m:48s remains)
INFO - root - 2019-11-04 03:49:11.856817: step 16400, total loss = 0.33, predict loss = 0.07 (85.9 examples/sec; 0.047 sec/batch; 77h:23m:59s remains)
INFO - root - 2019-11-04 03:49:12.361314: step 16410, total loss = 0.50, predict loss = 0.10 (91.9 examples/sec; 0.044 sec/batch; 72h:21m:01s remains)
INFO - root - 2019-11-04 03:49:12.863045: step 16420, total loss = 0.55, predict loss = 0.14 (91.0 examples/sec; 0.044 sec/batch; 73h:04m:38s remains)
INFO - root - 2019-11-04 03:49:13.363330: step 16430, total loss = 0.36, predict loss = 0.07 (85.5 examples/sec; 0.047 sec/batch; 77h:47m:17s remains)
INFO - root - 2019-11-04 03:49:13.858165: step 16440, total loss = 0.42, predict loss = 0.07 (96.8 examples/sec; 0.041 sec/batch; 68h:42m:08s remains)
INFO - root - 2019-11-04 03:49:14.424556: step 16450, total loss = 0.36, predict loss = 0.07 (92.4 examples/sec; 0.043 sec/batch; 71h:56m:50s remains)
INFO - root - 2019-11-04 03:49:14.913304: step 16460, total loss = 0.43, predict loss = 0.11 (89.1 examples/sec; 0.045 sec/batch; 74h:37m:57s remains)
INFO - root - 2019-11-04 03:49:15.413931: step 16470, total loss = 0.42, predict loss = 0.08 (84.4 examples/sec; 0.047 sec/batch; 78h:46m:26s remains)
INFO - root - 2019-11-04 03:49:15.921414: step 16480, total loss = 0.27, predict loss = 0.05 (85.3 examples/sec; 0.047 sec/batch; 77h:56m:44s remains)
INFO - root - 2019-11-04 03:49:16.446314: step 16490, total loss = 0.38, predict loss = 0.07 (80.4 examples/sec; 0.050 sec/batch; 82h:40m:33s remains)
INFO - root - 2019-11-04 03:49:16.951052: step 16500, total loss = 0.47, predict loss = 0.06 (83.8 examples/sec; 0.048 sec/batch; 79h:19m:18s remains)
INFO - root - 2019-11-04 03:49:17.470752: step 16510, total loss = 0.33, predict loss = 0.07 (81.5 examples/sec; 0.049 sec/batch; 81h:37m:25s remains)
INFO - root - 2019-11-04 03:49:18.041402: step 16520, total loss = 0.25, predict loss = 0.04 (73.5 examples/sec; 0.054 sec/batch; 90h:30m:36s remains)
INFO - root - 2019-11-04 03:49:18.643404: step 16530, total loss = 0.39, predict loss = 0.09 (84.7 examples/sec; 0.047 sec/batch; 78h:27m:30s remains)
INFO - root - 2019-11-04 03:49:19.167711: step 16540, total loss = 0.31, predict loss = 0.06 (82.8 examples/sec; 0.048 sec/batch; 80h:20m:03s remains)
INFO - root - 2019-11-04 03:49:19.706263: step 16550, total loss = 0.35, predict loss = 0.08 (84.7 examples/sec; 0.047 sec/batch; 78h:27m:14s remains)
INFO - root - 2019-11-04 03:49:20.243385: step 16560, total loss = 0.36, predict loss = 0.07 (76.8 examples/sec; 0.052 sec/batch; 86h:31m:42s remains)
INFO - root - 2019-11-04 03:49:20.736855: step 16570, total loss = 0.46, predict loss = 0.10 (88.2 examples/sec; 0.045 sec/batch; 75h:24m:41s remains)
INFO - root - 2019-11-04 03:49:21.277778: step 16580, total loss = 0.30, predict loss = 0.05 (70.7 examples/sec; 0.057 sec/batch; 94h:00m:32s remains)
INFO - root - 2019-11-04 03:49:21.870795: step 16590, total loss = 0.31, predict loss = 0.07 (76.6 examples/sec; 0.052 sec/batch; 86h:48m:34s remains)
INFO - root - 2019-11-04 03:49:22.519615: step 16600, total loss = 0.28, predict loss = 0.06 (61.7 examples/sec; 0.065 sec/batch; 107h:42m:50s remains)
INFO - root - 2019-11-04 03:49:23.205541: step 16610, total loss = 0.45, predict loss = 0.09 (53.7 examples/sec; 0.074 sec/batch; 123h:45m:41s remains)
INFO - root - 2019-11-04 03:49:23.794124: step 16620, total loss = 0.60, predict loss = 0.13 (88.3 examples/sec; 0.045 sec/batch; 75h:17m:42s remains)
INFO - root - 2019-11-04 03:49:24.298916: step 16630, total loss = 0.31, predict loss = 0.06 (88.3 examples/sec; 0.045 sec/batch; 75h:15m:49s remains)
INFO - root - 2019-11-04 03:49:24.799070: step 16640, total loss = 0.39, predict loss = 0.08 (86.2 examples/sec; 0.046 sec/batch; 77h:06m:39s remains)
INFO - root - 2019-11-04 03:49:25.296537: step 16650, total loss = 0.38, predict loss = 0.08 (83.3 examples/sec; 0.048 sec/batch; 79h:50m:13s remains)
INFO - root - 2019-11-04 03:49:25.800093: step 16660, total loss = 0.44, predict loss = 0.08 (91.5 examples/sec; 0.044 sec/batch; 72h:39m:06s remains)
INFO - root - 2019-11-04 03:49:26.346062: step 16670, total loss = 0.40, predict loss = 0.08 (80.7 examples/sec; 0.050 sec/batch; 82h:25m:53s remains)
INFO - root - 2019-11-04 03:49:26.960841: step 16680, total loss = 0.43, predict loss = 0.08 (68.2 examples/sec; 0.059 sec/batch; 97h:30m:28s remains)
INFO - root - 2019-11-04 03:49:27.510908: step 16690, total loss = 0.42, predict loss = 0.09 (77.2 examples/sec; 0.052 sec/batch; 86h:04m:22s remains)
INFO - root - 2019-11-04 03:49:28.099210: step 16700, total loss = 0.44, predict loss = 0.08 (52.6 examples/sec; 0.076 sec/batch; 126h:28m:39s remains)
INFO - root - 2019-11-04 03:49:28.665727: step 16710, total loss = 0.48, predict loss = 0.10 (86.7 examples/sec; 0.046 sec/batch; 76h:40m:11s remains)
INFO - root - 2019-11-04 03:49:29.411837: step 16720, total loss = 0.44, predict loss = 0.10 (65.9 examples/sec; 0.061 sec/batch; 100h:55m:54s remains)
INFO - root - 2019-11-04 03:49:30.001565: step 16730, total loss = 0.38, predict loss = 0.08 (68.4 examples/sec; 0.058 sec/batch; 97h:07m:56s remains)
INFO - root - 2019-11-04 03:49:30.598740: step 16740, total loss = 0.33, predict loss = 0.07 (76.1 examples/sec; 0.053 sec/batch; 87h:22m:27s remains)
INFO - root - 2019-11-04 03:49:31.256460: step 16750, total loss = 0.30, predict loss = 0.06 (79.7 examples/sec; 0.050 sec/batch; 83h:22m:19s remains)
INFO - root - 2019-11-04 03:49:31.795029: step 16760, total loss = 0.39, predict loss = 0.08 (79.6 examples/sec; 0.050 sec/batch; 83h:32m:57s remains)
INFO - root - 2019-11-04 03:49:32.336528: step 16770, total loss = 0.46, predict loss = 0.10 (85.2 examples/sec; 0.047 sec/batch; 78h:02m:30s remains)
INFO - root - 2019-11-04 03:49:32.907953: step 16780, total loss = 0.41, predict loss = 0.07 (84.1 examples/sec; 0.048 sec/batch; 79h:05m:00s remains)
INFO - root - 2019-11-04 03:49:33.509572: step 16790, total loss = 0.51, predict loss = 0.12 (73.6 examples/sec; 0.054 sec/batch; 90h:22m:56s remains)
INFO - root - 2019-11-04 03:49:34.093752: step 16800, total loss = 0.49, predict loss = 0.10 (75.3 examples/sec; 0.053 sec/batch; 88h:20m:22s remains)
INFO - root - 2019-11-04 03:49:34.741834: step 16810, total loss = 0.51, predict loss = 0.12 (64.0 examples/sec; 0.062 sec/batch; 103h:49m:01s remains)
