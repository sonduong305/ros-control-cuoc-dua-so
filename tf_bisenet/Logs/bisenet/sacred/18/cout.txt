INFO - bisenet-v2 - Running command 'main'
INFO - bisenet-v2 - Started run with ID "18"
INFO - root - nvidia-ml-py is not installed, automatically select gpu is disabled!
WARNING:tensorflow:From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - tensorflow - From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - root - img_mean is not explicitly specified, using default value: None
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:88: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:88: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:100: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:100: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO - root - preproces -- augment
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:108: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:108: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
/home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:218: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map__image_mirroring, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(_image_mirroring, num_parallel_calls=threads)
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:119: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:119: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:122: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:122: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:123: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:123: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

/home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:220: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map__image_scaling, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(_image_scaling, num_parallel_calls=threads)
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:148: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:148: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

/home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:223: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map_<lambda>, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  num_parallel_calls=threads)
/home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:224: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map_<lambda>, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(lambda image, label: _apply_with_random_selector(image, lambda x, ordering: _distort_color
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:235: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/Dataset/dataset.py:235: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f3a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f3a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f3a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f3a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86eb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86eb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86eb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86eb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d86e978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d86e978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d86e978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d86e978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d86e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d5f66a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d5f66a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d5f66a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d5f66a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f6208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f6208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f6208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5f6208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d580cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d580cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d580cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d580cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d5858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d57ef28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d57ef28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d57ef28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d57ef28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f125d59a2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f125d59a2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f125d59a2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f125d59a2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d885748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d885748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d885748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d885748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d52acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d52acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d52acc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d52acc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d462a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4a9780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4a9780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4a9780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4a9780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3edc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3edc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3edc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3edc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d462550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d462550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d462550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d462550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3ed898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3ed898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3ed898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d3ed898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d5c35f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d5c35f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d5c35f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d5c35f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d59a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d59a550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d59a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d59a550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d59a048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d59a048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d59a048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d59a048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d52aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d52aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d52aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d52aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4baba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4baba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4baba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d4baba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d332048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d332048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d332048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d332048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d332400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d332400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d332400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d332400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d1a7c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d1a7c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d1a7c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d1a7c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d8853c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d8853c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d8853c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d8853c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d0a1518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d0a1518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d0a1518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d0a1518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d126a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d126a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d126a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d126a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cfe3be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cfe3be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cfe3be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cfe3be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a7710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a7710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cf84588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cf84588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cf84588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cf84588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cf51f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cf51f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cf51f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cf51f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08e588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08e588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cfe37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cfe37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cfe37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cfe37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d08efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d0a1e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d0a1e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d0a1e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d0a1e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a77f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a77f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a77f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d1a77f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d516c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d516c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d516c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d516c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ce76208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d526128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cdaad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cdaad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cdaad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cdaad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc9e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc9e320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc9e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc9e320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cdaad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cdaad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cdaad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cdaad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cb97978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cb97978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cb97978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cb97978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d01c7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d01c7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d01c7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d01c7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc5e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc5e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc5e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cc5e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbe0e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbe0e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbe0e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbe0e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ccff048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ccff048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ccff048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125ccff048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda1ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda1ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda1ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda1ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbc82b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbc82b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbc82b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cbc82b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cab5b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca55c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca55c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca55c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca55c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad2080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad2080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad2080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad2080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3d710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3d710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad21d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cad21d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3dfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ca3dfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c81fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c81fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c81fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c81fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125ce76e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c966390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c966390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c966390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c966390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c861710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c861710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c861710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c861710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773b70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c8614e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c8614e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c8614e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c8614e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c73e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c73e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c73e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c73e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c6af0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c6af0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c6af0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c6af0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c773828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c9eb748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c9eb748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c9eb748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c9eb748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c73e908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c966358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c966358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c966358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c966358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c44e9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c44e9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c44e9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c44e9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cd947b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cd947b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cd947b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cd947b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c5434e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c5434e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c5434e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c5434e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c49f668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c49f668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c49f668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c49f668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cda1320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cda1320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cda1320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125cda1320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cb77940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cb77940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cb77940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cb77940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda7ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda7ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda7ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125cda7ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c331588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c331588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c331588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c331588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c411e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c411e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c411e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c411e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b748>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c2b2128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c2b2128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c2b2128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c2b2128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c42b438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c331588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c331588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c331588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c331588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1c4080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1c4080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1c4080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1c4080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1f3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1f3908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1f3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c1f3908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c5c1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c244a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c244a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c244a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c244a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c1c4898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c1c4898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c1c4898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c1c4898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c102cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c102cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c102cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c102cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c0ad978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c0ad978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c0ad978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c0ad978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c43e278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c43e278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c43e278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125c43e278>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0d048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0d048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f08080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f08080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f08080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f08080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa34a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa34a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa34a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa34a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fe6438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fe6438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fe6438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fe6438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257fa3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f8fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f8fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f8fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f8fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0de48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257f0de48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f0de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f0de48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f0de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257f0de48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d0d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d0d668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d0d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d0d668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257d0dc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257d0dc18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257d0dc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257d0dc18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fa3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fa3898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fa3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257fa3898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ce6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ce6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ce6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ce6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f0d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f0d048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f0d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f0d048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257b5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257b5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257b5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257b5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:178: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:178: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d1ab3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d1ab3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d1ab3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125d1ab3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d126a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d126a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d126a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125d126a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257d985f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257d985f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257d985f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257d985f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c460898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c460898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c460898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125c460898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8f898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8f898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8f898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8f898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257dfdda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257dfdda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257dfdda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257dfdda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257b5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257b5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257b5a9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257b5a9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257d7fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12579db2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12579db2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12579db2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12579db2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579ae400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579ae400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579ae400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579ae400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125791cbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125791cbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125791cbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125791cbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257965f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257965f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257965f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257965f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257965f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257965f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257965f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257965f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257890208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257890208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257890208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257890208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125797deb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125797deb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125797deb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125797deb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257f8fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125784f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125784f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125784f7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125784f7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125790f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257830208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257830208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257830208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257830208>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12578309e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12578309e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12578309e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12578309e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579db5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579db5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579db5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12579db5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257717240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257717240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257717240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257717240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257717160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257695438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257695438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257695438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257695438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12575c3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12575c3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12575c3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12575c3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:216: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:216: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:220: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:220: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:223: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:223: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:228: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:228: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:235: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:235: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:239: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING - tensorflow - From /home/nhatdeptrai/Desktop/cuocduaso/bisenet-tensorflow/models/bisenet.py:239: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING:tensorflow:From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - tensorflow - From /home/nhatdeptrai/anaconda3/envs/cuocduaso/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - root - img_mean is not explicitly specified, using default value: None
WARNING - root - random_scale is not explicitly specified, using default value: False
WARNING - root - random_mirror is not explicitly specified, using default value: True
INFO - root - preproces -- None
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257311438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257311438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257311438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257311438>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c47f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c47f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c47f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c47f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c4be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257768940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257768940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257768940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1257768940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728da58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728da58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572d4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572d4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572d4e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572d4e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d4828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d4828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d4828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d4828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c40f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c40f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c40f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12572c40f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d45f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d45f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d45f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572d45f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f12572c4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f12572c4320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f12572c4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f12572c4320>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572d4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572d4160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572d4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572d4160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728dcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728dcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728dcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728dcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257300cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257300cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257300cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257300cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572fffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572fffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572fffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572fffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572fffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572fffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572fffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572fffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ff7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ff7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ff7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ff7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffe48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffe48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffe48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffe48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ffcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728e780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728e780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d423940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d423940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d423940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125d423940>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728def0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257339908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572e0400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572e0400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572e0400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572e0400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257311c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257311c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257311c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257311c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257311eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257311eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257311eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257311eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572a0ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257297a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257297a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257297a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257297a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728e0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728e0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728e0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125728e0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bca20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bca20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bca20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bca20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a0518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a0518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a0518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a0518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c20f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c20f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c20f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c20f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a04a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a04a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a04a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572a04a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ad3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ad3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ad3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572ad3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572c2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572c2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572c2e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572c2e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731f9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731f9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ad9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ad9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ad9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572ad9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731fda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125731fda0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572534a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572534a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572534a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572534a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257274080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257274080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257274080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257274080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125731f160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125731f160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125731f160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125731f160>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c2710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572c2710>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125727f0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125727f0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125727f0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125727f0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572bc4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572747b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572747b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572747b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572747b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e67b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e67b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e67b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e67b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572bc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572bc8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572bc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12572bc8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12572226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726a780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726a780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257222da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257222da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257222da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257222da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726ac88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726ac88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726ac88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125726ac88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257282cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257183a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e9550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e9550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e9550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e9550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257183a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e9400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e9400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e9400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e9400>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bb390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bf8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bf8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bf8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bf8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571bb668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571d6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571d6898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571d6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571d6898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571e6cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571bffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571d6eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571d6eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571d6eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571d6eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125714f4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125714f4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125714f4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125714f4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e95c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e95c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e95c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571e95c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fc88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fa90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125714fa90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257122be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257122be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257122be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257122be0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571a14e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571a14e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571a14e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571a14e0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571b6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571b6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571b6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571b6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125726a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125726a550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125726a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125726a550>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257109e80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257166780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257166780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257166780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257166780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571665c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571665c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571665c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571665c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257109a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570ee470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570ee470>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570ee470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570ee470>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571666d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571666d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571666d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571666d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a40b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a40b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a40b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a40b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570a4390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4d30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4d30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257087080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257087080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257087080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257087080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570a4978>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570feb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570feb38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570feb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570feb38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12571b6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570fef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570fef60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570fef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570fef60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125715bb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125715bb38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125715bb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f125715bb38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571117f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571117f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571117f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12571117f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570fe780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570fe780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570fe780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f12570fe780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257155518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257155518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257155518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257155518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257111668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257111668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257111668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257111668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570c6048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570c6048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570c6048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f12570c6048>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257155358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257155358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257155358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257155358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704da58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704da58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704da58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257129518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257129518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257129518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f1257129518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704d5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704d5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704d5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125704d5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570eea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570eea58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570eea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570eea58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707fb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707fb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707fb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707fb00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125704de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125704de10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125704de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125704de10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707f5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707f5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707f5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f125707f5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125707f198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125707f198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125707f198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125707f198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc59b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc59b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc59b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc59b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125705dd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125705dd68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125705dd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125705dd68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257032e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257032e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257032e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257032e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570320b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570320b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570320b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f12570320b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc5b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc5b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc5b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fc5b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256fee7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256fee7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256fee7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256fee7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f83128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f83128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f83128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f83128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ac9668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ac9668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ac9668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ac9668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f83358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728da20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728da20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728da20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728da20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f4a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f4a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f4a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f4a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728e080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728e080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728e080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728e080>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ae2f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ae2f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ae2f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1257ae2f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f125728d7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256fee908>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f198>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f5f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f5f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f5f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f1256f5f7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256f5f9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING - tensorflow - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1256e98cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING - tensorflow - From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING - tensorflow - From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING - tensorflow - From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING - tensorflow - From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-11-06 17:32:50.404650: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-06 17:32:50.409427: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-11-06 17:32:50.525520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.525992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ca7b1dd20 executing computations on platform CUDA. Devices:
2019-11-06 17:32:50.526009: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-11-06 17:32:50.544733: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-11-06 17:32:50.545150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ca795e030 executing computations on platform Host. Devices:
2019-11-06 17:32:50.545167: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-11-06 17:32:50.545289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.545672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2019-11-06 17:32:50.545807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-11-06 17:32:50.546539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-11-06 17:32:50.547169: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-11-06 17:32:50.547321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-11-06 17:32:50.548111: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-11-06 17:32:50.548692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-11-06 17:32:50.550619: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-11-06 17:32:50.550699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.551112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.551463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-11-06 17:32:50.551488: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-11-06 17:32:50.552111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-11-06 17:32:50.552122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-11-06 17:32:50.552127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-11-06 17:32:50.552285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.552727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-11-06 17:32:50.553098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6827 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-11-06 17:32:51.894422: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO - root - Train for 150000 steps
2019-11-06 17:32:56.981419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
INFO - root - 2019-11-06 17:32:58.473996: step 0, total loss = 4.68, predict loss = 1.37 (0.7 examples/sec; 5.954 sec/batch; 248h:04m:17s remains)
2019-11-06 17:32:59.698002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
INFO - root - 2019-11-06 17:33:01.755690: step 10, total loss = 5.68, predict loss = 1.69 (60.9 examples/sec; 0.066 sec/batch; 2h:44m:18s remains)
INFO - root - 2019-11-06 17:33:02.385408: step 20, total loss = 6.74, predict loss = 1.95 (69.4 examples/sec; 0.058 sec/batch; 2h:24m:09s remains)
INFO - root - 2019-11-06 17:33:03.021136: step 30, total loss = 5.75, predict loss = 1.72 (74.7 examples/sec; 0.054 sec/batch; 2h:13m:48s remains)
INFO - root - 2019-11-06 17:33:03.726208: step 40, total loss = 3.47, predict loss = 1.05 (59.3 examples/sec; 0.067 sec/batch; 2h:48m:28s remains)
INFO - root - 2019-11-06 17:33:04.390552: step 50, total loss = 4.15, predict loss = 1.31 (94.8 examples/sec; 0.042 sec/batch; 1h:45m:25s remains)
INFO - root - 2019-11-06 17:33:04.826059: step 60, total loss = 4.44, predict loss = 1.41 (99.7 examples/sec; 0.040 sec/batch; 1h:40m:18s remains)
INFO - root - 2019-11-06 17:33:05.257124: step 70, total loss = 5.85, predict loss = 1.75 (100.3 examples/sec; 0.040 sec/batch; 1h:39m:38s remains)
INFO - root - 2019-11-06 17:33:06.714712: step 80, total loss = 3.08, predict loss = 0.94 (64.2 examples/sec; 0.062 sec/batch; 2h:35m:43s remains)
INFO - root - 2019-11-06 17:33:07.480629: step 90, total loss = 6.56, predict loss = 1.94 (68.4 examples/sec; 0.058 sec/batch; 2h:26m:06s remains)
INFO - root - 2019-11-06 17:33:08.231388: step 100, total loss = 5.58, predict loss = 1.61 (58.9 examples/sec; 0.068 sec/batch; 2h:49m:37s remains)
INFO - root - 2019-11-06 17:33:09.020837: step 110, total loss = 3.34, predict loss = 1.00 (53.4 examples/sec; 0.075 sec/batch; 3h:07m:16s remains)
INFO - root - 2019-11-06 17:33:09.775121: step 120, total loss = 4.54, predict loss = 1.39 (67.3 examples/sec; 0.059 sec/batch; 2h:28m:33s remains)
INFO - root - 2019-11-06 17:33:10.325095: step 130, total loss = 2.87, predict loss = 0.83 (95.3 examples/sec; 0.042 sec/batch; 1h:44m:49s remains)
INFO - root - 2019-11-06 17:33:10.764104: step 140, total loss = 5.94, predict loss = 1.76 (99.9 examples/sec; 0.040 sec/batch; 1h:39m:59s remains)
INFO - root - 2019-11-06 17:33:11.880773: step 150, total loss = 5.81, predict loss = 1.67 (76.0 examples/sec; 0.053 sec/batch; 2h:11m:25s remains)
INFO - root - 2019-11-06 17:33:12.556108: step 160, total loss = 4.10, predict loss = 1.14 (64.2 examples/sec; 0.062 sec/batch; 2h:35m:31s remains)
INFO - root - 2019-11-06 17:33:13.288192: step 170, total loss = 4.12, predict loss = 1.18 (66.4 examples/sec; 0.060 sec/batch; 2h:30m:28s remains)
INFO - root - 2019-11-06 17:33:13.986158: step 180, total loss = 3.51, predict loss = 1.00 (61.5 examples/sec; 0.065 sec/batch; 2h:42m:30s remains)
INFO - root - 2019-11-06 17:33:14.735549: step 190, total loss = 3.35, predict loss = 0.93 (53.5 examples/sec; 0.075 sec/batch; 3h:06m:35s remains)
INFO - root - 2019-11-06 17:33:15.377630: step 200, total loss = 5.29, predict loss = 1.62 (89.6 examples/sec; 0.045 sec/batch; 1h:51m:29s remains)
INFO - root - 2019-11-06 17:33:15.846041: step 210, total loss = 5.82, predict loss = 1.74 (98.4 examples/sec; 0.041 sec/batch; 1h:41m:29s remains)
INFO - root - 2019-11-06 17:33:16.290322: step 220, total loss = 3.39, predict loss = 1.01 (104.0 examples/sec; 0.038 sec/batch; 1h:36m:02s remains)
INFO - root - 2019-11-06 17:33:17.505020: step 230, total loss = 5.72, predict loss = 1.62 (66.8 examples/sec; 0.060 sec/batch; 2h:29m:31s remains)
INFO - root - 2019-11-06 17:33:18.231000: step 240, total loss = 4.95, predict loss = 1.43 (57.6 examples/sec; 0.069 sec/batch; 2h:53m:11s remains)
INFO - root - 2019-11-06 17:33:19.006304: step 250, total loss = 4.48, predict loss = 1.25 (58.7 examples/sec; 0.068 sec/batch; 2h:50m:11s remains)
INFO - root - 2019-11-06 17:33:19.810785: step 260, total loss = 5.36, predict loss = 1.55 (53.8 examples/sec; 0.074 sec/batch; 3h:05m:34s remains)
INFO - root - 2019-11-06 17:33:20.534490: step 270, total loss = 2.90, predict loss = 0.87 (71.9 examples/sec; 0.056 sec/batch; 2h:18m:45s remains)
INFO - root - 2019-11-06 17:33:21.036874: step 280, total loss = 5.80, predict loss = 1.64 (99.0 examples/sec; 0.040 sec/batch; 1h:40m:49s remains)
INFO - root - 2019-11-06 17:33:21.515778: step 290, total loss = 5.17, predict loss = 1.40 (94.8 examples/sec; 0.042 sec/batch; 1h:45m:18s remains)
INFO - root - 2019-11-06 17:33:22.641099: step 300, total loss = 4.95, predict loss = 1.39 (76.3 examples/sec; 0.052 sec/batch; 2h:10m:48s remains)
INFO - root - 2019-11-06 17:33:23.311583: step 310, total loss = 2.82, predict loss = 0.80 (60.8 examples/sec; 0.066 sec/batch; 2h:44m:09s remains)
INFO - root - 2019-11-06 17:33:23.999445: step 320, total loss = 3.51, predict loss = 0.98 (74.1 examples/sec; 0.054 sec/batch; 2h:14m:37s remains)
INFO - root - 2019-11-06 17:33:24.697925: step 330, total loss = 3.94, predict loss = 1.04 (68.7 examples/sec; 0.058 sec/batch; 2h:25m:13s remains)
INFO - root - 2019-11-06 17:33:25.421372: step 340, total loss = 4.48, predict loss = 1.28 (60.5 examples/sec; 0.066 sec/batch; 2h:45m:00s remains)
INFO - root - 2019-11-06 17:33:25.998117: step 350, total loss = 2.63, predict loss = 0.77 (106.8 examples/sec; 0.037 sec/batch; 1h:33m:22s remains)
INFO - root - 2019-11-06 17:33:26.432288: step 360, total loss = 2.60, predict loss = 0.74 (100.2 examples/sec; 0.040 sec/batch; 1h:39m:34s remains)
INFO - root - 2019-11-06 17:33:26.896659: step 370, total loss = 4.23, predict loss = 1.14 (103.4 examples/sec; 0.039 sec/batch; 1h:36m:29s remains)
INFO - root - 2019-11-06 17:33:28.238413: step 380, total loss = 4.43, predict loss = 1.20 (60.1 examples/sec; 0.067 sec/batch; 2h:45m:58s remains)
INFO - root - 2019-11-06 17:33:28.955034: step 390, total loss = 3.78, predict loss = 1.03 (61.4 examples/sec; 0.065 sec/batch; 2h:42m:24s remains)
INFO - root - 2019-11-06 17:33:29.738341: step 400, total loss = 3.74, predict loss = 0.97 (59.9 examples/sec; 0.067 sec/batch; 2h:46m:26s remains)
INFO - root - 2019-11-06 17:33:30.537911: step 410, total loss = 3.08, predict loss = 0.84 (61.6 examples/sec; 0.065 sec/batch; 2h:41m:55s remains)
INFO - root - 2019-11-06 17:33:31.211433: step 420, total loss = 5.06, predict loss = 1.54 (76.2 examples/sec; 0.052 sec/batch; 2h:10m:48s remains)
INFO - root - 2019-11-06 17:33:31.704612: step 430, total loss = 5.70, predict loss = 1.70 (106.5 examples/sec; 0.038 sec/batch; 1h:33m:35s remains)
INFO - root - 2019-11-06 17:33:32.132366: step 440, total loss = 3.79, predict loss = 1.05 (99.4 examples/sec; 0.040 sec/batch; 1h:40m:17s remains)
INFO - root - 2019-11-06 17:33:33.310630: step 450, total loss = 2.31, predict loss = 0.72 (67.4 examples/sec; 0.059 sec/batch; 2h:27m:50s remains)
INFO - root - 2019-11-06 17:33:34.032854: step 460, total loss = 3.18, predict loss = 0.84 (53.3 examples/sec; 0.075 sec/batch; 3h:07m:10s remains)
INFO - root - 2019-11-06 17:33:34.784593: step 470, total loss = 2.87, predict loss = 0.77 (62.0 examples/sec; 0.065 sec/batch; 2h:40m:53s remains)
INFO - root - 2019-11-06 17:33:35.581008: step 480, total loss = 4.16, predict loss = 1.16 (56.0 examples/sec; 0.071 sec/batch; 2h:57m:53s remains)
INFO - root - 2019-11-06 17:33:36.354203: step 490, total loss = 3.24, predict loss = 0.85 (57.9 examples/sec; 0.069 sec/batch; 2h:52m:05s remains)
INFO - root - 2019-11-06 17:33:36.935085: step 500, total loss = 3.49, predict loss = 0.99 (99.7 examples/sec; 0.040 sec/batch; 1h:39m:56s remains)
INFO - root - 2019-11-06 17:33:37.400115: step 510, total loss = 4.79, predict loss = 1.30 (101.8 examples/sec; 0.039 sec/batch; 1h:37m:51s remains)
INFO - root - 2019-11-06 17:33:37.839437: step 520, total loss = 3.18, predict loss = 0.88 (93.2 examples/sec; 0.043 sec/batch; 1h:46m:53s remains)
INFO - root - 2019-11-06 17:33:39.291596: step 530, total loss = 2.58, predict loss = 0.88 (53.5 examples/sec; 0.075 sec/batch; 3h:06m:21s remains)
INFO - root - 2019-11-06 17:33:40.152709: step 540, total loss = 4.29, predict loss = 1.14 (35.6 examples/sec; 0.112 sec/batch; 4h:39m:38s remains)
INFO - root - 2019-11-06 17:33:40.929273: step 550, total loss = 4.45, predict loss = 1.26 (54.6 examples/sec; 0.073 sec/batch; 3h:02m:27s remains)
INFO - root - 2019-11-06 17:33:41.707841: step 560, total loss = 4.14, predict loss = 1.21 (51.6 examples/sec; 0.077 sec/batch; 3h:12m:57s remains)
INFO - root - 2019-11-06 17:33:42.432916: step 570, total loss = 4.69, predict loss = 1.34 (71.2 examples/sec; 0.056 sec/batch; 2h:19m:52s remains)
INFO - root - 2019-11-06 17:33:42.923886: step 580, total loss = 4.07, predict loss = 1.12 (92.4 examples/sec; 0.043 sec/batch; 1h:47m:48s remains)
INFO - root - 2019-11-06 17:33:43.394364: step 590, total loss = 3.48, predict loss = 0.94 (97.0 examples/sec; 0.041 sec/batch; 1h:42m:38s remains)
INFO - root - 2019-11-06 17:33:44.665743: step 600, total loss = 2.15, predict loss = 0.67 (48.6 examples/sec; 0.082 sec/batch; 3h:24m:53s remains)
INFO - root - 2019-11-06 17:33:45.475664: step 610, total loss = 3.13, predict loss = 0.87 (59.8 examples/sec; 0.067 sec/batch; 2h:46m:26s remains)
INFO - root - 2019-11-06 17:33:46.276567: step 620, total loss = 2.49, predict loss = 0.62 (59.4 examples/sec; 0.067 sec/batch; 2h:47m:42s remains)
INFO - root - 2019-11-06 17:33:46.971136: step 630, total loss = 1.56, predict loss = 0.51 (73.7 examples/sec; 0.054 sec/batch; 2h:15m:05s remains)
INFO - root - 2019-11-06 17:33:47.679373: step 640, total loss = 3.54, predict loss = 0.97 (61.0 examples/sec; 0.066 sec/batch; 2h:43m:21s remains)
INFO - root - 2019-11-06 17:33:48.254212: step 650, total loss = 3.32, predict loss = 0.88 (101.9 examples/sec; 0.039 sec/batch; 1h:37m:43s remains)
INFO - root - 2019-11-06 17:33:48.710390: step 660, total loss = 3.22, predict loss = 0.93 (91.6 examples/sec; 0.044 sec/batch; 1h:48m:42s remains)
INFO - root - 2019-11-06 17:33:49.149678: step 670, total loss = 4.29, predict loss = 1.22 (132.4 examples/sec; 0.030 sec/batch; 1h:15m:12s remains)
INFO - root - 2019-11-06 17:33:50.546373: step 680, total loss = 4.19, predict loss = 1.12 (55.5 examples/sec; 0.072 sec/batch; 2h:59m:27s remains)
INFO - root - 2019-11-06 17:33:51.266246: step 690, total loss = 2.94, predict loss = 0.94 (59.4 examples/sec; 0.067 sec/batch; 2h:47m:34s remains)
INFO - root - 2019-11-06 17:33:52.053085: step 700, total loss = 3.18, predict loss = 0.81 (67.5 examples/sec; 0.059 sec/batch; 2h:27m:33s remains)
INFO - root - 2019-11-06 17:33:52.775495: step 710, total loss = 3.59, predict loss = 0.95 (60.9 examples/sec; 0.066 sec/batch; 2h:43m:21s remains)
INFO - root - 2019-11-06 17:33:53.455011: step 720, total loss = 3.52, predict loss = 0.96 (71.5 examples/sec; 0.056 sec/batch; 2h:19m:09s remains)
INFO - root - 2019-11-06 17:33:53.933744: step 730, total loss = 2.30, predict loss = 0.59 (101.3 examples/sec; 0.039 sec/batch; 1h:38m:13s remains)
INFO - root - 2019-11-06 17:33:54.367825: step 740, total loss = 2.40, predict loss = 0.64 (103.7 examples/sec; 0.039 sec/batch; 1h:36m:00s remains)
INFO - root - 2019-11-06 17:33:55.608626: step 750, total loss = 3.66, predict loss = 0.96 (64.3 examples/sec; 0.062 sec/batch; 2h:34m:51s remains)
INFO - root - 2019-11-06 17:33:56.338143: step 760, total loss = 2.98, predict loss = 0.71 (54.2 examples/sec; 0.074 sec/batch; 3h:03m:41s remains)
INFO - root - 2019-11-06 17:33:57.099559: step 770, total loss = 3.57, predict loss = 0.89 (51.3 examples/sec; 0.078 sec/batch; 3h:13m:45s remains)
INFO - root - 2019-11-06 17:33:57.939835: step 780, total loss = 3.87, predict loss = 1.05 (54.1 examples/sec; 0.074 sec/batch; 3h:03m:54s remains)
INFO - root - 2019-11-06 17:33:58.669395: step 790, total loss = 2.92, predict loss = 0.75 (74.7 examples/sec; 0.054 sec/batch; 2h:13m:06s remains)
INFO - root - 2019-11-06 17:33:59.253154: step 800, total loss = 4.89, predict loss = 1.50 (99.6 examples/sec; 0.040 sec/batch; 1h:39m:53s remains)
INFO - root - 2019-11-06 17:33:59.726659: step 810, total loss = 3.12, predict loss = 0.89 (96.2 examples/sec; 0.042 sec/batch; 1h:43m:20s remains)
INFO - root - 2019-11-06 17:34:00.881428: step 820, total loss = 2.55, predict loss = 0.65 (5.4 examples/sec; 0.736 sec/batch; 30h:28m:59s remains)
INFO - root - 2019-11-06 17:34:01.566737: step 830, total loss = 3.62, predict loss = 1.02 (58.7 examples/sec; 0.068 sec/batch; 2h:49m:28s remains)
INFO - root - 2019-11-06 17:34:02.328998: step 840, total loss = 3.20, predict loss = 0.79 (60.4 examples/sec; 0.066 sec/batch; 2h:44m:32s remains)
INFO - root - 2019-11-06 17:34:03.056763: step 850, total loss = 3.40, predict loss = 0.84 (54.5 examples/sec; 0.073 sec/batch; 3h:02m:29s remains)
INFO - root - 2019-11-06 17:34:03.803237: step 860, total loss = 3.64, predict loss = 0.94 (60.3 examples/sec; 0.066 sec/batch; 2h:44m:47s remains)
INFO - root - 2019-11-06 17:34:04.463201: step 870, total loss = 3.06, predict loss = 0.76 (91.6 examples/sec; 0.044 sec/batch; 1h:48m:33s remains)
INFO - root - 2019-11-06 17:34:04.939846: step 880, total loss = 3.09, predict loss = 0.82 (68.8 examples/sec; 0.058 sec/batch; 2h:24m:34s remains)
INFO - root - 2019-11-06 17:34:05.403794: step 890, total loss = 3.35, predict loss = 0.95 (100.8 examples/sec; 0.040 sec/batch; 1h:38m:36s remains)
INFO - root - 2019-11-06 17:34:06.784009: step 900, total loss = 3.05, predict loss = 0.80 (60.2 examples/sec; 0.066 sec/batch; 2h:45m:00s remains)
INFO - root - 2019-11-06 17:34:07.531902: step 910, total loss = 4.24, predict loss = 1.29 (76.2 examples/sec; 0.053 sec/batch; 2h:10m:31s remains)
INFO - root - 2019-11-06 17:34:08.216244: step 920, total loss = 3.13, predict loss = 0.78 (61.9 examples/sec; 0.065 sec/batch; 2h:40m:36s remains)
INFO - root - 2019-11-06 17:34:09.030709: step 930, total loss = 3.23, predict loss = 0.88 (52.5 examples/sec; 0.076 sec/batch; 3h:09m:26s remains)
INFO - root - 2019-11-06 17:34:09.740991: step 940, total loss = 2.19, predict loss = 0.66 (63.7 examples/sec; 0.063 sec/batch; 2h:36m:00s remains)
INFO - root - 2019-11-06 17:34:10.286418: step 950, total loss = 3.15, predict loss = 0.79 (99.1 examples/sec; 0.040 sec/batch; 1h:40m:19s remains)
INFO - root - 2019-11-06 17:34:10.731391: step 960, total loss = 3.18, predict loss = 0.77 (99.9 examples/sec; 0.040 sec/batch; 1h:39m:25s remains)
INFO - root - 2019-11-06 17:34:11.904350: step 970, total loss = 3.07, predict loss = 0.76 (66.1 examples/sec; 0.060 sec/batch; 2h:30m:14s remains)
INFO - root - 2019-11-06 17:34:12.585810: step 980, total loss = 2.77, predict loss = 0.71 (56.1 examples/sec; 0.071 sec/batch; 2h:57m:08s remains)
INFO - root - 2019-11-06 17:34:13.303830: step 990, total loss = 3.48, predict loss = 0.91 (61.2 examples/sec; 0.065 sec/batch; 2h:42m:14s remains)
INFO - root - 2019-11-06 17:34:14.102067: step 1000, total loss = 3.22, predict loss = 0.86 (56.4 examples/sec; 0.071 sec/batch; 2h:56m:08s remains)
INFO - root - 2019-11-06 17:34:14.860000: step 1010, total loss = 1.83, predict loss = 0.50 (51.2 examples/sec; 0.078 sec/batch; 3h:14m:02s remains)
INFO - root - 2019-11-06 17:34:15.473023: step 1020, total loss = 2.45, predict loss = 0.70 (85.4 examples/sec; 0.047 sec/batch; 1h:56m:15s remains)
INFO - root - 2019-11-06 17:34:15.903701: step 1030, total loss = 1.81, predict loss = 0.48 (99.8 examples/sec; 0.040 sec/batch; 1h:39m:30s remains)
INFO - root - 2019-11-06 17:34:16.352174: step 1040, total loss = 3.10, predict loss = 0.82 (106.3 examples/sec; 0.038 sec/batch; 1h:33m:25s remains)
INFO - root - 2019-11-06 17:34:17.653632: step 1050, total loss = 3.93, predict loss = 1.07 (58.5 examples/sec; 0.068 sec/batch; 2h:49m:44s remains)
INFO - root - 2019-11-06 17:34:18.385777: step 1060, total loss = 3.17, predict loss = 0.76 (56.6 examples/sec; 0.071 sec/batch; 2h:55m:19s remains)
INFO - root - 2019-11-06 17:34:19.153011: step 1070, total loss = 3.32, predict loss = 0.85 (62.0 examples/sec; 0.064 sec/batch; 2h:40m:01s remains)
INFO - root - 2019-11-06 17:34:19.864617: step 1080, total loss = 4.21, predict loss = 1.19 (69.4 examples/sec; 0.058 sec/batch; 2h:22m:58s remains)
INFO - root - 2019-11-06 17:34:20.601668: step 1090, total loss = 3.28, predict loss = 0.85 (66.0 examples/sec; 0.061 sec/batch; 2h:30m:26s remains)
INFO - root - 2019-11-06 17:34:21.108487: step 1100, total loss = 4.25, predict loss = 1.17 (107.3 examples/sec; 0.037 sec/batch; 1h:32m:31s remains)
INFO - root - 2019-11-06 17:34:21.541060: step 1110, total loss = 3.13, predict loss = 0.82 (98.8 examples/sec; 0.040 sec/batch; 1h:40m:27s remains)
INFO - root - 2019-11-06 17:34:22.759736: step 1120, total loss = 3.33, predict loss = 0.77 (69.5 examples/sec; 0.058 sec/batch; 2h:22m:43s remains)
INFO - root - 2019-11-06 17:34:23.490090: step 1130, total loss = 2.56, predict loss = 0.63 (62.0 examples/sec; 0.064 sec/batch; 2h:39m:58s remains)
INFO - root - 2019-11-06 17:34:24.194751: step 1140, total loss = 2.44, predict loss = 0.58 (63.8 examples/sec; 0.063 sec/batch; 2h:35m:25s remains)
INFO - root - 2019-11-06 17:34:24.889577: step 1150, total loss = 3.46, predict loss = 0.92 (66.0 examples/sec; 0.061 sec/batch; 2h:30m:17s remains)
INFO - root - 2019-11-06 17:34:25.606899: step 1160, total loss = 3.13, predict loss = 0.79 (58.3 examples/sec; 0.069 sec/batch; 2h:50m:09s remains)
INFO - root - 2019-11-06 17:34:26.260493: step 1170, total loss = 3.16, predict loss = 0.84 (101.2 examples/sec; 0.040 sec/batch; 1h:38m:04s remains)
INFO - root - 2019-11-06 17:34:26.697629: step 1180, total loss = 1.65, predict loss = 0.41 (101.7 examples/sec; 0.039 sec/batch; 1h:37m:31s remains)
INFO - root - 2019-11-06 17:34:27.142311: step 1190, total loss = 2.57, predict loss = 0.64 (89.3 examples/sec; 0.045 sec/batch; 1h:51m:06s remains)
INFO - root - 2019-11-06 17:34:28.393246: step 1200, total loss = 2.10, predict loss = 0.57 (61.1 examples/sec; 0.065 sec/batch; 2h:42m:15s remains)
INFO - root - 2019-11-06 17:34:29.154490: step 1210, total loss = 2.45, predict loss = 0.56 (65.7 examples/sec; 0.061 sec/batch; 2h:30m:53s remains)
INFO - root - 2019-11-06 17:34:29.917502: step 1220, total loss = 2.42, predict loss = 0.62 (59.3 examples/sec; 0.067 sec/batch; 2h:47m:18s remains)
INFO - root - 2019-11-06 17:34:30.660075: step 1230, total loss = 4.33, predict loss = 1.27 (63.2 examples/sec; 0.063 sec/batch; 2h:36m:56s remains)
INFO - root - 2019-11-06 17:34:31.368913: step 1240, total loss = 2.32, predict loss = 0.55 (66.9 examples/sec; 0.060 sec/batch; 2h:28m:17s remains)
INFO - root - 2019-11-06 17:34:31.900086: step 1250, total loss = 2.94, predict loss = 0.76 (106.3 examples/sec; 0.038 sec/batch; 1h:33m:16s remains)
INFO - root - 2019-11-06 17:34:32.341326: step 1260, total loss = 3.46, predict loss = 1.01 (97.0 examples/sec; 0.041 sec/batch; 1h:42m:14s remains)
INFO - root - 2019-11-06 17:34:33.452952: step 1270, total loss = 3.56, predict loss = 0.96 (76.0 examples/sec; 0.053 sec/batch; 2h:10m:26s remains)
INFO - root - 2019-11-06 17:34:34.144460: step 1280, total loss = 2.23, predict loss = 0.58 (67.9 examples/sec; 0.059 sec/batch; 2h:26m:07s remains)
INFO - root - 2019-11-06 17:34:34.896338: step 1290, total loss = 1.63, predict loss = 0.43 (61.8 examples/sec; 0.065 sec/batch; 2h:40m:22s remains)
INFO - root - 2019-11-06 17:34:35.643842: step 1300, total loss = 2.72, predict loss = 0.68 (55.6 examples/sec; 0.072 sec/batch; 2h:58m:24s remains)
INFO - root - 2019-11-06 17:34:36.411763: step 1310, total loss = 1.73, predict loss = 0.43 (59.7 examples/sec; 0.067 sec/batch; 2h:46m:01s remains)
INFO - root - 2019-11-06 17:34:37.034838: step 1320, total loss = 3.14, predict loss = 0.89 (96.9 examples/sec; 0.041 sec/batch; 1h:42m:15s remains)
INFO - root - 2019-11-06 17:34:37.516065: step 1330, total loss = 2.69, predict loss = 0.63 (87.6 examples/sec; 0.046 sec/batch; 1h:53m:10s remains)
INFO - root - 2019-11-06 17:34:37.979482: step 1340, total loss = 4.00, predict loss = 1.16 (92.3 examples/sec; 0.043 sec/batch; 1h:47m:22s remains)
INFO - root - 2019-11-06 17:34:39.281719: step 1350, total loss = 1.78, predict loss = 0.46 (57.3 examples/sec; 0.070 sec/batch; 2h:52m:51s remains)
INFO - root - 2019-11-06 17:34:40.021436: step 1360, total loss = 2.50, predict loss = 0.55 (62.6 examples/sec; 0.064 sec/batch; 2h:38m:16s remains)
INFO - root - 2019-11-06 17:34:40.762045: step 1370, total loss = 3.23, predict loss = 0.83 (57.3 examples/sec; 0.070 sec/batch; 2h:52m:48s remains)
INFO - root - 2019-11-06 17:34:41.535883: step 1380, total loss = 4.14, predict loss = 1.25 (51.5 examples/sec; 0.078 sec/batch; 3h:12m:15s remains)
INFO - root - 2019-11-06 17:34:42.237865: step 1390, total loss = 3.34, predict loss = 0.95 (68.9 examples/sec; 0.058 sec/batch; 2h:23m:45s remains)
INFO - root - 2019-11-06 17:34:42.708729: step 1400, total loss = 3.59, predict loss = 1.01 (91.8 examples/sec; 0.044 sec/batch; 1h:47m:54s remains)
INFO - root - 2019-11-06 17:34:43.179061: step 1410, total loss = 2.24, predict loss = 0.56 (98.0 examples/sec; 0.041 sec/batch; 1h:41m:05s remains)
INFO - root - 2019-11-06 17:34:44.341107: step 1420, total loss = 2.32, predict loss = 0.63 (61.5 examples/sec; 0.065 sec/batch; 2h:41m:03s remains)
INFO - root - 2019-11-06 17:34:45.058411: step 1430, total loss = 2.46, predict loss = 0.63 (65.3 examples/sec; 0.061 sec/batch; 2h:31m:35s remains)
INFO - root - 2019-11-06 17:34:45.783778: step 1440, total loss = 2.84, predict loss = 0.74 (62.3 examples/sec; 0.064 sec/batch; 2h:39m:04s remains)
INFO - root - 2019-11-06 17:34:46.535020: step 1450, total loss = 2.63, predict loss = 0.64 (56.2 examples/sec; 0.071 sec/batch; 2h:56m:05s remains)
INFO - root - 2019-11-06 17:34:47.225400: step 1460, total loss = 2.22, predict loss = 0.62 (72.5 examples/sec; 0.055 sec/batch; 2h:16m:39s remains)
INFO - root - 2019-11-06 17:34:47.782182: step 1470, total loss = 1.51, predict loss = 0.42 (98.2 examples/sec; 0.041 sec/batch; 1h:40m:49s remains)
INFO - root - 2019-11-06 17:34:48.232687: step 1480, total loss = 2.42, predict loss = 0.62 (98.5 examples/sec; 0.041 sec/batch; 1h:40m:32s remains)
INFO - root - 2019-11-06 17:34:48.693904: step 1490, total loss = 3.20, predict loss = 0.99 (141.0 examples/sec; 0.028 sec/batch; 1h:10m:11s remains)
INFO - root - 2019-11-06 17:34:49.969860: step 1500, total loss = 1.71, predict loss = 0.43 (59.1 examples/sec; 0.068 sec/batch; 2h:47m:37s remains)
INFO - root - 2019-11-06 17:34:50.725180: step 1510, total loss = 2.48, predict loss = 0.57 (66.2 examples/sec; 0.060 sec/batch; 2h:29m:29s remains)
INFO - root - 2019-11-06 17:34:51.549134: step 1520, total loss = 2.66, predict loss = 0.63 (45.5 examples/sec; 0.088 sec/batch; 3h:37m:28s remains)
INFO - root - 2019-11-06 17:34:52.299116: step 1530, total loss = 2.55, predict loss = 0.64 (60.7 examples/sec; 0.066 sec/batch; 2h:43m:03s remains)
INFO - root - 2019-11-06 17:34:52.956084: step 1540, total loss = 1.21, predict loss = 0.32 (76.9 examples/sec; 0.052 sec/batch; 2h:08m:47s remains)
INFO - root - 2019-11-06 17:34:53.426515: step 1550, total loss = 2.02, predict loss = 0.46 (96.0 examples/sec; 0.042 sec/batch; 1h:43m:07s remains)
INFO - root - 2019-11-06 17:34:53.873289: step 1560, total loss = 1.52, predict loss = 0.44 (100.0 examples/sec; 0.040 sec/batch; 1h:38m:57s remains)
INFO - root - 2019-11-06 17:34:55.068194: step 1570, total loss = 3.18, predict loss = 0.80 (66.7 examples/sec; 0.060 sec/batch; 2h:28m:23s remains)
INFO - root - 2019-11-06 17:34:55.864098: step 1580, total loss = 3.19, predict loss = 0.85 (50.6 examples/sec; 0.079 sec/batch; 3h:15m:32s remains)
INFO - root - 2019-11-06 17:34:56.630532: step 1590, total loss = 2.29, predict loss = 0.62 (51.0 examples/sec; 0.078 sec/batch; 3h:13m:52s remains)
INFO - root - 2019-11-06 17:34:57.364941: step 1600, total loss = 2.97, predict loss = 0.77 (57.5 examples/sec; 0.070 sec/batch; 2h:52m:06s remains)
INFO - root - 2019-11-06 17:34:58.146597: step 1610, total loss = 1.50, predict loss = 0.41 (61.6 examples/sec; 0.065 sec/batch; 2h:40m:32s remains)
INFO - root - 2019-11-06 17:34:58.692133: step 1620, total loss = 2.51, predict loss = 0.72 (93.4 examples/sec; 0.043 sec/batch; 1h:45m:52s remains)
INFO - root - 2019-11-06 17:34:59.158210: step 1630, total loss = 2.27, predict loss = 0.56 (94.2 examples/sec; 0.042 sec/batch; 1h:44m:56s remains)
INFO - root - 2019-11-06 17:35:00.263111: step 1640, total loss = 2.88, predict loss = 0.79 (5.7 examples/sec; 0.697 sec/batch; 28h:42m:28s remains)
INFO - root - 2019-11-06 17:35:00.977613: step 1650, total loss = 1.74, predict loss = 0.46 (60.1 examples/sec; 0.067 sec/batch; 2h:44m:34s remains)
INFO - root - 2019-11-06 17:35:01.701705: step 1660, total loss = 2.67, predict loss = 0.68 (59.5 examples/sec; 0.067 sec/batch; 2h:46m:12s remains)
INFO - root - 2019-11-06 17:35:02.500850: step 1670, total loss = 1.93, predict loss = 0.47 (56.8 examples/sec; 0.070 sec/batch; 2h:54m:07s remains)
INFO - root - 2019-11-06 17:35:03.257798: step 1680, total loss = 2.44, predict loss = 0.58 (57.8 examples/sec; 0.069 sec/batch; 2h:51m:04s remains)
INFO - root - 2019-11-06 17:35:03.932195: step 1690, total loss = 2.41, predict loss = 0.65 (89.6 examples/sec; 0.045 sec/batch; 1h:50m:18s remains)
INFO - root - 2019-11-06 17:35:04.406247: step 1700, total loss = 2.53, predict loss = 0.74 (100.5 examples/sec; 0.040 sec/batch; 1h:38m:22s remains)
INFO - root - 2019-11-06 17:35:04.840813: step 1710, total loss = 0.99, predict loss = 0.29 (105.5 examples/sec; 0.038 sec/batch; 1h:33m:44s remains)
INFO - root - 2019-11-06 17:35:06.025204: step 1720, total loss = 3.24, predict loss = 0.98 (59.9 examples/sec; 0.067 sec/batch; 2h:45m:02s remains)
INFO - root - 2019-11-06 17:35:06.760309: step 1730, total loss = 1.86, predict loss = 0.45 (65.5 examples/sec; 0.061 sec/batch; 2h:30m:50s remains)
INFO - root - 2019-11-06 17:35:07.508218: step 1740, total loss = 2.26, predict loss = 0.61 (48.5 examples/sec; 0.082 sec/batch; 3h:23m:44s remains)
INFO - root - 2019-11-06 17:35:08.342996: step 1750, total loss = 1.66, predict loss = 0.44 (53.3 examples/sec; 0.075 sec/batch; 3h:05m:35s remains)
INFO - root - 2019-11-06 17:35:09.146224: step 1760, total loss = 2.97, predict loss = 0.72 (63.9 examples/sec; 0.063 sec/batch; 2h:34m:44s remains)
INFO - root - 2019-11-06 17:35:09.724159: step 1770, total loss = 1.67, predict loss = 0.38 (98.8 examples/sec; 0.040 sec/batch; 1h:39m:59s remains)
INFO - root - 2019-11-06 17:35:10.162820: step 1780, total loss = 2.79, predict loss = 0.75 (103.3 examples/sec; 0.039 sec/batch; 1h:35m:40s remains)
INFO - root - 2019-11-06 17:35:11.261896: step 1790, total loss = 3.02, predict loss = 0.88 (71.5 examples/sec; 0.056 sec/batch; 2h:18m:09s remains)
INFO - root - 2019-11-06 17:35:11.947481: step 1800, total loss = 2.81, predict loss = 0.72 (65.2 examples/sec; 0.061 sec/batch; 2h:31m:27s remains)
INFO - root - 2019-11-06 17:35:12.726447: step 1810, total loss = 3.25, predict loss = 0.93 (57.9 examples/sec; 0.069 sec/batch; 2h:50m:31s remains)
INFO - root - 2019-11-06 17:35:13.499196: step 1820, total loss = 1.93, predict loss = 0.52 (64.3 examples/sec; 0.062 sec/batch; 2h:33m:31s remains)
INFO - root - 2019-11-06 17:35:14.194329: step 1830, total loss = 1.94, predict loss = 0.46 (66.4 examples/sec; 0.060 sec/batch; 2h:28m:39s remains)
INFO - root - 2019-11-06 17:35:14.848513: step 1840, total loss = 2.61, predict loss = 0.64 (87.4 examples/sec; 0.046 sec/batch; 1h:53m:02s remains)
INFO - root - 2019-11-06 17:35:15.341898: step 1850, total loss = 1.81, predict loss = 0.41 (97.5 examples/sec; 0.041 sec/batch; 1h:41m:19s remains)
INFO - root - 2019-11-06 17:35:15.810009: step 1860, total loss = 2.39, predict loss = 0.69 (97.0 examples/sec; 0.041 sec/batch; 1h:41m:45s remains)
INFO - root - 2019-11-06 17:35:17.045274: step 1870, total loss = 2.49, predict loss = 0.63 (55.0 examples/sec; 0.073 sec/batch; 2h:59m:34s remains)
INFO - root - 2019-11-06 17:35:17.774497: step 1880, total loss = 2.12, predict loss = 0.45 (63.1 examples/sec; 0.063 sec/batch; 2h:36m:28s remains)
INFO - root - 2019-11-06 17:35:18.517702: step 1890, total loss = 1.71, predict loss = 0.49 (59.5 examples/sec; 0.067 sec/batch; 2h:45m:58s remains)
INFO - root - 2019-11-06 17:35:19.308720: step 1900, total loss = 2.98, predict loss = 0.73 (53.7 examples/sec; 0.075 sec/batch; 3h:03m:53s remains)
INFO - root - 2019-11-06 17:35:19.987409: step 1910, total loss = 1.74, predict loss = 0.44 (78.3 examples/sec; 0.051 sec/batch; 2h:06m:04s remains)
INFO - root - 2019-11-06 17:35:20.469124: step 1920, total loss = 2.56, predict loss = 0.67 (100.8 examples/sec; 0.040 sec/batch; 1h:37m:54s remains)
INFO - root - 2019-11-06 17:35:20.942817: step 1930, total loss = 2.57, predict loss = 0.67 (92.5 examples/sec; 0.043 sec/batch; 1h:46m:46s remains)
INFO - root - 2019-11-06 17:35:22.082974: step 1940, total loss = 1.41, predict loss = 0.39 (67.8 examples/sec; 0.059 sec/batch; 2h:25m:35s remains)
INFO - root - 2019-11-06 17:35:22.791902: step 1950, total loss = 2.83, predict loss = 0.68 (58.6 examples/sec; 0.068 sec/batch; 2h:48m:33s remains)
INFO - root - 2019-11-06 17:35:23.528430: step 1960, total loss = 2.50, predict loss = 0.62 (56.5 examples/sec; 0.071 sec/batch; 2h:54m:33s remains)
INFO - root - 2019-11-06 17:35:24.298062: step 1970, total loss = 2.43, predict loss = 0.59 (59.4 examples/sec; 0.067 sec/batch; 2h:46m:12s remains)
INFO - root - 2019-11-06 17:35:25.048015: step 1980, total loss = 2.96, predict loss = 0.87 (65.5 examples/sec; 0.061 sec/batch; 2h:30m:40s remains)
INFO - root - 2019-11-06 17:35:25.639763: step 1990, total loss = 2.37, predict loss = 0.57 (103.6 examples/sec; 0.039 sec/batch; 1h:35m:15s remains)
INFO - root - 2019-11-06 17:35:26.078703: step 2000, total loss = 1.71, predict loss = 0.39 (95.2 examples/sec; 0.042 sec/batch; 1h:43m:36s remains)
INFO - root - 2019-11-06 17:35:26.554862: step 2010, total loss = 2.36, predict loss = 0.76 (101.1 examples/sec; 0.040 sec/batch; 1h:37m:35s remains)
INFO - root - 2019-11-06 17:35:27.771203: step 2020, total loss = 1.71, predict loss = 0.38 (70.1 examples/sec; 0.057 sec/batch; 2h:20m:42s remains)
INFO - root - 2019-11-06 17:35:28.467254: step 2030, total loss = 1.42, predict loss = 0.29 (62.7 examples/sec; 0.064 sec/batch; 2h:37m:12s remains)
INFO - root - 2019-11-06 17:35:29.214350: step 2040, total loss = 2.16, predict loss = 0.49 (51.7 examples/sec; 0.077 sec/batch; 3h:10m:41s remains)
INFO - root - 2019-11-06 17:35:29.957603: step 2050, total loss = 2.39, predict loss = 0.67 (53.8 examples/sec; 0.074 sec/batch; 3h:03m:20s remains)
INFO - root - 2019-11-06 17:35:30.602730: step 2060, total loss = 1.70, predict loss = 0.39 (78.0 examples/sec; 0.051 sec/batch; 2h:06m:29s remains)
INFO - root - 2019-11-06 17:35:31.058175: step 2070, total loss = 1.68, predict loss = 0.41 (98.5 examples/sec; 0.041 sec/batch; 1h:40m:05s remains)
INFO - root - 2019-11-06 17:35:31.505690: step 2080, total loss = 2.02, predict loss = 0.53 (105.7 examples/sec; 0.038 sec/batch; 1h:33m:15s remains)
INFO - root - 2019-11-06 17:35:32.710843: step 2090, total loss = 2.27, predict loss = 0.57 (68.7 examples/sec; 0.058 sec/batch; 2h:23m:30s remains)
INFO - root - 2019-11-06 17:35:33.478177: step 2100, total loss = 2.00, predict loss = 0.50 (58.5 examples/sec; 0.068 sec/batch; 2h:48m:31s remains)
INFO - root - 2019-11-06 17:35:34.225128: step 2110, total loss = 2.11, predict loss = 0.48 (61.9 examples/sec; 0.065 sec/batch; 2h:39m:13s remains)
INFO - root - 2019-11-06 17:35:34.985206: step 2120, total loss = 2.30, predict loss = 0.58 (58.6 examples/sec; 0.068 sec/batch; 2h:48m:19s remains)
INFO - root - 2019-11-06 17:35:35.738381: step 2130, total loss = 2.06, predict loss = 0.51 (56.2 examples/sec; 0.071 sec/batch; 2h:55m:25s remains)
INFO - root - 2019-11-06 17:35:36.326074: step 2140, total loss = 2.08, predict loss = 0.55 (98.6 examples/sec; 0.041 sec/batch; 1h:39m:57s remains)
INFO - root - 2019-11-06 17:35:36.776406: step 2150, total loss = 2.32, predict loss = 0.59 (96.7 examples/sec; 0.041 sec/batch; 1h:41m:57s remains)
INFO - root - 2019-11-06 17:35:37.228552: step 2160, total loss = 1.66, predict loss = 0.37 (92.4 examples/sec; 0.043 sec/batch; 1h:46m:43s remains)
INFO - root - 2019-11-06 17:35:38.573172: step 2170, total loss = 2.15, predict loss = 0.53 (68.2 examples/sec; 0.059 sec/batch; 2h:24m:33s remains)
INFO - root - 2019-11-06 17:35:39.327308: step 2180, total loss = 1.46, predict loss = 0.32 (52.3 examples/sec; 0.076 sec/batch; 3h:08m:18s remains)
INFO - root - 2019-11-06 17:35:40.062781: step 2190, total loss = 2.99, predict loss = 0.81 (61.4 examples/sec; 0.065 sec/batch; 2h:40m:31s remains)
INFO - root - 2019-11-06 17:35:40.831033: step 2200, total loss = 1.68, predict loss = 0.39 (58.0 examples/sec; 0.069 sec/batch; 2h:50m:00s remains)
INFO - root - 2019-11-06 17:35:41.582333: step 2210, total loss = 2.29, predict loss = 0.66 (68.5 examples/sec; 0.058 sec/batch; 2h:23m:46s remains)
INFO - root - 2019-11-06 17:35:42.074042: step 2220, total loss = 2.83, predict loss = 0.80 (101.7 examples/sec; 0.039 sec/batch; 1h:36m:50s remains)
INFO - root - 2019-11-06 17:35:42.523077: step 2230, total loss = 2.34, predict loss = 0.63 (92.6 examples/sec; 0.043 sec/batch; 1h:46m:20s remains)
INFO - root - 2019-11-06 17:35:43.670009: step 2240, total loss = 2.45, predict loss = 0.53 (65.5 examples/sec; 0.061 sec/batch; 2h:30m:25s remains)
INFO - root - 2019-11-06 17:35:44.397094: step 2250, total loss = 3.08, predict loss = 0.84 (57.4 examples/sec; 0.070 sec/batch; 2h:51m:33s remains)
INFO - root - 2019-11-06 17:35:45.108736: step 2260, total loss = 1.49, predict loss = 0.36 (59.4 examples/sec; 0.067 sec/batch; 2h:45m:46s remains)
INFO - root - 2019-11-06 17:35:45.834800: step 2270, total loss = 2.49, predict loss = 0.58 (53.3 examples/sec; 0.075 sec/batch; 3h:04m:49s remains)
INFO - root - 2019-11-06 17:35:46.597738: step 2280, total loss = 2.10, predict loss = 0.54 (62.5 examples/sec; 0.064 sec/batch; 2h:37m:39s remains)
INFO - root - 2019-11-06 17:35:47.179735: step 2290, total loss = 1.52, predict loss = 0.35 (104.7 examples/sec; 0.038 sec/batch; 1h:34m:01s remains)
INFO - root - 2019-11-06 17:35:47.635193: step 2300, total loss = 2.00, predict loss = 0.47 (94.5 examples/sec; 0.042 sec/batch; 1h:44m:08s remains)
INFO - root - 2019-11-06 17:35:48.070382: step 2310, total loss = 2.78, predict loss = 0.88 (124.2 examples/sec; 0.032 sec/batch; 1h:19m:15s remains)
INFO - root - 2019-11-06 17:35:49.412483: step 2320, total loss = 1.93, predict loss = 0.41 (57.7 examples/sec; 0.069 sec/batch; 2h:50m:33s remains)
INFO - root - 2019-11-06 17:35:50.221020: step 2330, total loss = 1.56, predict loss = 0.38 (54.5 examples/sec; 0.073 sec/batch; 3h:00m:29s remains)
INFO - root - 2019-11-06 17:35:50.970400: step 2340, total loss = 2.02, predict loss = 0.55 (58.1 examples/sec; 0.069 sec/batch; 2h:49m:20s remains)
INFO - root - 2019-11-06 17:35:51.695099: step 2350, total loss = 2.14, predict loss = 0.57 (62.4 examples/sec; 0.064 sec/batch; 2h:37m:45s remains)
INFO - root - 2019-11-06 17:35:52.313743: step 2360, total loss = 2.00, predict loss = 0.49 (77.1 examples/sec; 0.052 sec/batch; 2h:07m:37s remains)
INFO - root - 2019-11-06 17:35:52.775130: step 2370, total loss = 1.79, predict loss = 0.47 (101.5 examples/sec; 0.039 sec/batch; 1h:37m:00s remains)
INFO - root - 2019-11-06 17:35:53.237039: step 2380, total loss = 2.23, predict loss = 0.59 (97.2 examples/sec; 0.041 sec/batch; 1h:41m:13s remains)
INFO - root - 2019-11-06 17:35:54.665252: step 2390, total loss = 2.08, predict loss = 0.52 (59.0 examples/sec; 0.068 sec/batch; 2h:46m:47s remains)
INFO - root - 2019-11-06 17:35:55.326238: step 2400, total loss = 2.02, predict loss = 0.54 (59.6 examples/sec; 0.067 sec/batch; 2h:45m:12s remains)
INFO - root - 2019-11-06 17:35:56.123130: step 2410, total loss = 1.46, predict loss = 0.36 (44.3 examples/sec; 0.090 sec/batch; 3h:42m:17s remains)
INFO - root - 2019-11-06 17:35:56.889946: step 2420, total loss = 2.66, predict loss = 0.76 (56.2 examples/sec; 0.071 sec/batch; 2h:54m:55s remains)
INFO - root - 2019-11-06 17:35:57.646271: step 2430, total loss = 1.94, predict loss = 0.46 (67.5 examples/sec; 0.059 sec/batch; 2h:25m:50s remains)
INFO - root - 2019-11-06 17:35:58.190798: step 2440, total loss = 2.00, predict loss = 0.45 (100.5 examples/sec; 0.040 sec/batch; 1h:37m:55s remains)
INFO - root - 2019-11-06 17:35:58.651794: step 2450, total loss = 1.69, predict loss = 0.46 (100.9 examples/sec; 0.040 sec/batch; 1h:37m:31s remains)
INFO - root - 2019-11-06 17:35:59.736653: step 2460, total loss = 1.34, predict loss = 0.34 (5.7 examples/sec; 0.702 sec/batch; 28h:46m:19s remains)
INFO - root - 2019-11-06 17:36:00.430824: step 2470, total loss = 1.52, predict loss = 0.39 (60.3 examples/sec; 0.066 sec/batch; 2h:43m:13s remains)
INFO - root - 2019-11-06 17:36:01.184789: step 2480, total loss = 1.10, predict loss = 0.27 (59.2 examples/sec; 0.068 sec/batch; 2h:46m:02s remains)
INFO - root - 2019-11-06 17:36:01.988494: step 2490, total loss = 1.73, predict loss = 0.42 (52.6 examples/sec; 0.076 sec/batch; 3h:07m:07s remains)
INFO - root - 2019-11-06 17:36:02.721726: step 2500, total loss = 1.85, predict loss = 0.43 (55.1 examples/sec; 0.073 sec/batch; 2h:58m:28s remains)
INFO - root - 2019-11-06 17:36:03.346756: step 2510, total loss = 1.32, predict loss = 0.33 (97.2 examples/sec; 0.041 sec/batch; 1h:41m:06s remains)
INFO - root - 2019-11-06 17:36:03.787201: step 2520, total loss = 2.18, predict loss = 0.54 (94.4 examples/sec; 0.042 sec/batch; 1h:44m:10s remains)
INFO - root - 2019-11-06 17:36:04.260329: step 2530, total loss = 1.49, predict loss = 0.37 (90.6 examples/sec; 0.044 sec/batch; 1h:48m:29s remains)
INFO - root - 2019-11-06 17:36:05.466049: step 2540, total loss = 1.82, predict loss = 0.41 (69.4 examples/sec; 0.058 sec/batch; 2h:21m:33s remains)
INFO - root - 2019-11-06 17:36:06.194437: step 2550, total loss = 2.00, predict loss = 0.55 (52.3 examples/sec; 0.077 sec/batch; 3h:08m:00s remains)
INFO - root - 2019-11-06 17:36:07.006775: step 2560, total loss = 1.37, predict loss = 0.37 (59.5 examples/sec; 0.067 sec/batch; 2h:45m:09s remains)
INFO - root - 2019-11-06 17:36:07.732484: step 2570, total loss = 2.88, predict loss = 0.92 (62.2 examples/sec; 0.064 sec/batch; 2h:37m:58s remains)
INFO - root - 2019-11-06 17:36:08.444896: step 2580, total loss = 2.48, predict loss = 0.60 (65.3 examples/sec; 0.061 sec/batch; 2h:30m:35s remains)
INFO - root - 2019-11-06 17:36:08.962721: step 2590, total loss = 1.60, predict loss = 0.38 (95.1 examples/sec; 0.042 sec/batch; 1h:43m:17s remains)
INFO - root - 2019-11-06 17:36:09.404513: step 2600, total loss = 2.12, predict loss = 0.55 (98.3 examples/sec; 0.041 sec/batch; 1h:39m:55s remains)
INFO - root - 2019-11-06 17:36:10.518170: step 2610, total loss = 2.31, predict loss = 0.54 (68.9 examples/sec; 0.058 sec/batch; 2h:22m:31s remains)
INFO - root - 2019-11-06 17:36:11.251369: step 2620, total loss = 1.80, predict loss = 0.49 (54.6 examples/sec; 0.073 sec/batch; 3h:00m:01s remains)
INFO - root - 2019-11-06 17:36:12.072421: step 2630, total loss = 1.77, predict loss = 0.49 (61.0 examples/sec; 0.066 sec/batch; 2h:40m:58s remains)
INFO - root - 2019-11-06 17:36:12.856330: step 2640, total loss = 1.15, predict loss = 0.28 (59.3 examples/sec; 0.067 sec/batch; 2h:45m:46s remains)
INFO - root - 2019-11-06 17:36:13.684060: step 2650, total loss = 1.12, predict loss = 0.31 (37.6 examples/sec; 0.106 sec/batch; 4h:21m:12s remains)
INFO - root - 2019-11-06 17:36:14.298246: step 2660, total loss = 1.99, predict loss = 0.49 (96.1 examples/sec; 0.042 sec/batch; 1h:42m:15s remains)
INFO - root - 2019-11-06 17:36:14.733122: step 2670, total loss = 1.34, predict loss = 0.34 (94.1 examples/sec; 0.042 sec/batch; 1h:44m:21s remains)
INFO - root - 2019-11-06 17:36:15.177542: step 2680, total loss = 1.94, predict loss = 0.46 (91.9 examples/sec; 0.044 sec/batch; 1h:46m:54s remains)
INFO - root - 2019-11-06 17:36:16.441115: step 2690, total loss = 0.98, predict loss = 0.30 (63.7 examples/sec; 0.063 sec/batch; 2h:34m:03s remains)
INFO - root - 2019-11-06 17:36:17.289454: step 2700, total loss = 1.40, predict loss = 0.34 (56.2 examples/sec; 0.071 sec/batch; 2h:54m:45s remains)
INFO - root - 2019-11-06 17:36:18.047709: step 2710, total loss = 1.99, predict loss = 0.48 (54.9 examples/sec; 0.073 sec/batch; 2h:58m:49s remains)
INFO - root - 2019-11-06 17:36:18.757000: step 2720, total loss = 1.72, predict loss = 0.41 (66.1 examples/sec; 0.061 sec/batch; 2h:28m:33s remains)
INFO - root - 2019-11-06 17:36:19.475375: step 2730, total loss = 1.26, predict loss = 0.30 (72.9 examples/sec; 0.055 sec/batch; 2h:14m:46s remains)
INFO - root - 2019-11-06 17:36:19.971166: step 2740, total loss = 2.23, predict loss = 0.68 (103.6 examples/sec; 0.039 sec/batch; 1h:34m:45s remains)
INFO - root - 2019-11-06 17:36:20.401276: step 2750, total loss = 1.09, predict loss = 0.26 (102.0 examples/sec; 0.039 sec/batch; 1h:36m:14s remains)
INFO - root - 2019-11-06 17:36:21.528209: step 2760, total loss = 0.89, predict loss = 0.29 (68.0 examples/sec; 0.059 sec/batch; 2h:24m:24s remains)
INFO - root - 2019-11-06 17:36:22.242123: step 2770, total loss = 1.58, predict loss = 0.42 (56.6 examples/sec; 0.071 sec/batch; 2h:53m:25s remains)
INFO - root - 2019-11-06 17:36:22.936842: step 2780, total loss = 1.38, predict loss = 0.32 (59.6 examples/sec; 0.067 sec/batch; 2h:44m:47s remains)
INFO - root - 2019-11-06 17:36:23.685587: step 2790, total loss = 1.46, predict loss = 0.41 (64.1 examples/sec; 0.062 sec/batch; 2h:33m:07s remains)
INFO - root - 2019-11-06 17:36:24.395844: step 2800, total loss = 2.12, predict loss = 0.54 (66.8 examples/sec; 0.060 sec/batch; 2h:26m:48s remains)
INFO - root - 2019-11-06 17:36:24.992350: step 2810, total loss = 1.81, predict loss = 0.45 (102.5 examples/sec; 0.039 sec/batch; 1h:35m:44s remains)
INFO - root - 2019-11-06 17:36:25.427613: step 2820, total loss = 2.27, predict loss = 0.61 (99.0 examples/sec; 0.040 sec/batch; 1h:39m:08s remains)
INFO - root - 2019-11-06 17:36:25.874691: step 2830, total loss = 1.24, predict loss = 0.30 (99.8 examples/sec; 0.040 sec/batch; 1h:38m:19s remains)
INFO - root - 2019-11-06 17:36:27.115793: step 2840, total loss = 1.78, predict loss = 0.47 (65.2 examples/sec; 0.061 sec/batch; 2h:30m:22s remains)
INFO - root - 2019-11-06 17:36:27.867376: step 2850, total loss = 2.27, predict loss = 0.70 (53.0 examples/sec; 0.075 sec/batch; 3h:04m:55s remains)
INFO - root - 2019-11-06 17:36:28.578182: step 2860, total loss = 1.65, predict loss = 0.40 (67.0 examples/sec; 0.060 sec/batch; 2h:26m:19s remains)
INFO - root - 2019-11-06 17:36:29.308914: step 2870, total loss = 2.42, predict loss = 0.57 (61.1 examples/sec; 0.065 sec/batch; 2h:40m:36s remains)
INFO - root - 2019-11-06 17:36:30.003459: step 2880, total loss = 1.34, predict loss = 0.27 (73.2 examples/sec; 0.055 sec/batch; 2h:14m:00s remains)
INFO - root - 2019-11-06 17:36:30.540670: step 2890, total loss = 1.59, predict loss = 0.41 (95.1 examples/sec; 0.042 sec/batch; 1h:43m:08s remains)
INFO - root - 2019-11-06 17:36:30.994246: step 2900, total loss = 1.30, predict loss = 0.31 (94.9 examples/sec; 0.042 sec/batch; 1h:43m:21s remains)
INFO - root - 2019-11-06 17:36:32.162861: step 2910, total loss = 1.68, predict loss = 0.40 (68.3 examples/sec; 0.059 sec/batch; 2h:23m:36s remains)
INFO - root - 2019-11-06 17:36:32.852928: step 2920, total loss = 1.62, predict loss = 0.39 (54.0 examples/sec; 0.074 sec/batch; 3h:01m:42s remains)
INFO - root - 2019-11-06 17:36:33.583726: step 2930, total loss = 1.52, predict loss = 0.37 (60.8 examples/sec; 0.066 sec/batch; 2h:41m:14s remains)
INFO - root - 2019-11-06 17:36:34.274751: step 2940, total loss = 1.34, predict loss = 0.30 (64.1 examples/sec; 0.062 sec/batch; 2h:33m:03s remains)
INFO - root - 2019-11-06 17:36:34.952246: step 2950, total loss = 1.84, predict loss = 0.56 (60.4 examples/sec; 0.066 sec/batch; 2h:42m:13s remains)
INFO - root - 2019-11-06 17:36:35.514917: step 2960, total loss = 1.45, predict loss = 0.36 (103.0 examples/sec; 0.039 sec/batch; 1h:35m:09s remains)
INFO - root - 2019-11-06 17:36:35.982384: step 2970, total loss = 1.26, predict loss = 0.28 (102.5 examples/sec; 0.039 sec/batch; 1h:35m:39s remains)
INFO - root - 2019-11-06 17:36:36.428188: step 2980, total loss = 1.27, predict loss = 0.36 (94.4 examples/sec; 0.042 sec/batch; 1h:43m:51s remains)
INFO - root - 2019-11-06 17:36:37.757603: step 2990, total loss = 1.63, predict loss = 0.41 (70.3 examples/sec; 0.057 sec/batch; 2h:19m:18s remains)
INFO - root - 2019-11-06 17:36:38.549514: step 3000, total loss = 1.78, predict loss = 0.52 (53.1 examples/sec; 0.075 sec/batch; 3h:04m:36s remains)
INFO - root - 2019-11-06 17:36:39.283780: step 3010, total loss = 2.20, predict loss = 0.55 (55.2 examples/sec; 0.072 sec/batch; 2h:57m:26s remains)
INFO - root - 2019-11-06 17:36:40.049580: step 3020, total loss = 2.57, predict loss = 0.65 (54.4 examples/sec; 0.074 sec/batch; 3h:00m:09s remains)
INFO - root - 2019-11-06 17:36:40.708573: step 3030, total loss = 1.68, predict loss = 0.42 (89.1 examples/sec; 0.045 sec/batch; 1h:49m:56s remains)
INFO - root - 2019-11-06 17:36:41.161934: step 3040, total loss = 2.13, predict loss = 0.59 (97.5 examples/sec; 0.041 sec/batch; 1h:40m:27s remains)
INFO - root - 2019-11-06 17:36:41.640059: step 3050, total loss = 1.05, predict loss = 0.26 (98.0 examples/sec; 0.041 sec/batch; 1h:40m:00s remains)
INFO - root - 2019-11-06 17:36:42.809135: step 3060, total loss = 2.48, predict loss = 0.73 (65.8 examples/sec; 0.061 sec/batch; 2h:28m:50s remains)
INFO - root - 2019-11-06 17:36:43.548634: step 3070, total loss = 1.62, predict loss = 0.39 (55.0 examples/sec; 0.073 sec/batch; 2h:58m:03s remains)
INFO - root - 2019-11-06 17:36:44.292669: step 3080, total loss = 1.88, predict loss = 0.46 (60.4 examples/sec; 0.066 sec/batch; 2h:42m:09s remains)
INFO - root - 2019-11-06 17:36:45.066902: step 3090, total loss = 1.94, predict loss = 0.43 (60.1 examples/sec; 0.067 sec/batch; 2h:42m:55s remains)
INFO - root - 2019-11-06 17:36:45.800150: step 3100, total loss = 1.41, predict loss = 0.34 (65.0 examples/sec; 0.062 sec/batch; 2h:30m:40s remains)
INFO - root - 2019-11-06 17:36:46.373595: step 3110, total loss = 1.47, predict loss = 0.39 (101.4 examples/sec; 0.039 sec/batch; 1h:36m:35s remains)
INFO - root - 2019-11-06 17:36:46.819975: step 3120, total loss = 1.33, predict loss = 0.36 (98.6 examples/sec; 0.041 sec/batch; 1h:39m:18s remains)
INFO - root - 2019-11-06 17:36:47.275164: step 3130, total loss = 2.06, predict loss = 0.57 (137.7 examples/sec; 0.029 sec/batch; 1h:11m:06s remains)
INFO - root - 2019-11-06 17:36:48.605891: step 3140, total loss = 1.48, predict loss = 0.35 (59.0 examples/sec; 0.068 sec/batch; 2h:45m:52s remains)
INFO - root - 2019-11-06 17:36:49.342488: step 3150, total loss = 2.36, predict loss = 0.53 (55.1 examples/sec; 0.073 sec/batch; 2h:57m:44s remains)
INFO - root - 2019-11-06 17:36:50.080236: step 3160, total loss = 1.79, predict loss = 0.58 (65.6 examples/sec; 0.061 sec/batch; 2h:29m:12s remains)
INFO - root - 2019-11-06 17:36:50.812861: step 3170, total loss = 1.77, predict loss = 0.44 (61.6 examples/sec; 0.065 sec/batch; 2h:39m:00s remains)
INFO - root - 2019-11-06 17:36:51.467283: step 3180, total loss = 1.39, predict loss = 0.34 (76.0 examples/sec; 0.053 sec/batch; 2h:08m:46s remains)
INFO - root - 2019-11-06 17:36:51.907217: step 3190, total loss = 1.88, predict loss = 0.41 (103.0 examples/sec; 0.039 sec/batch; 1h:35m:01s remains)
INFO - root - 2019-11-06 17:36:52.362378: step 3200, total loss = 2.82, predict loss = 0.95 (96.2 examples/sec; 0.042 sec/batch; 1h:41m:43s remains)
INFO - root - 2019-11-06 17:36:53.565285: step 3210, total loss = 1.62, predict loss = 0.35 (67.3 examples/sec; 0.059 sec/batch; 2h:25m:18s remains)
INFO - root - 2019-11-06 17:36:54.307200: step 3220, total loss = 2.26, predict loss = 0.73 (65.9 examples/sec; 0.061 sec/batch; 2h:28m:25s remains)
INFO - root - 2019-11-06 17:36:55.046740: step 3230, total loss = 2.07, predict loss = 0.56 (63.3 examples/sec; 0.063 sec/batch; 2h:34m:39s remains)
INFO - root - 2019-11-06 17:36:55.845844: step 3240, total loss = 2.25, predict loss = 0.59 (50.9 examples/sec; 0.079 sec/batch; 3h:12m:10s remains)
INFO - root - 2019-11-06 17:36:56.575770: step 3250, total loss = 1.07, predict loss = 0.27 (63.5 examples/sec; 0.063 sec/batch; 2h:34m:02s remains)
INFO - root - 2019-11-06 17:36:57.109997: step 3260, total loss = 1.43, predict loss = 0.32 (104.3 examples/sec; 0.038 sec/batch; 1h:33m:47s remains)
INFO - root - 2019-11-06 17:36:57.560568: step 3270, total loss = 1.47, predict loss = 0.37 (96.4 examples/sec; 0.041 sec/batch; 1h:41m:28s remains)
INFO - root - 2019-11-06 17:36:58.680488: step 3280, total loss = 1.22, predict loss = 0.31 (5.6 examples/sec; 0.719 sec/batch; 29h:18m:34s remains)
INFO - root - 2019-11-06 17:36:59.408570: step 3290, total loss = 1.27, predict loss = 0.32 (59.6 examples/sec; 0.067 sec/batch; 2h:44m:01s remains)
INFO - root - 2019-11-06 17:37:00.166180: step 3300, total loss = 1.20, predict loss = 0.25 (60.4 examples/sec; 0.066 sec/batch; 2h:41m:48s remains)
INFO - root - 2019-11-06 17:37:00.881301: step 3310, total loss = 1.36, predict loss = 0.32 (62.7 examples/sec; 0.064 sec/batch; 2h:35m:58s remains)
INFO - root - 2019-11-06 17:37:01.621713: step 3320, total loss = 1.56, predict loss = 0.37 (56.7 examples/sec; 0.071 sec/batch; 2h:52m:23s remains)
INFO - root - 2019-11-06 17:37:02.318808: step 3330, total loss = 1.14, predict loss = 0.28 (92.6 examples/sec; 0.043 sec/batch; 1h:45m:36s remains)
INFO - root - 2019-11-06 17:37:02.751171: step 3340, total loss = 1.37, predict loss = 0.33 (97.0 examples/sec; 0.041 sec/batch; 1h:40m:49s remains)
INFO - root - 2019-11-06 17:37:03.203038: step 3350, total loss = 2.32, predict loss = 0.66 (103.2 examples/sec; 0.039 sec/batch; 1h:34m:45s remains)
INFO - root - 2019-11-06 17:37:04.391875: step 3360, total loss = 1.76, predict loss = 0.41 (65.4 examples/sec; 0.061 sec/batch; 2h:29m:22s remains)
INFO - root - 2019-11-06 17:37:05.122454: step 3370, total loss = 1.76, predict loss = 0.47 (65.5 examples/sec; 0.061 sec/batch; 2h:29m:09s remains)
INFO - root - 2019-11-06 17:37:05.826128: step 3380, total loss = 1.53, predict loss = 0.37 (54.9 examples/sec; 0.073 sec/batch; 2h:57m:59s remains)
INFO - root - 2019-11-06 17:37:06.511280: step 3390, total loss = 1.26, predict loss = 0.32 (70.4 examples/sec; 0.057 sec/batch; 2h:18m:54s remains)
INFO - root - 2019-11-06 17:37:07.183964: step 3400, total loss = 1.76, predict loss = 0.43 (73.6 examples/sec; 0.054 sec/batch; 2h:12m:49s remains)
INFO - root - 2019-11-06 17:37:07.732017: step 3410, total loss = 0.92, predict loss = 0.23 (101.5 examples/sec; 0.039 sec/batch; 1h:36m:16s remains)
INFO - root - 2019-11-06 17:37:08.177389: step 3420, total loss = 2.62, predict loss = 0.76 (107.2 examples/sec; 0.037 sec/batch; 1h:31m:09s remains)
INFO - root - 2019-11-06 17:37:09.272125: step 3430, total loss = 2.13, predict loss = 0.61 (75.9 examples/sec; 0.053 sec/batch; 2h:08m:48s remains)
INFO - root - 2019-11-06 17:37:10.034692: step 3440, total loss = 2.29, predict loss = 0.66 (46.7 examples/sec; 0.086 sec/batch; 3h:29m:05s remains)
INFO - root - 2019-11-06 17:37:10.825464: step 3450, total loss = 0.75, predict loss = 0.15 (55.1 examples/sec; 0.073 sec/batch; 2h:57m:15s remains)
INFO - root - 2019-11-06 17:37:11.511234: step 3460, total loss = 1.80, predict loss = 0.44 (68.0 examples/sec; 0.059 sec/batch; 2h:23m:34s remains)
INFO - root - 2019-11-06 17:37:12.178913: step 3470, total loss = 1.48, predict loss = 0.38 (60.5 examples/sec; 0.066 sec/batch; 2h:41m:33s remains)
INFO - root - 2019-11-06 17:37:12.804323: step 3480, total loss = 1.80, predict loss = 0.52 (99.3 examples/sec; 0.040 sec/batch; 1h:38m:21s remains)
INFO - root - 2019-11-06 17:37:13.277550: step 3490, total loss = 2.02, predict loss = 0.55 (98.4 examples/sec; 0.041 sec/batch; 1h:39m:13s remains)
INFO - root - 2019-11-06 17:37:13.709012: step 3500, total loss = 1.46, predict loss = 0.37 (99.8 examples/sec; 0.040 sec/batch; 1h:37m:50s remains)
INFO - root - 2019-11-06 17:37:14.987562: step 3510, total loss = 1.63, predict loss = 0.35 (66.7 examples/sec; 0.060 sec/batch; 2h:26m:24s remains)
INFO - root - 2019-11-06 17:37:15.772950: step 3520, total loss = 2.72, predict loss = 0.88 (56.6 examples/sec; 0.071 sec/batch; 2h:52m:28s remains)
INFO - root - 2019-11-06 17:37:16.492777: step 3530, total loss = 1.66, predict loss = 0.37 (70.1 examples/sec; 0.057 sec/batch; 2h:19m:20s remains)
INFO - root - 2019-11-06 17:37:17.196881: step 3540, total loss = 1.65, predict loss = 0.40 (60.6 examples/sec; 0.066 sec/batch; 2h:41m:13s remains)
INFO - root - 2019-11-06 17:37:17.923844: step 3550, total loss = 1.25, predict loss = 0.29 (66.2 examples/sec; 0.060 sec/batch; 2h:27m:23s remains)
INFO - root - 2019-11-06 17:37:18.448110: step 3560, total loss = 1.15, predict loss = 0.26 (100.6 examples/sec; 0.040 sec/batch; 1h:37m:04s remains)
INFO - root - 2019-11-06 17:37:18.916220: step 3570, total loss = 1.97, predict loss = 0.54 (97.3 examples/sec; 0.041 sec/batch; 1h:40m:18s remains)
INFO - root - 2019-11-06 17:37:20.050098: step 3580, total loss = 2.63, predict loss = 0.81 (70.0 examples/sec; 0.057 sec/batch; 2h:19m:24s remains)
INFO - root - 2019-11-06 17:37:20.761208: step 3590, total loss = 1.48, predict loss = 0.37 (60.5 examples/sec; 0.066 sec/batch; 2h:41m:20s remains)
INFO - root - 2019-11-06 17:37:21.457058: step 3600, total loss = 1.60, predict loss = 0.38 (64.7 examples/sec; 0.062 sec/batch; 2h:30m:57s remains)
INFO - root - 2019-11-06 17:37:22.190278: step 3610, total loss = 2.48, predict loss = 0.65 (63.3 examples/sec; 0.063 sec/batch; 2h:34m:05s remains)
INFO - root - 2019-11-06 17:37:22.883225: step 3620, total loss = 1.70, predict loss = 0.43 (59.7 examples/sec; 0.067 sec/batch; 2h:43m:32s remains)
INFO - root - 2019-11-06 17:37:23.480880: step 3630, total loss = 2.10, predict loss = 0.58 (101.3 examples/sec; 0.039 sec/batch; 1h:36m:20s remains)
INFO - root - 2019-11-06 17:37:23.932983: step 3640, total loss = 2.24, predict loss = 0.78 (88.6 examples/sec; 0.045 sec/batch; 1h:50m:04s remains)
INFO - root - 2019-11-06 17:37:24.422725: step 3650, total loss = 1.45, predict loss = 0.40 (88.1 examples/sec; 0.045 sec/batch; 1h:50m:44s remains)
INFO - root - 2019-11-06 17:37:25.651067: step 3660, total loss = 2.54, predict loss = 0.82 (67.2 examples/sec; 0.060 sec/batch; 2h:25m:14s remains)
INFO - root - 2019-11-06 17:37:26.401222: step 3670, total loss = 1.04, predict loss = 0.22 (55.4 examples/sec; 0.072 sec/batch; 2h:56m:14s remains)
INFO - root - 2019-11-06 17:37:27.185804: step 3680, total loss = 1.81, predict loss = 0.47 (54.3 examples/sec; 0.074 sec/batch; 2h:59m:31s remains)
INFO - root - 2019-11-06 17:37:27.903465: step 3690, total loss = 1.04, predict loss = 0.25 (55.3 examples/sec; 0.072 sec/batch; 2h:56m:16s remains)
INFO - root - 2019-11-06 17:37:28.690080: step 3700, total loss = 2.17, predict loss = 0.65 (81.0 examples/sec; 0.049 sec/batch; 2h:00m:21s remains)
INFO - root - 2019-11-06 17:37:29.156230: step 3710, total loss = 1.50, predict loss = 0.34 (97.5 examples/sec; 0.041 sec/batch; 1h:39m:59s remains)
INFO - root - 2019-11-06 17:37:29.609373: step 3720, total loss = 1.88, predict loss = 0.56 (93.3 examples/sec; 0.043 sec/batch; 1h:44m:30s remains)
INFO - root - 2019-11-06 17:37:30.834363: step 3730, total loss = 1.41, predict loss = 0.37 (71.2 examples/sec; 0.056 sec/batch; 2h:16m:52s remains)
INFO - root - 2019-11-06 17:37:31.551472: step 3740, total loss = 0.92, predict loss = 0.22 (54.7 examples/sec; 0.073 sec/batch; 2h:58m:12s remains)
INFO - root - 2019-11-06 17:37:32.267238: step 3750, total loss = 1.43, predict loss = 0.34 (60.7 examples/sec; 0.066 sec/batch; 2h:40m:42s remains)
INFO - root - 2019-11-06 17:37:33.011134: step 3760, total loss = 1.06, predict loss = 0.27 (60.9 examples/sec; 0.066 sec/batch; 2h:40m:04s remains)
INFO - root - 2019-11-06 17:37:33.722512: step 3770, total loss = 1.89, predict loss = 0.47 (62.2 examples/sec; 0.064 sec/batch; 2h:36m:42s remains)
INFO - root - 2019-11-06 17:37:34.296130: step 3780, total loss = 1.28, predict loss = 0.31 (103.8 examples/sec; 0.039 sec/batch; 1h:33m:53s remains)
INFO - root - 2019-11-06 17:37:34.740613: step 3790, total loss = 1.39, predict loss = 0.35 (102.0 examples/sec; 0.039 sec/batch; 1h:35m:31s remains)
INFO - root - 2019-11-06 17:37:35.203920: step 3800, total loss = 1.70, predict loss = 0.45 (90.9 examples/sec; 0.044 sec/batch; 1h:47m:14s remains)
INFO - root - 2019-11-06 17:37:36.506460: step 3810, total loss = 1.41, predict loss = 0.36 (60.1 examples/sec; 0.067 sec/batch; 2h:42m:11s remains)
INFO - root - 2019-11-06 17:37:37.263337: step 3820, total loss = 1.29, predict loss = 0.32 (63.7 examples/sec; 0.063 sec/batch; 2h:32m:56s remains)
INFO - root - 2019-11-06 17:37:37.981935: step 3830, total loss = 1.17, predict loss = 0.26 (67.2 examples/sec; 0.060 sec/batch; 2h:25m:06s remains)
INFO - root - 2019-11-06 17:37:38.741969: step 3840, total loss = 1.94, predict loss = 0.55 (65.1 examples/sec; 0.061 sec/batch; 2h:29m:37s remains)
INFO - root - 2019-11-06 17:37:39.411186: step 3850, total loss = 0.96, predict loss = 0.28 (74.5 examples/sec; 0.054 sec/batch; 2h:10m:51s remains)
INFO - root - 2019-11-06 17:37:39.883586: step 3860, total loss = 0.97, predict loss = 0.22 (93.1 examples/sec; 0.043 sec/batch; 1h:44m:36s remains)
INFO - root - 2019-11-06 17:37:40.326225: step 3870, total loss = 1.15, predict loss = 0.30 (98.3 examples/sec; 0.041 sec/batch; 1h:39m:06s remains)
INFO - root - 2019-11-06 17:37:41.496493: step 3880, total loss = 2.01, predict loss = 0.45 (73.1 examples/sec; 0.055 sec/batch; 2h:13m:19s remains)
INFO - root - 2019-11-06 17:37:42.190579: step 3890, total loss = 1.68, predict loss = 0.45 (67.5 examples/sec; 0.059 sec/batch; 2h:24m:15s remains)
INFO - root - 2019-11-06 17:37:42.937087: step 3900, total loss = 1.54, predict loss = 0.41 (58.2 examples/sec; 0.069 sec/batch; 2h:47m:27s remains)
INFO - root - 2019-11-06 17:37:43.636340: step 3910, total loss = 1.58, predict loss = 0.45 (68.0 examples/sec; 0.059 sec/batch; 2h:23m:13s remains)
INFO - root - 2019-11-06 17:37:44.285297: step 3920, total loss = 1.46, predict loss = 0.42 (71.7 examples/sec; 0.056 sec/batch; 2h:15m:46s remains)
INFO - root - 2019-11-06 17:37:44.815503: step 3930, total loss = 1.67, predict loss = 0.40 (98.8 examples/sec; 0.040 sec/batch; 1h:38m:34s remains)
INFO - root - 2019-11-06 17:37:45.267400: step 3940, total loss = 2.28, predict loss = 0.74 (96.7 examples/sec; 0.041 sec/batch; 1h:40m:42s remains)
INFO - root - 2019-11-06 17:37:45.710788: step 3950, total loss = 0.67, predict loss = 0.24 (120.1 examples/sec; 0.033 sec/batch; 1h:21m:03s remains)
INFO - root - 2019-11-06 17:37:47.054400: step 3960, total loss = 1.90, predict loss = 0.52 (53.2 examples/sec; 0.075 sec/batch; 3h:02m:59s remains)
INFO - root - 2019-11-06 17:37:47.803288: step 3970, total loss = 1.62, predict loss = 0.44 (62.9 examples/sec; 0.064 sec/batch; 2h:34m:50s remains)
INFO - root - 2019-11-06 17:37:48.539663: step 3980, total loss = 1.16, predict loss = 0.32 (65.0 examples/sec; 0.061 sec/batch; 2h:29m:39s remains)
INFO - root - 2019-11-06 17:37:49.338425: step 3990, total loss = 1.65, predict loss = 0.43 (60.0 examples/sec; 0.067 sec/batch; 2h:42m:18s remains)
INFO - root - 2019-11-06 17:37:49.992984: step 4000, total loss = 1.12, predict loss = 0.32 (83.4 examples/sec; 0.048 sec/batch; 1h:56m:43s remains)
INFO - root - 2019-11-06 17:37:50.479634: step 4010, total loss = 1.36, predict loss = 0.28 (97.3 examples/sec; 0.041 sec/batch; 1h:39m:59s remains)
INFO - root - 2019-11-06 17:37:50.936774: step 4020, total loss = 1.56, predict loss = 0.42 (98.6 examples/sec; 0.041 sec/batch; 1h:38m:41s remains)
INFO - root - 2019-11-06 17:37:52.112183: step 4030, total loss = 1.57, predict loss = 0.42 (67.8 examples/sec; 0.059 sec/batch; 2h:23m:37s remains)
INFO - root - 2019-11-06 17:37:52.885139: step 4040, total loss = 0.97, predict loss = 0.28 (47.3 examples/sec; 0.085 sec/batch; 3h:25m:51s remains)
INFO - root - 2019-11-06 17:37:53.630601: step 4050, total loss = 2.65, predict loss = 0.91 (56.7 examples/sec; 0.071 sec/batch; 2h:51m:44s remains)
INFO - root - 2019-11-06 17:37:54.352479: step 4060, total loss = 0.73, predict loss = 0.20 (67.3 examples/sec; 0.059 sec/batch; 2h:24m:39s remains)
INFO - root - 2019-11-06 17:37:55.073166: step 4070, total loss = 1.73, predict loss = 0.42 (75.6 examples/sec; 0.053 sec/batch; 2h:08m:39s remains)
INFO - root - 2019-11-06 17:37:55.627072: step 4080, total loss = 1.93, predict loss = 0.55 (103.1 examples/sec; 0.039 sec/batch; 1h:34m:22s remains)
INFO - root - 2019-11-06 17:37:56.095529: step 4090, total loss = 1.49, predict loss = 0.39 (95.3 examples/sec; 0.042 sec/batch; 1h:42m:05s remains)
INFO - root - 2019-11-06 17:37:57.179984: step 4100, total loss = 1.90, predict loss = 0.51 (5.8 examples/sec; 0.691 sec/batch; 28h:00m:47s remains)
INFO - root - 2019-11-06 17:37:57.855657: step 4110, total loss = 1.09, predict loss = 0.28 (61.4 examples/sec; 0.065 sec/batch; 2h:38m:27s remains)
INFO - root - 2019-11-06 17:37:58.540761: step 4120, total loss = 1.40, predict loss = 0.35 (68.7 examples/sec; 0.058 sec/batch; 2h:21m:31s remains)
INFO - root - 2019-11-06 17:37:59.259844: step 4130, total loss = 1.35, predict loss = 0.30 (62.2 examples/sec; 0.064 sec/batch; 2h:36m:21s remains)
INFO - root - 2019-11-06 17:38:00.035443: step 4140, total loss = 0.66, predict loss = 0.18 (57.2 examples/sec; 0.070 sec/batch; 2h:50m:00s remains)
INFO - root - 2019-11-06 17:38:00.741109: step 4150, total loss = 0.97, predict loss = 0.26 (77.3 examples/sec; 0.052 sec/batch; 2h:05m:48s remains)
INFO - root - 2019-11-06 17:38:01.185874: step 4160, total loss = 1.14, predict loss = 0.33 (97.7 examples/sec; 0.041 sec/batch; 1h:39m:30s remains)
INFO - root - 2019-11-06 17:38:01.662728: step 4170, total loss = 1.83, predict loss = 0.55 (95.5 examples/sec; 0.042 sec/batch; 1h:41m:50s remains)
INFO - root - 2019-11-06 17:38:02.898590: step 4180, total loss = 1.46, predict loss = 0.38 (63.3 examples/sec; 0.063 sec/batch; 2h:33m:40s remains)
INFO - root - 2019-11-06 17:38:03.608366: step 4190, total loss = 0.92, predict loss = 0.28 (62.2 examples/sec; 0.064 sec/batch; 2h:36m:21s remains)
INFO - root - 2019-11-06 17:38:04.351449: step 4200, total loss = 2.32, predict loss = 0.62 (54.7 examples/sec; 0.073 sec/batch; 2h:57m:47s remains)
INFO - root - 2019-11-06 17:38:05.179557: step 4210, total loss = 1.00, predict loss = 0.25 (53.7 examples/sec; 0.075 sec/batch; 3h:01m:02s remains)
INFO - root - 2019-11-06 17:38:05.941367: step 4220, total loss = 1.45, predict loss = 0.41 (72.6 examples/sec; 0.055 sec/batch; 2h:13m:50s remains)
INFO - root - 2019-11-06 17:38:06.482431: step 4230, total loss = 1.28, predict loss = 0.31 (105.8 examples/sec; 0.038 sec/batch; 1h:31m:49s remains)
INFO - root - 2019-11-06 17:38:06.925557: step 4240, total loss = 1.43, predict loss = 0.37 (94.9 examples/sec; 0.042 sec/batch; 1h:42m:24s remains)
INFO - root - 2019-11-06 17:38:08.092330: step 4250, total loss = 1.65, predict loss = 0.45 (71.1 examples/sec; 0.056 sec/batch; 2h:16m:38s remains)
INFO - root - 2019-11-06 17:38:08.821023: step 4260, total loss = 0.78, predict loss = 0.19 (52.4 examples/sec; 0.076 sec/batch; 3h:05m:29s remains)
INFO - root - 2019-11-06 17:38:09.632732: step 4270, total loss = 1.34, predict loss = 0.31 (50.6 examples/sec; 0.079 sec/batch; 3h:12m:03s remains)
INFO - root - 2019-11-06 17:38:10.384480: step 4280, total loss = 1.11, predict loss = 0.29 (62.5 examples/sec; 0.064 sec/batch; 2h:35m:25s remains)
INFO - root - 2019-11-06 17:38:11.086568: step 4290, total loss = 1.26, predict loss = 0.32 (74.7 examples/sec; 0.054 sec/batch; 2h:10m:02s remains)
INFO - root - 2019-11-06 17:38:11.671446: step 4300, total loss = 2.45, predict loss = 0.82 (100.7 examples/sec; 0.040 sec/batch; 1h:36m:28s remains)
INFO - root - 2019-11-06 17:38:12.113241: step 4310, total loss = 1.29, predict loss = 0.29 (96.2 examples/sec; 0.042 sec/batch; 1h:40m:58s remains)
INFO - root - 2019-11-06 17:38:12.552713: step 4320, total loss = 2.30, predict loss = 0.67 (99.4 examples/sec; 0.040 sec/batch; 1h:37m:43s remains)
INFO - root - 2019-11-06 17:38:13.797467: step 4330, total loss = 1.82, predict loss = 0.62 (56.5 examples/sec; 0.071 sec/batch; 2h:51m:58s remains)
INFO - root - 2019-11-06 17:38:14.544815: step 4340, total loss = 1.03, predict loss = 0.24 (56.3 examples/sec; 0.071 sec/batch; 2h:52m:28s remains)
INFO - root - 2019-11-06 17:38:15.281624: step 4350, total loss = 1.74, predict loss = 0.43 (61.4 examples/sec; 0.065 sec/batch; 2h:38m:10s remains)
INFO - root - 2019-11-06 17:38:16.026053: step 4360, total loss = 1.46, predict loss = 0.36 (55.9 examples/sec; 0.072 sec/batch; 2h:53m:34s remains)
INFO - root - 2019-11-06 17:38:16.733183: step 4370, total loss = 1.24, predict loss = 0.35 (76.0 examples/sec; 0.053 sec/batch; 2h:07m:47s remains)
INFO - root - 2019-11-06 17:38:17.234237: step 4380, total loss = 1.34, predict loss = 0.34 (106.9 examples/sec; 0.037 sec/batch; 1h:30m:49s remains)
INFO - root - 2019-11-06 17:38:17.670553: step 4390, total loss = 2.29, predict loss = 0.56 (99.1 examples/sec; 0.040 sec/batch; 1h:37m:56s remains)
INFO - root - 2019-11-06 17:38:18.781340: step 4400, total loss = 0.97, predict loss = 0.26 (66.5 examples/sec; 0.060 sec/batch; 2h:26m:03s remains)
INFO - root - 2019-11-06 17:38:19.494475: step 4410, total loss = 1.17, predict loss = 0.29 (55.1 examples/sec; 0.073 sec/batch; 2h:56m:13s remains)
INFO - root - 2019-11-06 17:38:20.236766: step 4420, total loss = 1.54, predict loss = 0.41 (67.4 examples/sec; 0.059 sec/batch; 2h:23m:56s remains)
INFO - root - 2019-11-06 17:38:20.964147: step 4430, total loss = 1.45, predict loss = 0.41 (59.6 examples/sec; 0.067 sec/batch; 2h:42m:47s remains)
INFO - root - 2019-11-06 17:38:21.699508: step 4440, total loss = 2.25, predict loss = 0.62 (61.0 examples/sec; 0.066 sec/batch; 2h:39m:02s remains)
INFO - root - 2019-11-06 17:38:22.283114: step 4450, total loss = 1.70, predict loss = 0.48 (105.8 examples/sec; 0.038 sec/batch; 1h:31m:45s remains)
INFO - root - 2019-11-06 17:38:22.717144: step 4460, total loss = 0.69, predict loss = 0.19 (98.8 examples/sec; 0.040 sec/batch; 1h:38m:14s remains)
INFO - root - 2019-11-06 17:38:23.163300: step 4470, total loss = 1.59, predict loss = 0.40 (97.3 examples/sec; 0.041 sec/batch; 1h:39m:40s remains)
INFO - root - 2019-11-06 17:38:24.414920: step 4480, total loss = 0.68, predict loss = 0.15 (66.6 examples/sec; 0.060 sec/batch; 2h:25m:41s remains)
INFO - root - 2019-11-06 17:38:25.176435: step 4490, total loss = 2.37, predict loss = 0.63 (60.2 examples/sec; 0.066 sec/batch; 2h:41m:08s remains)
INFO - root - 2019-11-06 17:38:25.875495: step 4500, total loss = 1.43, predict loss = 0.37 (67.6 examples/sec; 0.059 sec/batch; 2h:23m:32s remains)
INFO - root - 2019-11-06 17:38:26.567355: step 4510, total loss = 1.45, predict loss = 0.45 (59.9 examples/sec; 0.067 sec/batch; 2h:41m:57s remains)
INFO - root - 2019-11-06 17:38:27.270739: step 4520, total loss = 0.89, predict loss = 0.23 (73.1 examples/sec; 0.055 sec/batch; 2h:12m:41s remains)
INFO - root - 2019-11-06 17:38:27.778067: step 4530, total loss = 1.33, predict loss = 0.33 (93.1 examples/sec; 0.043 sec/batch; 1h:44m:07s remains)
INFO - root - 2019-11-06 17:38:28.231108: step 4540, total loss = 0.87, predict loss = 0.26 (91.1 examples/sec; 0.044 sec/batch; 1h:46m:23s remains)
INFO - root - 2019-11-06 17:38:29.397174: step 4550, total loss = 1.59, predict loss = 0.46 (68.6 examples/sec; 0.058 sec/batch; 2h:21m:18s remains)
INFO - root - 2019-11-06 17:38:30.087934: step 4560, total loss = 0.90, predict loss = 0.21 (69.3 examples/sec; 0.058 sec/batch; 2h:19m:48s remains)
INFO - root - 2019-11-06 17:38:30.877959: step 4570, total loss = 0.81, predict loss = 0.21 (61.8 examples/sec; 0.065 sec/batch; 2h:36m:53s remains)
INFO - root - 2019-11-06 17:38:31.636957: step 4580, total loss = 2.27, predict loss = 0.76 (59.3 examples/sec; 0.067 sec/batch; 2h:43m:26s remains)
INFO - root - 2019-11-06 17:38:32.435270: step 4590, total loss = 1.01, predict loss = 0.25 (57.8 examples/sec; 0.069 sec/batch; 2h:47m:47s remains)
INFO - root - 2019-11-06 17:38:33.026452: step 4600, total loss = 1.22, predict loss = 0.30 (101.4 examples/sec; 0.039 sec/batch; 1h:35m:35s remains)
INFO - root - 2019-11-06 17:38:33.501770: step 4610, total loss = 1.16, predict loss = 0.31 (99.1 examples/sec; 0.040 sec/batch; 1h:37m:47s remains)
INFO - root - 2019-11-06 17:38:33.932099: step 4620, total loss = 1.52, predict loss = 0.37 (93.5 examples/sec; 0.043 sec/batch; 1h:43m:36s remains)
INFO - root - 2019-11-06 17:38:35.229236: step 4630, total loss = 1.27, predict loss = 0.31 (54.4 examples/sec; 0.073 sec/batch; 2h:58m:00s remains)
INFO - root - 2019-11-06 17:38:35.974367: step 4640, total loss = 1.20, predict loss = 0.31 (64.2 examples/sec; 0.062 sec/batch; 2h:30m:59s remains)
INFO - root - 2019-11-06 17:38:36.798873: step 4650, total loss = 1.20, predict loss = 0.29 (57.4 examples/sec; 0.070 sec/batch; 2h:48m:41s remains)
INFO - root - 2019-11-06 17:38:37.562850: step 4660, total loss = 1.05, predict loss = 0.24 (54.5 examples/sec; 0.073 sec/batch; 2h:57m:56s remains)
INFO - root - 2019-11-06 17:38:38.289525: step 4670, total loss = 1.52, predict loss = 0.40 (73.5 examples/sec; 0.054 sec/batch; 2h:11m:50s remains)
INFO - root - 2019-11-06 17:38:38.777797: step 4680, total loss = 1.12, predict loss = 0.27 (98.9 examples/sec; 0.040 sec/batch; 1h:37m:57s remains)
INFO - root - 2019-11-06 17:38:39.262905: step 4690, total loss = 1.62, predict loss = 0.46 (91.4 examples/sec; 0.044 sec/batch; 1h:46m:01s remains)
INFO - root - 2019-11-06 17:38:40.418179: step 4700, total loss = 1.53, predict loss = 0.44 (65.0 examples/sec; 0.062 sec/batch; 2h:28m:56s remains)
INFO - root - 2019-11-06 17:38:41.122923: step 4710, total loss = 2.03, predict loss = 0.66 (64.1 examples/sec; 0.062 sec/batch; 2h:31m:00s remains)
INFO - root - 2019-11-06 17:38:41.861670: step 4720, total loss = 1.78, predict loss = 0.58 (62.0 examples/sec; 0.065 sec/batch; 2h:36m:11s remains)
INFO - root - 2019-11-06 17:38:42.586777: step 4730, total loss = 1.00, predict loss = 0.23 (57.8 examples/sec; 0.069 sec/batch; 2h:47m:40s remains)
INFO - root - 2019-11-06 17:38:43.359192: step 4740, total loss = 1.32, predict loss = 0.30 (49.4 examples/sec; 0.081 sec/batch; 3h:15m:52s remains)
INFO - root - 2019-11-06 17:38:43.914919: step 4750, total loss = 0.98, predict loss = 0.26 (92.7 examples/sec; 0.043 sec/batch; 1h:44m:26s remains)
INFO - root - 2019-11-06 17:38:44.353592: step 4760, total loss = 1.32, predict loss = 0.38 (96.7 examples/sec; 0.041 sec/batch; 1h:40m:09s remains)
INFO - root - 2019-11-06 17:38:44.819641: step 4770, total loss = 1.17, predict loss = 0.28 (118.6 examples/sec; 0.034 sec/batch; 1h:21m:37s remains)
INFO - root - 2019-11-06 17:38:46.171980: step 4780, total loss = 0.63, predict loss = 0.14 (57.7 examples/sec; 0.069 sec/batch; 2h:47m:41s remains)
INFO - root - 2019-11-06 17:38:46.935069: step 4790, total loss = 1.15, predict loss = 0.30 (57.6 examples/sec; 0.069 sec/batch; 2h:48m:11s remains)
INFO - root - 2019-11-06 17:38:47.700464: step 4800, total loss = 0.92, predict loss = 0.22 (49.2 examples/sec; 0.081 sec/batch; 3h:16m:44s remains)
INFO - root - 2019-11-06 17:38:48.472083: step 4810, total loss = 1.47, predict loss = 0.44 (61.4 examples/sec; 0.065 sec/batch; 2h:37m:42s remains)
INFO - root - 2019-11-06 17:38:49.157141: step 4820, total loss = 1.70, predict loss = 0.45 (74.0 examples/sec; 0.054 sec/batch; 2h:10m:51s remains)
INFO - root - 2019-11-06 17:38:49.615027: step 4830, total loss = 2.00, predict loss = 0.57 (97.8 examples/sec; 0.041 sec/batch; 1h:38m:56s remains)
INFO - root - 2019-11-06 17:38:50.059759: step 4840, total loss = 0.86, predict loss = 0.22 (90.8 examples/sec; 0.044 sec/batch; 1h:46m:32s remains)
INFO - root - 2019-11-06 17:38:51.331594: step 4850, total loss = 0.83, predict loss = 0.19 (56.1 examples/sec; 0.071 sec/batch; 2h:52m:37s remains)
INFO - root - 2019-11-06 17:38:52.033128: step 4860, total loss = 0.74, predict loss = 0.17 (64.9 examples/sec; 0.062 sec/batch; 2h:29m:10s remains)
INFO - root - 2019-11-06 17:38:52.751815: step 4870, total loss = 1.11, predict loss = 0.26 (60.3 examples/sec; 0.066 sec/batch; 2h:40m:30s remains)
INFO - root - 2019-11-06 17:38:53.470475: step 4880, total loss = 1.29, predict loss = 0.33 (62.5 examples/sec; 0.064 sec/batch; 2h:34m:42s remains)
INFO - root - 2019-11-06 17:38:54.182190: step 4890, total loss = 1.45, predict loss = 0.38 (72.4 examples/sec; 0.055 sec/batch; 2h:13m:35s remains)
INFO - root - 2019-11-06 17:38:54.736230: step 4900, total loss = 0.90, predict loss = 0.23 (92.3 examples/sec; 0.043 sec/batch; 1h:44m:51s remains)
INFO - root - 2019-11-06 17:38:55.169488: step 4910, total loss = 0.80, predict loss = 0.22 (100.4 examples/sec; 0.040 sec/batch; 1h:36m:19s remains)
INFO - root - 2019-11-06 17:38:56.271582: step 4920, total loss = 1.62, predict loss = 0.41 (5.6 examples/sec; 0.719 sec/batch; 28h:59m:12s remains)
INFO - root - 2019-11-06 17:38:57.007396: step 4930, total loss = 1.03, predict loss = 0.28 (62.0 examples/sec; 0.065 sec/batch; 2h:36m:06s remains)
INFO - root - 2019-11-06 17:38:57.740395: step 4940, total loss = 1.07, predict loss = 0.25 (53.5 examples/sec; 0.075 sec/batch; 3h:00m:38s remains)
INFO - root - 2019-11-06 17:38:58.492773: step 4950, total loss = 1.11, predict loss = 0.28 (57.0 examples/sec; 0.070 sec/batch; 2h:49m:46s remains)
INFO - root - 2019-11-06 17:38:59.204356: step 4960, total loss = 0.97, predict loss = 0.23 (59.5 examples/sec; 0.067 sec/batch; 2h:42m:33s remains)
INFO - root - 2019-11-06 17:38:59.848305: step 4970, total loss = 1.33, predict loss = 0.35 (91.1 examples/sec; 0.044 sec/batch; 1h:46m:07s remains)
INFO - root - 2019-11-06 17:39:00.290152: step 4980, total loss = 1.42, predict loss = 0.38 (96.2 examples/sec; 0.042 sec/batch; 1h:40m:29s remains)
INFO - root - 2019-11-06 17:39:00.723367: step 4990, total loss = 1.07, predict loss = 0.31 (109.2 examples/sec; 0.037 sec/batch; 1h:28m:30s remains)
INFO - root - 2019-11-06 17:39:01.912790: step 5000, total loss = 1.07, predict loss = 0.30 (63.8 examples/sec; 0.063 sec/batch; 2h:31m:32s remains)
INFO - root - 2019-11-06 17:39:02.655408: step 5010, total loss = 1.11, predict loss = 0.28 (64.8 examples/sec; 0.062 sec/batch; 2h:29m:11s remains)
INFO - root - 2019-11-06 17:39:03.387506: step 5020, total loss = 1.81, predict loss = 0.56 (58.5 examples/sec; 0.068 sec/batch; 2h:45m:20s remains)
INFO - root - 2019-11-06 17:39:04.063208: step 5030, total loss = 1.52, predict loss = 0.39 (57.8 examples/sec; 0.069 sec/batch; 2h:47m:20s remains)
INFO - root - 2019-11-06 17:39:04.773174: step 5040, total loss = 0.97, predict loss = 0.26 (64.5 examples/sec; 0.062 sec/batch; 2h:29m:54s remains)
INFO - root - 2019-11-06 17:39:05.340652: step 5050, total loss = 1.22, predict loss = 0.34 (79.7 examples/sec; 0.050 sec/batch; 2h:01m:10s remains)
INFO - root - 2019-11-06 17:39:05.789548: step 5060, total loss = 2.19, predict loss = 0.70 (92.7 examples/sec; 0.043 sec/batch; 1h:44m:11s remains)
INFO - root - 2019-11-06 17:39:06.921295: step 5070, total loss = 1.42, predict loss = 0.34 (67.0 examples/sec; 0.060 sec/batch; 2h:24m:16s remains)
INFO - root - 2019-11-06 17:39:07.571234: step 5080, total loss = 1.16, predict loss = 0.25 (63.1 examples/sec; 0.063 sec/batch; 2h:33m:03s remains)
INFO - root - 2019-11-06 17:39:08.300412: step 5090, total loss = 1.39, predict loss = 0.37 (63.9 examples/sec; 0.063 sec/batch; 2h:31m:14s remains)
INFO - root - 2019-11-06 17:39:09.114280: step 5100, total loss = 1.34, predict loss = 0.36 (53.2 examples/sec; 0.075 sec/batch; 3h:01m:42s remains)
INFO - root - 2019-11-06 17:39:09.858890: step 5110, total loss = 1.79, predict loss = 0.52 (58.7 examples/sec; 0.068 sec/batch; 2h:44m:39s remains)
INFO - root - 2019-11-06 17:39:10.548877: step 5120, total loss = 1.43, predict loss = 0.37 (89.1 examples/sec; 0.045 sec/batch; 1h:48m:26s remains)
INFO - root - 2019-11-06 17:39:11.055218: step 5130, total loss = 0.99, predict loss = 0.21 (97.2 examples/sec; 0.041 sec/batch; 1h:39m:20s remains)
INFO - root - 2019-11-06 17:39:11.495102: step 5140, total loss = 1.34, predict loss = 0.36 (106.6 examples/sec; 0.038 sec/batch; 1h:30m:35s remains)
INFO - root - 2019-11-06 17:39:12.774639: step 5150, total loss = 0.85, predict loss = 0.27 (58.5 examples/sec; 0.068 sec/batch; 2h:45m:09s remains)
INFO - root - 2019-11-06 17:39:13.500976: step 5160, total loss = 1.41, predict loss = 0.39 (54.7 examples/sec; 0.073 sec/batch; 2h:56m:24s remains)
INFO - root - 2019-11-06 17:39:14.338528: step 5170, total loss = 1.41, predict loss = 0.42 (62.6 examples/sec; 0.064 sec/batch; 2h:34m:15s remains)
INFO - root - 2019-11-06 17:39:15.029092: step 5180, total loss = 0.95, predict loss = 0.24 (61.7 examples/sec; 0.065 sec/batch; 2h:36m:26s remains)
INFO - root - 2019-11-06 17:39:15.700014: step 5190, total loss = 1.54, predict loss = 0.46 (75.3 examples/sec; 0.053 sec/batch; 2h:08m:08s remains)
INFO - root - 2019-11-06 17:39:16.177383: step 5200, total loss = 1.12, predict loss = 0.27 (99.5 examples/sec; 0.040 sec/batch; 1h:37m:01s remains)
INFO - root - 2019-11-06 17:39:16.650951: step 5210, total loss = 0.97, predict loss = 0.20 (96.3 examples/sec; 0.042 sec/batch; 1h:40m:15s remains)
INFO - root - 2019-11-06 17:39:17.810273: step 5220, total loss = 0.83, predict loss = 0.21 (64.9 examples/sec; 0.062 sec/batch; 2h:28m:39s remains)
INFO - root - 2019-11-06 17:39:18.539422: step 5230, total loss = 0.86, predict loss = 0.20 (65.1 examples/sec; 0.061 sec/batch; 2h:28m:17s remains)
INFO - root - 2019-11-06 17:39:19.315413: step 5240, total loss = 0.93, predict loss = 0.20 (51.6 examples/sec; 0.078 sec/batch; 3h:07m:02s remains)
INFO - root - 2019-11-06 17:39:20.124558: step 5250, total loss = 0.66, predict loss = 0.17 (63.7 examples/sec; 0.063 sec/batch; 2h:31m:29s remains)
INFO - root - 2019-11-06 17:39:20.830372: step 5260, total loss = 1.28, predict loss = 0.32 (58.8 examples/sec; 0.068 sec/batch; 2h:44m:02s remains)
INFO - root - 2019-11-06 17:39:21.488161: step 5270, total loss = 0.71, predict loss = 0.17 (96.3 examples/sec; 0.042 sec/batch; 1h:40m:11s remains)
INFO - root - 2019-11-06 17:39:21.913018: step 5280, total loss = 1.54, predict loss = 0.39 (97.8 examples/sec; 0.041 sec/batch; 1h:38m:40s remains)
INFO - root - 2019-11-06 17:39:22.373565: step 5290, total loss = 1.54, predict loss = 0.39 (104.4 examples/sec; 0.038 sec/batch; 1h:32m:25s remains)
INFO - root - 2019-11-06 17:39:23.748570: step 5300, total loss = 0.50, predict loss = 0.17 (46.1 examples/sec; 0.087 sec/batch; 3h:29m:26s remains)
INFO - root - 2019-11-06 17:39:24.532705: step 5310, total loss = 0.85, predict loss = 0.16 (57.4 examples/sec; 0.070 sec/batch; 2h:48m:02s remains)
INFO - root - 2019-11-06 17:39:25.324772: step 5320, total loss = 0.73, predict loss = 0.20 (49.0 examples/sec; 0.082 sec/batch; 3h:16m:44s remains)
INFO - root - 2019-11-06 17:39:26.088119: step 5330, total loss = 1.00, predict loss = 0.26 (57.1 examples/sec; 0.070 sec/batch; 2h:48m:46s remains)
INFO - root - 2019-11-06 17:39:26.806303: step 5340, total loss = 1.04, predict loss = 0.26 (61.0 examples/sec; 0.066 sec/batch; 2h:38m:10s remains)
INFO - root - 2019-11-06 17:39:27.286747: step 5350, total loss = 1.14, predict loss = 0.28 (100.9 examples/sec; 0.040 sec/batch; 1h:35m:33s remains)
INFO - root - 2019-11-06 17:39:27.734791: step 5360, total loss = 1.15, predict loss = 0.30 (96.0 examples/sec; 0.042 sec/batch; 1h:40m:24s remains)
INFO - root - 2019-11-06 17:39:28.958781: step 5370, total loss = 1.15, predict loss = 0.27 (70.0 examples/sec; 0.057 sec/batch; 2h:17m:39s remains)
INFO - root - 2019-11-06 17:39:29.697526: step 5380, total loss = 0.94, predict loss = 0.24 (50.1 examples/sec; 0.080 sec/batch; 3h:12m:31s remains)
INFO - root - 2019-11-06 17:39:30.419834: step 5390, total loss = 0.72, predict loss = 0.18 (62.1 examples/sec; 0.064 sec/batch; 2h:35m:12s remains)
INFO - root - 2019-11-06 17:39:31.146949: step 5400, total loss = 0.71, predict loss = 0.20 (64.0 examples/sec; 0.062 sec/batch; 2h:30m:35s remains)
INFO - root - 2019-11-06 17:39:31.922089: step 5410, total loss = 0.76, predict loss = 0.21 (60.2 examples/sec; 0.066 sec/batch; 2h:40m:00s remains)
INFO - root - 2019-11-06 17:39:32.499400: step 5420, total loss = 1.56, predict loss = 0.41 (106.0 examples/sec; 0.038 sec/batch; 1h:30m:55s remains)
INFO - root - 2019-11-06 17:39:32.935256: step 5430, total loss = 1.10, predict loss = 0.26 (96.0 examples/sec; 0.042 sec/batch; 1h:40m:23s remains)
INFO - root - 2019-11-06 17:39:33.384545: step 5440, total loss = 1.79, predict loss = 0.59 (98.5 examples/sec; 0.041 sec/batch; 1h:37m:48s remains)
INFO - root - 2019-11-06 17:39:34.760260: step 5450, total loss = 1.83, predict loss = 0.48 (62.2 examples/sec; 0.064 sec/batch; 2h:34m:52s remains)
INFO - root - 2019-11-06 17:39:35.471154: step 5460, total loss = 1.41, predict loss = 0.39 (63.8 examples/sec; 0.063 sec/batch; 2h:31m:04s remains)
INFO - root - 2019-11-06 17:39:36.197504: step 5470, total loss = 1.85, predict loss = 0.51 (60.8 examples/sec; 0.066 sec/batch; 2h:38m:33s remains)
INFO - root - 2019-11-06 17:39:36.984730: step 5480, total loss = 0.73, predict loss = 0.17 (58.6 examples/sec; 0.068 sec/batch; 2h:44m:18s remains)
INFO - root - 2019-11-06 17:39:37.691959: step 5490, total loss = 1.21, predict loss = 0.31 (73.2 examples/sec; 0.055 sec/batch; 2h:11m:36s remains)
INFO - root - 2019-11-06 17:39:38.159034: step 5500, total loss = 1.04, predict loss = 0.30 (97.7 examples/sec; 0.041 sec/batch; 1h:38m:35s remains)
INFO - root - 2019-11-06 17:39:38.603533: step 5510, total loss = 1.20, predict loss = 0.31 (99.3 examples/sec; 0.040 sec/batch; 1h:37m:03s remains)
INFO - root - 2019-11-06 17:39:39.795182: step 5520, total loss = 1.80, predict loss = 0.56 (69.7 examples/sec; 0.057 sec/batch; 2h:18m:15s remains)
INFO - root - 2019-11-06 17:39:40.534826: step 5530, total loss = 1.19, predict loss = 0.30 (55.7 examples/sec; 0.072 sec/batch; 2h:52m:47s remains)
INFO - root - 2019-11-06 17:39:41.255687: step 5540, total loss = 1.14, predict loss = 0.30 (56.4 examples/sec; 0.071 sec/batch; 2h:50m:37s remains)
INFO - root - 2019-11-06 17:39:41.946061: step 5550, total loss = 1.16, predict loss = 0.36 (70.0 examples/sec; 0.057 sec/batch; 2h:17m:34s remains)
INFO - root - 2019-11-06 17:39:42.662494: step 5560, total loss = 1.27, predict loss = 0.37 (60.2 examples/sec; 0.066 sec/batch; 2h:40m:00s remains)
INFO - root - 2019-11-06 17:39:43.238040: step 5570, total loss = 0.86, predict loss = 0.23 (103.6 examples/sec; 0.039 sec/batch; 1h:32m:54s remains)
INFO - root - 2019-11-06 17:39:43.686014: step 5580, total loss = 0.84, predict loss = 0.22 (96.6 examples/sec; 0.041 sec/batch; 1h:39m:38s remains)
INFO - root - 2019-11-06 17:39:44.130924: step 5590, total loss = 2.13, predict loss = 0.85 (125.9 examples/sec; 0.032 sec/batch; 1h:16m:28s remains)
INFO - root - 2019-11-06 17:39:45.471073: step 5600, total loss = 1.09, predict loss = 0.27 (53.2 examples/sec; 0.075 sec/batch; 3h:00m:58s remains)
INFO - root - 2019-11-06 17:39:46.219637: step 5610, total loss = 1.25, predict loss = 0.31 (59.9 examples/sec; 0.067 sec/batch; 2h:40m:45s remains)
INFO - root - 2019-11-06 17:39:46.924451: step 5620, total loss = 1.28, predict loss = 0.34 (61.5 examples/sec; 0.065 sec/batch; 2h:36m:31s remains)
INFO - root - 2019-11-06 17:39:47.713534: step 5630, total loss = 0.85, predict loss = 0.22 (54.5 examples/sec; 0.073 sec/batch; 2h:56m:32s remains)
INFO - root - 2019-11-06 17:39:48.366669: step 5640, total loss = 1.37, predict loss = 0.38 (77.8 examples/sec; 0.051 sec/batch; 2h:03m:43s remains)
INFO - root - 2019-11-06 17:39:48.847384: step 5650, total loss = 0.74, predict loss = 0.16 (96.1 examples/sec; 0.042 sec/batch; 1h:40m:08s remains)
INFO - root - 2019-11-06 17:39:49.302980: step 5660, total loss = 0.89, predict loss = 0.22 (96.9 examples/sec; 0.041 sec/batch; 1h:39m:16s remains)
INFO - root - 2019-11-06 17:39:50.505030: step 5670, total loss = 1.23, predict loss = 0.29 (70.0 examples/sec; 0.057 sec/batch; 2h:17m:27s remains)
INFO - root - 2019-11-06 17:39:51.214749: step 5680, total loss = 1.00, predict loss = 0.24 (57.6 examples/sec; 0.069 sec/batch; 2h:47m:05s remains)
INFO - root - 2019-11-06 17:39:51.981942: step 5690, total loss = 1.01, predict loss = 0.24 (51.5 examples/sec; 0.078 sec/batch; 3h:06m:44s remains)
INFO - root - 2019-11-06 17:39:52.709166: step 5700, total loss = 2.03, predict loss = 0.53 (70.5 examples/sec; 0.057 sec/batch; 2h:16m:25s remains)
INFO - root - 2019-11-06 17:39:53.398513: step 5710, total loss = 1.11, predict loss = 0.29 (65.7 examples/sec; 0.061 sec/batch; 2h:26m:22s remains)
INFO - root - 2019-11-06 17:39:53.934674: step 5720, total loss = 2.15, predict loss = 0.64 (96.5 examples/sec; 0.041 sec/batch; 1h:39m:43s remains)
INFO - root - 2019-11-06 17:39:54.430672: step 5730, total loss = 0.63, predict loss = 0.17 (98.3 examples/sec; 0.041 sec/batch; 1h:37m:52s remains)
INFO - root - 2019-11-06 17:39:55.580761: step 5740, total loss = 1.47, predict loss = 0.40 (5.4 examples/sec; 0.741 sec/batch; 29h:42m:12s remains)
INFO - root - 2019-11-06 17:39:56.344680: step 5750, total loss = 1.01, predict loss = 0.25 (54.3 examples/sec; 0.074 sec/batch; 2h:57m:01s remains)
INFO - root - 2019-11-06 17:39:57.026216: step 5760, total loss = 1.94, predict loss = 0.52 (72.6 examples/sec; 0.055 sec/batch; 2h:12m:25s remains)
INFO - root - 2019-11-06 17:39:57.846446: step 5770, total loss = 1.63, predict loss = 0.46 (53.5 examples/sec; 0.075 sec/batch; 2h:59m:43s remains)
INFO - root - 2019-11-06 17:39:58.639101: step 5780, total loss = 1.05, predict loss = 0.28 (60.0 examples/sec; 0.067 sec/batch; 2h:40m:20s remains)
INFO - root - 2019-11-06 17:39:59.380413: step 5790, total loss = 1.23, predict loss = 0.32 (76.2 examples/sec; 0.052 sec/batch; 2h:06m:10s remains)
INFO - root - 2019-11-06 17:39:59.839020: step 5800, total loss = 1.07, predict loss = 0.28 (105.1 examples/sec; 0.038 sec/batch; 1h:31m:29s remains)
INFO - root - 2019-11-06 17:40:00.316217: step 5810, total loss = 1.10, predict loss = 0.34 (99.4 examples/sec; 0.040 sec/batch; 1h:36m:39s remains)
INFO - root - 2019-11-06 17:40:01.536573: step 5820, total loss = 0.95, predict loss = 0.22 (64.1 examples/sec; 0.062 sec/batch; 2h:29m:53s remains)
INFO - root - 2019-11-06 17:40:02.293827: step 5830, total loss = 0.70, predict loss = 0.17 (63.9 examples/sec; 0.063 sec/batch; 2h:30m:21s remains)
INFO - root - 2019-11-06 17:40:02.986921: step 5840, total loss = 0.77, predict loss = 0.20 (63.6 examples/sec; 0.063 sec/batch; 2h:31m:09s remains)
INFO - root - 2019-11-06 17:40:03.735074: step 5850, total loss = 0.87, predict loss = 0.24 (52.7 examples/sec; 0.076 sec/batch; 3h:02m:24s remains)
INFO - root - 2019-11-06 17:40:04.439060: step 5860, total loss = 0.80, predict loss = 0.20 (75.6 examples/sec; 0.053 sec/batch; 2h:07m:10s remains)
INFO - root - 2019-11-06 17:40:04.939111: step 5870, total loss = 1.13, predict loss = 0.28 (108.7 examples/sec; 0.037 sec/batch; 1h:28m:24s remains)
INFO - root - 2019-11-06 17:40:05.376112: step 5880, total loss = 1.26, predict loss = 0.39 (97.3 examples/sec; 0.041 sec/batch; 1h:38m:42s remains)
INFO - root - 2019-11-06 17:40:06.563023: step 5890, total loss = 0.96, predict loss = 0.22 (68.0 examples/sec; 0.059 sec/batch; 2h:21m:17s remains)
INFO - root - 2019-11-06 17:40:07.265472: step 5900, total loss = 0.93, predict loss = 0.21 (59.5 examples/sec; 0.067 sec/batch; 2h:41m:32s remains)
INFO - root - 2019-11-06 17:40:08.047298: step 5910, total loss = 1.45, predict loss = 0.37 (60.3 examples/sec; 0.066 sec/batch; 2h:39m:15s remains)
INFO - root - 2019-11-06 17:40:08.787956: step 5920, total loss = 1.18, predict loss = 0.31 (61.5 examples/sec; 0.065 sec/batch; 2h:36m:11s remains)
INFO - root - 2019-11-06 17:40:09.534618: step 5930, total loss = 1.11, predict loss = 0.31 (64.8 examples/sec; 0.062 sec/batch; 2h:28m:18s remains)
INFO - root - 2019-11-06 17:40:10.153418: step 5940, total loss = 0.79, predict loss = 0.22 (95.2 examples/sec; 0.042 sec/batch; 1h:40m:51s remains)
INFO - root - 2019-11-06 17:40:10.594143: step 5950, total loss = 1.25, predict loss = 0.28 (93.8 examples/sec; 0.043 sec/batch; 1h:42m:22s remains)
INFO - root - 2019-11-06 17:40:11.028830: step 5960, total loss = 1.72, predict loss = 0.43 (102.3 examples/sec; 0.039 sec/batch; 1h:33m:51s remains)
INFO - root - 2019-11-06 17:40:12.417324: step 5970, total loss = 1.15, predict loss = 0.30 (48.7 examples/sec; 0.082 sec/batch; 3h:17m:12s remains)
INFO - root - 2019-11-06 17:40:13.147519: step 5980, total loss = 1.18, predict loss = 0.27 (59.1 examples/sec; 0.068 sec/batch; 2h:42m:23s remains)
INFO - root - 2019-11-06 17:40:13.956489: step 5990, total loss = 1.11, predict loss = 0.31 (52.8 examples/sec; 0.076 sec/batch; 3h:01m:50s remains)
INFO - root - 2019-11-06 17:40:14.680092: step 6000, total loss = 0.42, predict loss = 0.18 (60.8 examples/sec; 0.066 sec/batch; 2h:37m:48s remains)
INFO - root - 2019-11-06 17:40:15.390860: step 6010, total loss = 1.15, predict loss = 0.30 (71.5 examples/sec; 0.056 sec/batch; 2h:14m:20s remains)
INFO - root - 2019-11-06 17:40:15.874591: step 6020, total loss = 1.19, predict loss = 0.32 (100.1 examples/sec; 0.040 sec/batch; 1h:35m:51s remains)
INFO - root - 2019-11-06 17:40:16.321784: step 6030, total loss = 1.46, predict loss = 0.40 (99.5 examples/sec; 0.040 sec/batch; 1h:36m:25s remains)
INFO - root - 2019-11-06 17:40:17.504834: step 6040, total loss = 1.04, predict loss = 0.26 (68.7 examples/sec; 0.058 sec/batch; 2h:19m:47s remains)
INFO - root - 2019-11-06 17:40:18.225824: step 6050, total loss = 0.63, predict loss = 0.16 (66.4 examples/sec; 0.060 sec/batch; 2h:24m:30s remains)
INFO - root - 2019-11-06 17:40:18.888900: step 6060, total loss = 1.05, predict loss = 0.26 (70.4 examples/sec; 0.057 sec/batch; 2h:16m:13s remains)
INFO - root - 2019-11-06 17:40:19.575064: step 6070, total loss = 2.06, predict loss = 0.59 (50.8 examples/sec; 0.079 sec/batch; 3h:08m:45s remains)
INFO - root - 2019-11-06 17:40:20.310956: step 6080, total loss = 1.12, predict loss = 0.32 (56.5 examples/sec; 0.071 sec/batch; 2h:49m:52s remains)
INFO - root - 2019-11-06 17:40:20.929304: step 6090, total loss = 0.79, predict loss = 0.21 (102.6 examples/sec; 0.039 sec/batch; 1h:33m:28s remains)
INFO - root - 2019-11-06 17:40:21.381510: step 6100, total loss = 1.50, predict loss = 0.43 (90.9 examples/sec; 0.044 sec/batch; 1h:45m:33s remains)
INFO - root - 2019-11-06 17:40:21.825420: step 6110, total loss = 1.80, predict loss = 0.54 (102.1 examples/sec; 0.039 sec/batch; 1h:33m:56s remains)
INFO - root - 2019-11-06 17:40:23.213505: step 6120, total loss = 1.96, predict loss = 0.64 (54.8 examples/sec; 0.073 sec/batch; 2h:55m:03s remains)
INFO - root - 2019-11-06 17:40:23.948782: step 6130, total loss = 1.21, predict loss = 0.31 (56.5 examples/sec; 0.071 sec/batch; 2h:49m:50s remains)
INFO - root - 2019-11-06 17:40:24.680303: step 6140, total loss = 1.31, predict loss = 0.41 (62.8 examples/sec; 0.064 sec/batch; 2h:32m:44s remains)
INFO - root - 2019-11-06 17:40:25.417693: step 6150, total loss = 0.78, predict loss = 0.22 (60.7 examples/sec; 0.066 sec/batch; 2h:37m:57s remains)
INFO - root - 2019-11-06 17:40:26.155294: step 6160, total loss = 1.24, predict loss = 0.32 (71.8 examples/sec; 0.056 sec/batch; 2h:13m:37s remains)
INFO - root - 2019-11-06 17:40:26.694741: step 6170, total loss = 1.52, predict loss = 0.39 (90.5 examples/sec; 0.044 sec/batch; 1h:45m:55s remains)
INFO - root - 2019-11-06 17:40:27.136594: step 6180, total loss = 1.46, predict loss = 0.41 (97.2 examples/sec; 0.041 sec/batch; 1h:38m:35s remains)
INFO - root - 2019-11-06 17:40:28.330734: step 6190, total loss = 1.45, predict loss = 0.41 (68.6 examples/sec; 0.058 sec/batch; 2h:19m:44s remains)
INFO - root - 2019-11-06 17:40:29.032228: step 6200, total loss = 1.03, predict loss = 0.29 (65.6 examples/sec; 0.061 sec/batch; 2h:26m:05s remains)
INFO - root - 2019-11-06 17:40:29.821403: step 6210, total loss = 0.90, predict loss = 0.22 (49.5 examples/sec; 0.081 sec/batch; 3h:13m:31s remains)
INFO - root - 2019-11-06 17:40:30.551677: step 6220, total loss = 0.97, predict loss = 0.28 (64.3 examples/sec; 0.062 sec/batch; 2h:29m:08s remains)
INFO - root - 2019-11-06 17:40:31.332843: step 6230, total loss = 1.39, predict loss = 0.33 (48.1 examples/sec; 0.083 sec/batch; 3h:19m:05s remains)
INFO - root - 2019-11-06 17:40:31.942415: step 6240, total loss = 0.54, predict loss = 0.14 (103.8 examples/sec; 0.039 sec/batch; 1h:32m:17s remains)
INFO - root - 2019-11-06 17:40:32.416433: step 6250, total loss = 1.60, predict loss = 0.44 (96.9 examples/sec; 0.041 sec/batch; 1h:38m:53s remains)
INFO - root - 2019-11-06 17:40:32.854287: step 6260, total loss = 1.21, predict loss = 0.30 (102.7 examples/sec; 0.039 sec/batch; 1h:33m:18s remains)
INFO - root - 2019-11-06 17:40:34.160087: step 6270, total loss = 0.77, predict loss = 0.21 (61.7 examples/sec; 0.065 sec/batch; 2h:35m:20s remains)
INFO - root - 2019-11-06 17:40:34.881573: step 6280, total loss = 0.86, predict loss = 0.21 (59.6 examples/sec; 0.067 sec/batch; 2h:40m:43s remains)
INFO - root - 2019-11-06 17:40:35.601758: step 6290, total loss = 0.73, predict loss = 0.20 (69.0 examples/sec; 0.058 sec/batch; 2h:18m:54s remains)
INFO - root - 2019-11-06 17:40:36.356119: step 6300, total loss = 0.66, predict loss = 0.15 (58.2 examples/sec; 0.069 sec/batch; 2h:44m:35s remains)
INFO - root - 2019-11-06 17:40:37.120093: step 6310, total loss = 1.21, predict loss = 0.31 (59.1 examples/sec; 0.068 sec/batch; 2h:42m:03s remains)
INFO - root - 2019-11-06 17:40:37.632950: step 6320, total loss = 1.43, predict loss = 0.36 (93.9 examples/sec; 0.043 sec/batch; 1h:41m:58s remains)
INFO - root - 2019-11-06 17:40:38.103228: step 6330, total loss = 0.85, predict loss = 0.21 (108.2 examples/sec; 0.037 sec/batch; 1h:28m:30s remains)
INFO - root - 2019-11-06 17:40:39.292961: step 6340, total loss = 1.06, predict loss = 0.28 (67.1 examples/sec; 0.060 sec/batch; 2h:22m:44s remains)
INFO - root - 2019-11-06 17:40:39.992378: step 6350, total loss = 1.24, predict loss = 0.31 (65.3 examples/sec; 0.061 sec/batch; 2h:26m:41s remains)
INFO - root - 2019-11-06 17:40:40.769383: step 6360, total loss = 0.56, predict loss = 0.17 (49.3 examples/sec; 0.081 sec/batch; 3h:14m:17s remains)
INFO - root - 2019-11-06 17:40:41.543297: step 6370, total loss = 1.87, predict loss = 0.53 (69.9 examples/sec; 0.057 sec/batch; 2h:16m:56s remains)
INFO - root - 2019-11-06 17:40:42.253936: step 6380, total loss = 2.00, predict loss = 0.55 (69.6 examples/sec; 0.057 sec/batch; 2h:17m:28s remains)
INFO - root - 2019-11-06 17:40:42.805897: step 6390, total loss = 1.41, predict loss = 0.39 (103.9 examples/sec; 0.038 sec/batch; 1h:32m:08s remains)
INFO - root - 2019-11-06 17:40:43.255191: step 6400, total loss = 1.42, predict loss = 0.37 (99.2 examples/sec; 0.040 sec/batch; 1h:36m:28s remains)
INFO - root - 2019-11-06 17:40:43.710822: step 6410, total loss = 1.20, predict loss = 0.30 (140.2 examples/sec; 0.029 sec/batch; 1h:08m:18s remains)
INFO - root - 2019-11-06 17:40:45.053057: step 6420, total loss = 0.86, predict loss = 0.23 (62.0 examples/sec; 0.064 sec/batch; 2h:34m:19s remains)
INFO - root - 2019-11-06 17:40:45.826394: step 6430, total loss = 0.78, predict loss = 0.21 (58.4 examples/sec; 0.068 sec/batch; 2h:43m:45s remains)
INFO - root - 2019-11-06 17:40:46.602635: step 6440, total loss = 1.19, predict loss = 0.38 (54.7 examples/sec; 0.073 sec/batch; 2h:54m:50s remains)
INFO - root - 2019-11-06 17:40:47.350913: step 6450, total loss = 0.95, predict loss = 0.27 (62.9 examples/sec; 0.064 sec/batch; 2h:32m:11s remains)
INFO - root - 2019-11-06 17:40:48.028798: step 6460, total loss = 1.05, predict loss = 0.25 (76.1 examples/sec; 0.053 sec/batch; 2h:05m:48s remains)
INFO - root - 2019-11-06 17:40:48.486673: step 6470, total loss = 0.85, predict loss = 0.23 (96.7 examples/sec; 0.041 sec/batch; 1h:38m:58s remains)
INFO - root - 2019-11-06 17:40:48.926715: step 6480, total loss = 1.20, predict loss = 0.29 (100.0 examples/sec; 0.040 sec/batch; 1h:35m:40s remains)
INFO - root - 2019-11-06 17:40:50.280806: step 6490, total loss = 1.11, predict loss = 0.26 (67.1 examples/sec; 0.060 sec/batch; 2h:22m:40s remains)
INFO - root - 2019-11-06 17:40:50.989659: step 6500, total loss = 1.11, predict loss = 0.26 (61.0 examples/sec; 0.066 sec/batch; 2h:36m:52s remains)
INFO - root - 2019-11-06 17:40:51.747525: step 6510, total loss = 1.38, predict loss = 0.36 (61.3 examples/sec; 0.065 sec/batch; 2h:35m:58s remains)
INFO - root - 2019-11-06 17:40:52.500059: step 6520, total loss = 1.30, predict loss = 0.34 (57.5 examples/sec; 0.070 sec/batch; 2h:46m:18s remains)
INFO - root - 2019-11-06 17:40:53.269693: step 6530, total loss = 1.00, predict loss = 0.25 (64.2 examples/sec; 0.062 sec/batch; 2h:29m:05s remains)
INFO - root - 2019-11-06 17:40:53.795705: step 6540, total loss = 0.94, predict loss = 0.21 (109.0 examples/sec; 0.037 sec/batch; 1h:27m:43s remains)
INFO - root - 2019-11-06 17:40:54.231189: step 6550, total loss = 1.66, predict loss = 0.55 (95.6 examples/sec; 0.042 sec/batch; 1h:39m:59s remains)
INFO - root - 2019-11-06 17:40:55.362593: step 6560, total loss = 0.61, predict loss = 0.17 (5.5 examples/sec; 0.722 sec/batch; 28h:45m:32s remains)
INFO - root - 2019-11-06 17:40:56.074373: step 6570, total loss = 1.98, predict loss = 0.58 (59.4 examples/sec; 0.067 sec/batch; 2h:41m:03s remains)
INFO - root - 2019-11-06 17:40:56.853010: step 6580, total loss = 1.20, predict loss = 0.32 (56.5 examples/sec; 0.071 sec/batch; 2h:49m:07s remains)
INFO - root - 2019-11-06 17:40:57.655320: step 6590, total loss = 1.59, predict loss = 0.48 (63.3 examples/sec; 0.063 sec/batch; 2h:30m:59s remains)
INFO - root - 2019-11-06 17:40:58.346993: step 6600, total loss = 1.07, predict loss = 0.24 (73.0 examples/sec; 0.055 sec/batch; 2h:10m:53s remains)
INFO - root - 2019-11-06 17:40:59.020853: step 6610, total loss = 1.17, predict loss = 0.34 (98.9 examples/sec; 0.040 sec/batch; 1h:36m:39s remains)
INFO - root - 2019-11-06 17:40:59.469009: step 6620, total loss = 1.09, predict loss = 0.29 (98.0 examples/sec; 0.041 sec/batch; 1h:37m:33s remains)
INFO - root - 2019-11-06 17:40:59.911433: step 6630, total loss = 1.42, predict loss = 0.39 (100.2 examples/sec; 0.040 sec/batch; 1h:35m:22s remains)
INFO - root - 2019-11-06 17:41:01.184964: step 6640, total loss = 1.44, predict loss = 0.36 (64.0 examples/sec; 0.062 sec/batch; 2h:29m:14s remains)
INFO - root - 2019-11-06 17:41:01.965939: step 6650, total loss = 1.17, predict loss = 0.31 (70.2 examples/sec; 0.057 sec/batch; 2h:16m:07s remains)
INFO - root - 2019-11-06 17:41:02.666047: step 6660, total loss = 1.44, predict loss = 0.47 (63.7 examples/sec; 0.063 sec/batch; 2h:29m:58s remains)
INFO - root - 2019-11-06 17:41:03.370671: step 6670, total loss = 1.18, predict loss = 0.33 (61.1 examples/sec; 0.065 sec/batch; 2h:36m:18s remains)
INFO - root - 2019-11-06 17:41:04.126525: step 6680, total loss = 0.81, predict loss = 0.22 (62.8 examples/sec; 0.064 sec/batch; 2h:32m:11s remains)
INFO - root - 2019-11-06 17:41:04.688107: step 6690, total loss = 1.22, predict loss = 0.32 (96.5 examples/sec; 0.041 sec/batch; 1h:38m:59s remains)
INFO - root - 2019-11-06 17:41:05.153552: step 6700, total loss = 0.94, predict loss = 0.27 (103.0 examples/sec; 0.039 sec/batch; 1h:32m:43s remains)
INFO - root - 2019-11-06 17:41:06.320943: step 6710, total loss = 1.28, predict loss = 0.33 (66.2 examples/sec; 0.060 sec/batch; 2h:24m:13s remains)
INFO - root - 2019-11-06 17:41:07.048079: step 6720, total loss = 1.81, predict loss = 0.55 (61.1 examples/sec; 0.065 sec/batch; 2h:36m:18s remains)
INFO - root - 2019-11-06 17:41:07.842700: step 6730, total loss = 1.57, predict loss = 0.48 (64.6 examples/sec; 0.062 sec/batch; 2h:27m:51s remains)
INFO - root - 2019-11-06 17:41:08.547599: step 6740, total loss = 1.24, predict loss = 0.35 (58.1 examples/sec; 0.069 sec/batch; 2h:44m:17s remains)
INFO - root - 2019-11-06 17:41:09.278637: step 6750, total loss = 1.92, predict loss = 0.54 (61.9 examples/sec; 0.065 sec/batch; 2h:34m:18s remains)
INFO - root - 2019-11-06 17:41:09.929037: step 6760, total loss = 1.41, predict loss = 0.39 (90.9 examples/sec; 0.044 sec/batch; 1h:45m:03s remains)
INFO - root - 2019-11-06 17:41:10.401283: step 6770, total loss = 1.17, predict loss = 0.31 (86.9 examples/sec; 0.046 sec/batch; 1h:49m:53s remains)
INFO - root - 2019-11-06 17:41:10.858523: step 6780, total loss = 1.55, predict loss = 0.43 (94.5 examples/sec; 0.042 sec/batch; 1h:41m:02s remains)
INFO - root - 2019-11-06 17:41:12.263199: step 6790, total loss = 0.95, predict loss = 0.24 (52.7 examples/sec; 0.076 sec/batch; 3h:01m:19s remains)
INFO - root - 2019-11-06 17:41:13.023265: step 6800, total loss = 0.57, predict loss = 0.14 (66.5 examples/sec; 0.060 sec/batch; 2h:23m:36s remains)
INFO - root - 2019-11-06 17:41:13.780497: step 6810, total loss = 0.51, predict loss = 0.17 (64.2 examples/sec; 0.062 sec/batch; 2h:28m:42s remains)
INFO - root - 2019-11-06 17:41:14.518799: step 6820, total loss = 0.95, predict loss = 0.24 (61.7 examples/sec; 0.065 sec/batch; 2h:34m:44s remains)
INFO - root - 2019-11-06 17:41:15.287774: step 6830, total loss = 1.78, predict loss = 0.49 (58.1 examples/sec; 0.069 sec/batch; 2h:44m:14s remains)
INFO - root - 2019-11-06 17:41:15.792195: step 6840, total loss = 1.53, predict loss = 0.47 (103.6 examples/sec; 0.039 sec/batch; 1h:32m:06s remains)
INFO - root - 2019-11-06 17:41:16.259314: step 6850, total loss = 0.93, predict loss = 0.25 (88.8 examples/sec; 0.045 sec/batch; 1h:47m:30s remains)
INFO - root - 2019-11-06 17:41:17.470499: step 6860, total loss = 0.69, predict loss = 0.18 (69.2 examples/sec; 0.058 sec/batch; 2h:17m:55s remains)
INFO - root - 2019-11-06 17:41:18.131950: step 6870, total loss = 1.04, predict loss = 0.26 (61.9 examples/sec; 0.065 sec/batch; 2h:34m:02s remains)
INFO - root - 2019-11-06 17:41:18.882141: step 6880, total loss = 0.98, predict loss = 0.27 (57.3 examples/sec; 0.070 sec/batch; 2h:46m:30s remains)
INFO - root - 2019-11-06 17:41:19.626431: step 6890, total loss = 1.30, predict loss = 0.42 (61.7 examples/sec; 0.065 sec/batch; 2h:34m:32s remains)
INFO - root - 2019-11-06 17:41:20.378029: step 6900, total loss = 0.96, predict loss = 0.25 (61.3 examples/sec; 0.065 sec/batch; 2h:35m:42s remains)
INFO - root - 2019-11-06 17:41:20.960507: step 6910, total loss = 1.71, predict loss = 0.54 (103.2 examples/sec; 0.039 sec/batch; 1h:32m:28s remains)
INFO - root - 2019-11-06 17:41:21.406345: step 6920, total loss = 0.84, predict loss = 0.22 (97.4 examples/sec; 0.041 sec/batch; 1h:37m:53s remains)
INFO - root - 2019-11-06 17:41:21.875998: step 6930, total loss = 0.51, predict loss = 0.14 (95.6 examples/sec; 0.042 sec/batch; 1h:39m:47s remains)
INFO - root - 2019-11-06 17:41:23.144012: step 6940, total loss = 0.82, predict loss = 0.19 (65.7 examples/sec; 0.061 sec/batch; 2h:25m:04s remains)
INFO - root - 2019-11-06 17:41:23.869758: step 6950, total loss = 1.58, predict loss = 0.45 (58.5 examples/sec; 0.068 sec/batch; 2h:43m:03s remains)
INFO - root - 2019-11-06 17:41:24.645207: step 6960, total loss = 1.33, predict loss = 0.38 (58.4 examples/sec; 0.068 sec/batch; 2h:43m:17s remains)
INFO - root - 2019-11-06 17:41:25.380962: step 6970, total loss = 0.85, predict loss = 0.23 (63.7 examples/sec; 0.063 sec/batch; 2h:29m:46s remains)
INFO - root - 2019-11-06 17:41:26.081856: step 6980, total loss = 0.89, predict loss = 0.24 (75.4 examples/sec; 0.053 sec/batch; 2h:06m:30s remains)
INFO - root - 2019-11-06 17:41:26.572226: step 6990, total loss = 1.03, predict loss = 0.27 (94.2 examples/sec; 0.042 sec/batch; 1h:41m:13s remains)
INFO - root - 2019-11-06 17:41:27.014355: step 7000, total loss = 0.60, predict loss = 0.14 (95.1 examples/sec; 0.042 sec/batch; 1h:40m:14s remains)
INFO - root - 2019-11-06 17:41:28.241480: step 7010, total loss = 1.41, predict loss = 0.38 (74.3 examples/sec; 0.054 sec/batch; 2h:08m:22s remains)
INFO - root - 2019-11-06 17:41:28.952154: step 7020, total loss = 0.97, predict loss = 0.27 (67.3 examples/sec; 0.059 sec/batch; 2h:21m:38s remains)
INFO - root - 2019-11-06 17:41:29.706937: step 7030, total loss = 1.24, predict loss = 0.34 (61.3 examples/sec; 0.065 sec/batch; 2h:35m:29s remains)
INFO - root - 2019-11-06 17:41:30.452481: step 7040, total loss = 1.20, predict loss = 0.32 (57.2 examples/sec; 0.070 sec/batch; 2h:46m:35s remains)
INFO - root - 2019-11-06 17:41:31.211536: step 7050, total loss = 0.71, predict loss = 0.19 (66.8 examples/sec; 0.060 sec/batch; 2h:22m:45s remains)
INFO - root - 2019-11-06 17:41:31.786216: step 7060, total loss = 1.27, predict loss = 0.35 (99.1 examples/sec; 0.040 sec/batch; 1h:36m:10s remains)
INFO - root - 2019-11-06 17:41:32.222764: step 7070, total loss = 1.06, predict loss = 0.28 (104.7 examples/sec; 0.038 sec/batch; 1h:31m:01s remains)
INFO - root - 2019-11-06 17:41:32.665428: step 7080, total loss = 0.74, predict loss = 0.16 (94.0 examples/sec; 0.043 sec/batch; 1h:41m:18s remains)
INFO - root - 2019-11-06 17:41:34.006898: step 7090, total loss = 1.66, predict loss = 0.56 (62.0 examples/sec; 0.065 sec/batch; 2h:33m:44s remains)
INFO - root - 2019-11-06 17:41:34.800141: step 7100, total loss = 0.80, predict loss = 0.19 (53.3 examples/sec; 0.075 sec/batch; 2h:58m:51s remains)
INFO - root - 2019-11-06 17:41:35.544365: step 7110, total loss = 1.18, predict loss = 0.33 (56.3 examples/sec; 0.071 sec/batch; 2h:49m:05s remains)
INFO - root - 2019-11-06 17:41:36.295970: step 7120, total loss = 1.11, predict loss = 0.28 (60.1 examples/sec; 0.067 sec/batch; 2h:38m:26s remains)
INFO - root - 2019-11-06 17:41:36.986056: step 7130, total loss = 0.54, predict loss = 0.14 (67.8 examples/sec; 0.059 sec/batch; 2h:20m:28s remains)
INFO - root - 2019-11-06 17:41:37.442276: step 7140, total loss = 1.13, predict loss = 0.32 (97.7 examples/sec; 0.041 sec/batch; 1h:37m:27s remains)
INFO - root - 2019-11-06 17:41:37.870555: step 7150, total loss = 2.08, predict loss = 0.74 (96.0 examples/sec; 0.042 sec/batch; 1h:39m:10s remains)
INFO - root - 2019-11-06 17:41:38.997275: step 7160, total loss = 0.79, predict loss = 0.21 (69.4 examples/sec; 0.058 sec/batch; 2h:17m:17s remains)
INFO - root - 2019-11-06 17:41:39.716908: step 7170, total loss = 0.49, predict loss = 0.13 (58.7 examples/sec; 0.068 sec/batch; 2h:42m:07s remains)
INFO - root - 2019-11-06 17:41:40.429942: step 7180, total loss = 0.94, predict loss = 0.27 (57.8 examples/sec; 0.069 sec/batch; 2h:44m:36s remains)
INFO - root - 2019-11-06 17:41:41.171606: step 7190, total loss = 0.72, predict loss = 0.19 (60.1 examples/sec; 0.067 sec/batch; 2h:38m:28s remains)
INFO - root - 2019-11-06 17:41:41.985579: step 7200, total loss = 0.90, predict loss = 0.24 (53.4 examples/sec; 0.075 sec/batch; 2h:58m:21s remains)
INFO - root - 2019-11-06 17:41:42.586765: step 7210, total loss = 1.33, predict loss = 0.35 (109.9 examples/sec; 0.036 sec/batch; 1h:26m:37s remains)
INFO - root - 2019-11-06 17:41:43.016520: step 7220, total loss = 1.09, predict loss = 0.30 (100.7 examples/sec; 0.040 sec/batch; 1h:34m:30s remains)
INFO - root - 2019-11-06 17:41:43.446299: step 7230, total loss = 0.67, predict loss = 0.16 (132.2 examples/sec; 0.030 sec/batch; 1h:12m:01s remains)
INFO - root - 2019-11-06 17:41:44.768331: step 7240, total loss = 1.08, predict loss = 0.28 (62.5 examples/sec; 0.064 sec/batch; 2h:32m:19s remains)
INFO - root - 2019-11-06 17:41:45.504105: step 7250, total loss = 0.42, predict loss = 0.09 (60.6 examples/sec; 0.066 sec/batch; 2h:37m:07s remains)
INFO - root - 2019-11-06 17:41:46.227244: step 7260, total loss = 0.88, predict loss = 0.26 (70.9 examples/sec; 0.056 sec/batch; 2h:14m:16s remains)
INFO - root - 2019-11-06 17:41:46.891325: step 7270, total loss = 0.78, predict loss = 0.17 (68.9 examples/sec; 0.058 sec/batch; 2h:18m:00s remains)
INFO - root - 2019-11-06 17:41:47.534151: step 7280, total loss = 1.41, predict loss = 0.39 (77.9 examples/sec; 0.051 sec/batch; 2h:02m:08s remains)
INFO - root - 2019-11-06 17:41:48.025901: step 7290, total loss = 0.70, predict loss = 0.16 (96.3 examples/sec; 0.042 sec/batch; 1h:38m:49s remains)
INFO - root - 2019-11-06 17:41:48.469555: step 7300, total loss = 1.26, predict loss = 0.35 (101.0 examples/sec; 0.040 sec/batch; 1h:34m:12s remains)
INFO - root - 2019-11-06 17:41:49.673593: step 7310, total loss = 1.28, predict loss = 0.34 (68.0 examples/sec; 0.059 sec/batch; 2h:19m:48s remains)
INFO - root - 2019-11-06 17:41:50.401066: step 7320, total loss = 1.08, predict loss = 0.24 (62.2 examples/sec; 0.064 sec/batch; 2h:32m:53s remains)
INFO - root - 2019-11-06 17:41:51.167734: step 7330, total loss = 1.12, predict loss = 0.27 (64.1 examples/sec; 0.062 sec/batch; 2h:28m:27s remains)
INFO - root - 2019-11-06 17:41:51.928099: step 7340, total loss = 1.99, predict loss = 0.66 (53.3 examples/sec; 0.075 sec/batch; 2h:58m:29s remains)
INFO - root - 2019-11-06 17:41:52.650078: step 7350, total loss = 1.07, predict loss = 0.29 (58.7 examples/sec; 0.068 sec/batch; 2h:41m:57s remains)
INFO - root - 2019-11-06 17:41:53.197698: step 7360, total loss = 0.83, predict loss = 0.18 (102.8 examples/sec; 0.039 sec/batch; 1h:32m:28s remains)
INFO - root - 2019-11-06 17:41:53.680976: step 7370, total loss = 1.07, predict loss = 0.35 (105.7 examples/sec; 0.038 sec/batch; 1h:29m:57s remains)
INFO - root - 2019-11-06 17:41:54.817405: step 7380, total loss = 0.90, predict loss = 0.25 (5.5 examples/sec; 0.726 sec/batch; 28h:46m:30s remains)
INFO - root - 2019-11-06 17:41:55.607218: step 7390, total loss = 1.48, predict loss = 0.43 (49.5 examples/sec; 0.081 sec/batch; 3h:11m:57s remains)
INFO - root - 2019-11-06 17:41:56.336595: step 7400, total loss = 1.18, predict loss = 0.29 (66.5 examples/sec; 0.060 sec/batch; 2h:22m:59s remains)
INFO - root - 2019-11-06 17:41:57.115496: step 7410, total loss = 1.03, predict loss = 0.30 (57.5 examples/sec; 0.070 sec/batch; 2h:45m:17s remains)
INFO - root - 2019-11-06 17:41:57.895511: step 7420, total loss = 0.64, predict loss = 0.17 (49.9 examples/sec; 0.080 sec/batch; 3h:10m:23s remains)
INFO - root - 2019-11-06 17:41:58.610588: step 7430, total loss = 1.50, predict loss = 0.49 (85.3 examples/sec; 0.047 sec/batch; 1h:51m:24s remains)
INFO - root - 2019-11-06 17:41:59.061026: step 7440, total loss = 1.12, predict loss = 0.34 (100.0 examples/sec; 0.040 sec/batch; 1h:35m:04s remains)
INFO - root - 2019-11-06 17:41:59.525042: step 7450, total loss = 0.96, predict loss = 0.25 (92.7 examples/sec; 0.043 sec/batch; 1h:42m:32s remains)
INFO - root - 2019-11-06 17:42:00.708588: step 7460, total loss = 0.90, predict loss = 0.22 (60.4 examples/sec; 0.066 sec/batch; 2h:37m:12s remains)
INFO - root - 2019-11-06 17:42:01.469773: step 7470, total loss = 1.26, predict loss = 0.28 (60.8 examples/sec; 0.066 sec/batch; 2h:36m:16s remains)
INFO - root - 2019-11-06 17:42:02.168954: step 7480, total loss = 0.69, predict loss = 0.18 (64.0 examples/sec; 0.062 sec/batch; 2h:28m:23s remains)
INFO - root - 2019-11-06 17:42:02.895553: step 7490, total loss = 1.09, predict loss = 0.29 (58.6 examples/sec; 0.068 sec/batch; 2h:42m:06s remains)
INFO - root - 2019-11-06 17:42:03.586263: step 7500, total loss = 0.90, predict loss = 0.24 (69.2 examples/sec; 0.058 sec/batch; 2h:17m:16s remains)
INFO - root - 2019-11-06 17:42:04.114146: step 7510, total loss = 1.24, predict loss = 0.36 (99.5 examples/sec; 0.040 sec/batch; 1h:35m:26s remains)
INFO - root - 2019-11-06 17:42:04.561226: step 7520, total loss = 0.83, predict loss = 0.20 (105.1 examples/sec; 0.038 sec/batch; 1h:30m:21s remains)
INFO - root - 2019-11-06 17:42:05.696600: step 7530, total loss = 0.90, predict loss = 0.25 (71.7 examples/sec; 0.056 sec/batch; 2h:12m:30s remains)
INFO - root - 2019-11-06 17:42:06.365450: step 7540, total loss = 1.47, predict loss = 0.42 (58.7 examples/sec; 0.068 sec/batch; 2h:41m:49s remains)
INFO - root - 2019-11-06 17:42:07.090746: step 7550, total loss = 0.62, predict loss = 0.15 (64.8 examples/sec; 0.062 sec/batch; 2h:26m:38s remains)
INFO - root - 2019-11-06 17:42:07.821015: step 7560, total loss = 1.52, predict loss = 0.43 (60.0 examples/sec; 0.067 sec/batch; 2h:38m:15s remains)
INFO - root - 2019-11-06 17:42:08.569184: step 7570, total loss = 0.68, predict loss = 0.16 (61.8 examples/sec; 0.065 sec/batch; 2h:33m:45s remains)
INFO - root - 2019-11-06 17:42:09.182879: step 7580, total loss = 0.62, predict loss = 0.15 (91.1 examples/sec; 0.044 sec/batch; 1h:44m:12s remains)
INFO - root - 2019-11-06 17:42:09.601097: step 7590, total loss = 0.81, predict loss = 0.20 (103.1 examples/sec; 0.039 sec/batch; 1h:32m:05s remains)
INFO - root - 2019-11-06 17:42:10.046071: step 7600, total loss = 1.04, predict loss = 0.24 (98.7 examples/sec; 0.041 sec/batch; 1h:36m:11s remains)
INFO - root - 2019-11-06 17:42:11.307637: step 7610, total loss = 0.84, predict loss = 0.20 (56.7 examples/sec; 0.071 sec/batch; 2h:47m:19s remains)
INFO - root - 2019-11-06 17:42:12.109604: step 7620, total loss = 1.27, predict loss = 0.37 (59.7 examples/sec; 0.067 sec/batch; 2h:38m:57s remains)
INFO - root - 2019-11-06 17:42:12.882166: step 7630, total loss = 0.50, predict loss = 0.13 (57.2 examples/sec; 0.070 sec/batch; 2h:46m:04s remains)
INFO - root - 2019-11-06 17:42:13.591938: step 7640, total loss = 0.39, predict loss = 0.11 (66.0 examples/sec; 0.061 sec/batch; 2h:23m:42s remains)
INFO - root - 2019-11-06 17:42:14.321946: step 7650, total loss = 1.76, predict loss = 0.54 (67.0 examples/sec; 0.060 sec/batch; 2h:21m:43s remains)
INFO - root - 2019-11-06 17:42:14.850400: step 7660, total loss = 1.10, predict loss = 0.27 (100.9 examples/sec; 0.040 sec/batch; 1h:34m:03s remains)
INFO - root - 2019-11-06 17:42:15.289256: step 7670, total loss = 0.52, predict loss = 0.21 (95.5 examples/sec; 0.042 sec/batch; 1h:39m:22s remains)
INFO - root - 2019-11-06 17:42:16.461124: step 7680, total loss = 1.25, predict loss = 0.29 (68.1 examples/sec; 0.059 sec/batch; 2h:19m:15s remains)
INFO - root - 2019-11-06 17:42:17.194297: step 7690, total loss = 0.73, predict loss = 0.18 (56.9 examples/sec; 0.070 sec/batch; 2h:46m:39s remains)
INFO - root - 2019-11-06 17:42:18.008408: step 7700, total loss = 0.86, predict loss = 0.21 (45.9 examples/sec; 0.087 sec/batch; 3h:26m:40s remains)
INFO - root - 2019-11-06 17:42:18.736919: step 7710, total loss = 0.87, predict loss = 0.22 (62.7 examples/sec; 0.064 sec/batch; 2h:31m:18s remains)
INFO - root - 2019-11-06 17:42:19.501748: step 7720, total loss = 0.78, predict loss = 0.16 (57.0 examples/sec; 0.070 sec/batch; 2h:46m:24s remains)
INFO - root - 2019-11-06 17:42:20.165910: step 7730, total loss = 0.52, predict loss = 0.12 (96.2 examples/sec; 0.042 sec/batch; 1h:38m:34s remains)
INFO - root - 2019-11-06 17:42:20.638787: step 7740, total loss = 0.70, predict loss = 0.18 (78.7 examples/sec; 0.051 sec/batch; 2h:00m:29s remains)
INFO - root - 2019-11-06 17:42:21.099658: step 7750, total loss = 0.62, predict loss = 0.15 (105.2 examples/sec; 0.038 sec/batch; 1h:30m:09s remains)
INFO - root - 2019-11-06 17:42:22.633914: step 7760, total loss = 1.44, predict loss = 0.42 (67.5 examples/sec; 0.059 sec/batch; 2h:20m:28s remains)
INFO - root - 2019-11-06 17:42:23.417363: step 7770, total loss = 1.05, predict loss = 0.24 (56.4 examples/sec; 0.071 sec/batch; 2h:48m:00s remains)
INFO - root - 2019-11-06 17:42:24.184341: step 7780, total loss = 1.08, predict loss = 0.28 (69.4 examples/sec; 0.058 sec/batch; 2h:16m:34s remains)
INFO - root - 2019-11-06 17:42:24.919672: step 7790, total loss = 1.63, predict loss = 0.48 (55.3 examples/sec; 0.072 sec/batch; 2h:51m:26s remains)
INFO - root - 2019-11-06 17:42:25.572770: step 7800, total loss = 0.98, predict loss = 0.26 (70.2 examples/sec; 0.057 sec/batch; 2h:15m:05s remains)
INFO - root - 2019-11-06 17:42:26.074783: step 7810, total loss = 1.36, predict loss = 0.43 (93.5 examples/sec; 0.043 sec/batch; 1h:41m:23s remains)
INFO - root - 2019-11-06 17:42:26.505401: step 7820, total loss = 1.11, predict loss = 0.33 (104.0 examples/sec; 0.038 sec/batch; 1h:31m:08s remains)
INFO - root - 2019-11-06 17:42:27.695732: step 7830, total loss = 0.70, predict loss = 0.16 (66.5 examples/sec; 0.060 sec/batch; 2h:22m:27s remains)
INFO - root - 2019-11-06 17:42:28.425803: step 7840, total loss = 1.26, predict loss = 0.36 (62.4 examples/sec; 0.064 sec/batch; 2h:31m:57s remains)
INFO - root - 2019-11-06 17:42:29.257248: step 7850, total loss = 0.85, predict loss = 0.23 (51.1 examples/sec; 0.078 sec/batch; 3h:05m:29s remains)
INFO - root - 2019-11-06 17:42:30.073249: step 7860, total loss = 1.16, predict loss = 0.32 (52.1 examples/sec; 0.077 sec/batch; 3h:01m:45s remains)
INFO - root - 2019-11-06 17:42:30.841990: step 7870, total loss = 0.64, predict loss = 0.17 (61.0 examples/sec; 0.066 sec/batch; 2h:35m:19s remains)
INFO - root - 2019-11-06 17:42:31.421210: step 7880, total loss = 1.04, predict loss = 0.27 (107.4 examples/sec; 0.037 sec/batch; 1h:28m:11s remains)
INFO - root - 2019-11-06 17:42:31.902638: step 7890, total loss = 1.10, predict loss = 0.28 (94.7 examples/sec; 0.042 sec/batch; 1h:40m:00s remains)
INFO - root - 2019-11-06 17:42:32.343898: step 7900, total loss = 0.74, predict loss = 0.16 (93.5 examples/sec; 0.043 sec/batch; 1h:41m:16s remains)
INFO - root - 2019-11-06 17:42:33.651352: step 7910, total loss = 0.83, predict loss = 0.20 (63.4 examples/sec; 0.063 sec/batch; 2h:29m:20s remains)
INFO - root - 2019-11-06 17:42:34.356190: step 7920, total loss = 0.96, predict loss = 0.24 (60.7 examples/sec; 0.066 sec/batch; 2h:36m:07s remains)
INFO - root - 2019-11-06 17:42:35.100744: step 7930, total loss = 0.90, predict loss = 0.24 (61.4 examples/sec; 0.065 sec/batch; 2h:34m:09s remains)
INFO - root - 2019-11-06 17:42:35.796625: step 7940, total loss = 1.15, predict loss = 0.34 (64.0 examples/sec; 0.062 sec/batch; 2h:27m:56s remains)
INFO - root - 2019-11-06 17:42:36.470979: step 7950, total loss = 0.92, predict loss = 0.26 (62.7 examples/sec; 0.064 sec/batch; 2h:30m:59s remains)
INFO - root - 2019-11-06 17:42:36.954593: step 7960, total loss = 0.77, predict loss = 0.19 (96.7 examples/sec; 0.041 sec/batch; 1h:37m:52s remains)
INFO - root - 2019-11-06 17:42:37.441691: step 7970, total loss = 1.94, predict loss = 0.57 (96.3 examples/sec; 0.042 sec/batch; 1h:38m:21s remains)
INFO - root - 2019-11-06 17:42:38.594934: step 7980, total loss = 0.91, predict loss = 0.24 (68.7 examples/sec; 0.058 sec/batch; 2h:17m:54s remains)
INFO - root - 2019-11-06 17:42:39.301269: step 7990, total loss = 0.64, predict loss = 0.12 (64.5 examples/sec; 0.062 sec/batch; 2h:26m:50s remains)
INFO - root - 2019-11-06 17:42:40.022569: step 8000, total loss = 1.02, predict loss = 0.26 (61.3 examples/sec; 0.065 sec/batch; 2h:34m:31s remains)
INFO - root - 2019-11-06 17:42:40.766402: step 8010, total loss = 1.40, predict loss = 0.46 (59.2 examples/sec; 0.068 sec/batch; 2h:39m:55s remains)
INFO - root - 2019-11-06 17:42:41.445824: step 8020, total loss = 0.75, predict loss = 0.19 (72.8 examples/sec; 0.055 sec/batch; 2h:09m:59s remains)
INFO - root - 2019-11-06 17:42:41.956575: step 8030, total loss = 0.60, predict loss = 0.16 (90.3 examples/sec; 0.044 sec/batch; 1h:44m:50s remains)
INFO - root - 2019-11-06 17:42:42.392852: step 8040, total loss = 0.82, predict loss = 0.22 (100.8 examples/sec; 0.040 sec/batch; 1h:33m:50s remains)
INFO - root - 2019-11-06 17:42:42.848969: step 8050, total loss = 0.81, predict loss = 0.27 (140.4 examples/sec; 0.028 sec/batch; 1h:07m:23s remains)
INFO - root - 2019-11-06 17:42:44.234729: step 8060, total loss = 1.09, predict loss = 0.27 (53.1 examples/sec; 0.075 sec/batch; 2h:58m:19s remains)
INFO - root - 2019-11-06 17:42:44.958095: step 8070, total loss = 0.66, predict loss = 0.16 (56.6 examples/sec; 0.071 sec/batch; 2h:47m:17s remains)
INFO - root - 2019-11-06 17:42:45.691551: step 8080, total loss = 1.01, predict loss = 0.28 (60.3 examples/sec; 0.066 sec/batch; 2h:36m:50s remains)
INFO - root - 2019-11-06 17:42:46.445476: step 8090, total loss = 1.49, predict loss = 0.48 (63.1 examples/sec; 0.063 sec/batch; 2h:29m:51s remains)
INFO - root - 2019-11-06 17:42:47.108511: step 8100, total loss = 0.83, predict loss = 0.23 (82.9 examples/sec; 0.048 sec/batch; 1h:54m:04s remains)
INFO - root - 2019-11-06 17:42:47.572727: step 8110, total loss = 0.44, predict loss = 0.12 (95.6 examples/sec; 0.042 sec/batch; 1h:38m:54s remains)
INFO - root - 2019-11-06 17:42:48.014861: step 8120, total loss = 0.74, predict loss = 0.18 (100.0 examples/sec; 0.040 sec/batch; 1h:34m:36s remains)
INFO - root - 2019-11-06 17:42:49.209129: step 8130, total loss = 0.88, predict loss = 0.20 (73.0 examples/sec; 0.055 sec/batch; 2h:09m:38s remains)
INFO - root - 2019-11-06 17:42:49.921816: step 8140, total loss = 0.89, predict loss = 0.23 (52.0 examples/sec; 0.077 sec/batch; 3h:01m:42s remains)
INFO - root - 2019-11-06 17:42:50.637338: step 8150, total loss = 1.05, predict loss = 0.29 (61.2 examples/sec; 0.065 sec/batch; 2h:34m:25s remains)
INFO - root - 2019-11-06 17:42:51.329041: step 8160, total loss = 0.99, predict loss = 0.28 (60.5 examples/sec; 0.066 sec/batch; 2h:36m:23s remains)
INFO - root - 2019-11-06 17:42:52.056856: step 8170, total loss = 1.37, predict loss = 0.43 (68.0 examples/sec; 0.059 sec/batch; 2h:19m:06s remains)
INFO - root - 2019-11-06 17:42:52.565647: step 8180, total loss = 2.13, predict loss = 0.64 (101.1 examples/sec; 0.040 sec/batch; 1h:33m:28s remains)
INFO - root - 2019-11-06 17:42:53.010042: step 8190, total loss = 1.02, predict loss = 0.27 (109.7 examples/sec; 0.036 sec/batch; 1h:26m:10s remains)
INFO - root - 2019-11-06 17:42:54.104027: step 8200, total loss = 0.91, predict loss = 0.25 (5.6 examples/sec; 0.717 sec/batch; 28h:14m:46s remains)
INFO - root - 2019-11-06 17:42:54.845736: step 8210, total loss = 1.19, predict loss = 0.30 (60.9 examples/sec; 0.066 sec/batch; 2h:35m:18s remains)
INFO - root - 2019-11-06 17:42:55.507591: step 8220, total loss = 0.86, predict loss = 0.23 (65.8 examples/sec; 0.061 sec/batch; 2h:23m:37s remains)
INFO - root - 2019-11-06 17:42:56.196742: step 8230, total loss = 0.70, predict loss = 0.17 (56.7 examples/sec; 0.071 sec/batch; 2h:46m:46s remains)
INFO - root - 2019-11-06 17:42:56.966231: step 8240, total loss = 0.25, predict loss = 0.09 (50.1 examples/sec; 0.080 sec/batch; 3h:08m:41s remains)
INFO - root - 2019-11-06 17:42:57.607974: step 8250, total loss = 1.01, predict loss = 0.25 (96.9 examples/sec; 0.041 sec/batch; 1h:37m:33s remains)
INFO - root - 2019-11-06 17:42:58.049416: step 8260, total loss = 1.08, predict loss = 0.27 (94.3 examples/sec; 0.042 sec/batch; 1h:40m:13s remains)
INFO - root - 2019-11-06 17:42:58.488900: step 8270, total loss = 1.14, predict loss = 0.32 (99.6 examples/sec; 0.040 sec/batch; 1h:34m:49s remains)
INFO - root - 2019-11-06 17:42:59.852965: step 8280, total loss = 0.87, predict loss = 0.22 (61.1 examples/sec; 0.065 sec/batch; 2h:34m:37s remains)
INFO - root - 2019-11-06 17:43:00.585125: step 8290, total loss = 1.08, predict loss = 0.29 (64.8 examples/sec; 0.062 sec/batch; 2h:25m:50s remains)
INFO - root - 2019-11-06 17:43:01.314147: step 8300, total loss = 1.39, predict loss = 0.41 (61.6 examples/sec; 0.065 sec/batch; 2h:33m:24s remains)
INFO - root - 2019-11-06 17:43:02.155085: step 8310, total loss = 0.91, predict loss = 0.21 (58.0 examples/sec; 0.069 sec/batch; 2h:42m:55s remains)
INFO - root - 2019-11-06 17:43:02.870783: step 8320, total loss = 0.76, predict loss = 0.18 (69.2 examples/sec; 0.058 sec/batch; 2h:16m:24s remains)
INFO - root - 2019-11-06 17:43:03.414385: step 8330, total loss = 0.98, predict loss = 0.27 (92.4 examples/sec; 0.043 sec/batch; 1h:42m:12s remains)
INFO - root - 2019-11-06 17:43:03.866703: step 8340, total loss = 0.82, predict loss = 0.18 (92.1 examples/sec; 0.043 sec/batch; 1h:42m:29s remains)
INFO - root - 2019-11-06 17:43:05.044581: step 8350, total loss = 0.58, predict loss = 0.15 (59.4 examples/sec; 0.067 sec/batch; 2h:38m:54s remains)
INFO - root - 2019-11-06 17:43:05.788688: step 8360, total loss = 0.97, predict loss = 0.23 (62.9 examples/sec; 0.064 sec/batch; 2h:30m:03s remains)
INFO - root - 2019-11-06 17:43:06.551408: step 8370, total loss = 0.42, predict loss = 0.09 (53.0 examples/sec; 0.075 sec/batch; 2h:58m:04s remains)
INFO - root - 2019-11-06 17:43:07.294574: step 8380, total loss = 1.65, predict loss = 0.44 (60.1 examples/sec; 0.067 sec/batch; 2h:37m:00s remains)
INFO - root - 2019-11-06 17:43:08.007553: step 8390, total loss = 0.91, predict loss = 0.21 (67.6 examples/sec; 0.059 sec/batch; 2h:19m:37s remains)
INFO - root - 2019-11-06 17:43:08.781536: step 8400, total loss = 1.24, predict loss = 0.44 (78.9 examples/sec; 0.051 sec/batch; 1h:59m:37s remains)
INFO - root - 2019-11-06 17:43:09.256509: step 8410, total loss = 0.56, predict loss = 0.15 (99.3 examples/sec; 0.040 sec/batch; 1h:35m:04s remains)
INFO - root - 2019-11-06 17:43:09.711276: step 8420, total loss = 0.61, predict loss = 0.17 (95.1 examples/sec; 0.042 sec/batch; 1h:39m:16s remains)
INFO - root - 2019-11-06 17:43:10.944304: step 8430, total loss = 0.75, predict loss = 0.20 (63.8 examples/sec; 0.063 sec/batch; 2h:27m:57s remains)
INFO - root - 2019-11-06 17:43:11.712152: step 8440, total loss = 1.15, predict loss = 0.33 (59.0 examples/sec; 0.068 sec/batch; 2h:39m:51s remains)
INFO - root - 2019-11-06 17:43:12.482978: step 8450, total loss = 0.63, predict loss = 0.16 (61.8 examples/sec; 0.065 sec/batch; 2h:32m:35s remains)
INFO - root - 2019-11-06 17:43:13.236470: step 8460, total loss = 1.00, predict loss = 0.25 (47.8 examples/sec; 0.084 sec/batch; 3h:17m:23s remains)
INFO - root - 2019-11-06 17:43:13.950367: step 8470, total loss = 0.79, predict loss = 0.22 (67.3 examples/sec; 0.059 sec/batch; 2h:20m:13s remains)
INFO - root - 2019-11-06 17:43:14.471875: step 8480, total loss = 1.37, predict loss = 0.36 (98.6 examples/sec; 0.041 sec/batch; 1h:35m:39s remains)
INFO - root - 2019-11-06 17:43:14.938985: step 8490, total loss = 0.98, predict loss = 0.22 (95.6 examples/sec; 0.042 sec/batch; 1h:38m:39s remains)
INFO - root - 2019-11-06 17:43:16.134321: step 8500, total loss = 1.28, predict loss = 0.32 (66.5 examples/sec; 0.060 sec/batch; 2h:21m:50s remains)
INFO - root - 2019-11-06 17:43:16.846238: step 8510, total loss = 0.73, predict loss = 0.18 (58.2 examples/sec; 0.069 sec/batch; 2h:42m:09s remains)
INFO - root - 2019-11-06 17:43:17.592893: step 8520, total loss = 0.75, predict loss = 0.17 (54.0 examples/sec; 0.074 sec/batch; 2h:54m:45s remains)
INFO - root - 2019-11-06 17:43:18.332168: step 8530, total loss = 1.01, predict loss = 0.28 (63.0 examples/sec; 0.064 sec/batch; 2h:29m:43s remains)
INFO - root - 2019-11-06 17:43:19.001671: step 8540, total loss = 0.57, predict loss = 0.13 (67.2 examples/sec; 0.059 sec/batch; 2h:20m:15s remains)
INFO - root - 2019-11-06 17:43:19.584389: step 8550, total loss = 0.68, predict loss = 0.17 (98.2 examples/sec; 0.041 sec/batch; 1h:35m:59s remains)
INFO - root - 2019-11-06 17:43:20.021656: step 8560, total loss = 0.75, predict loss = 0.20 (96.6 examples/sec; 0.041 sec/batch; 1h:37m:34s remains)
INFO - root - 2019-11-06 17:43:20.491200: step 8570, total loss = 1.00, predict loss = 0.25 (105.4 examples/sec; 0.038 sec/batch; 1h:29m:29s remains)
INFO - root - 2019-11-06 17:43:21.796102: step 8580, total loss = 1.36, predict loss = 0.33 (62.1 examples/sec; 0.064 sec/batch; 2h:31m:49s remains)
INFO - root - 2019-11-06 17:43:22.534982: step 8590, total loss = 0.92, predict loss = 0.22 (63.4 examples/sec; 0.063 sec/batch; 2h:28m:40s remains)
INFO - root - 2019-11-06 17:43:23.239881: step 8600, total loss = 0.41, predict loss = 0.10 (63.7 examples/sec; 0.063 sec/batch; 2h:28m:04s remains)
INFO - root - 2019-11-06 17:43:23.987888: step 8610, total loss = 0.76, predict loss = 0.18 (63.8 examples/sec; 0.063 sec/batch; 2h:27m:50s remains)
INFO - root - 2019-11-06 17:43:24.660324: step 8620, total loss = 1.31, predict loss = 0.39 (71.7 examples/sec; 0.056 sec/batch; 2h:11m:27s remains)
INFO - root - 2019-11-06 17:43:25.199291: step 8630, total loss = 0.62, predict loss = 0.17 (92.6 examples/sec; 0.043 sec/batch; 1h:41m:49s remains)
INFO - root - 2019-11-06 17:43:25.680298: step 8640, total loss = 0.75, predict loss = 0.19 (93.7 examples/sec; 0.043 sec/batch; 1h:40m:33s remains)
INFO - root - 2019-11-06 17:43:26.923361: step 8650, total loss = 1.06, predict loss = 0.26 (74.6 examples/sec; 0.054 sec/batch; 2h:06m:15s remains)
INFO - root - 2019-11-06 17:43:27.598298: step 8660, total loss = 1.18, predict loss = 0.30 (57.8 examples/sec; 0.069 sec/batch; 2h:43m:04s remains)
INFO - root - 2019-11-06 17:43:28.377213: step 8670, total loss = 0.38, predict loss = 0.11 (55.2 examples/sec; 0.072 sec/batch; 2h:50m:34s remains)
INFO - root - 2019-11-06 17:43:29.111702: step 8680, total loss = 1.35, predict loss = 0.40 (61.2 examples/sec; 0.065 sec/batch; 2h:33m:49s remains)
INFO - root - 2019-11-06 17:43:29.792657: step 8690, total loss = 1.18, predict loss = 0.33 (68.0 examples/sec; 0.059 sec/batch; 2h:18m:29s remains)
INFO - root - 2019-11-06 17:43:30.351614: step 8700, total loss = 0.63, predict loss = 0.18 (103.0 examples/sec; 0.039 sec/batch; 1h:31m:25s remains)
INFO - root - 2019-11-06 17:43:30.827482: step 8710, total loss = 1.04, predict loss = 0.24 (96.1 examples/sec; 0.042 sec/batch; 1h:37m:58s remains)
INFO - root - 2019-11-06 17:43:31.274522: step 8720, total loss = 1.26, predict loss = 0.36 (89.1 examples/sec; 0.045 sec/batch; 1h:45m:44s remains)
INFO - root - 2019-11-06 17:43:32.723722: step 8730, total loss = 1.05, predict loss = 0.25 (42.1 examples/sec; 0.095 sec/batch; 3h:43m:31s remains)
INFO - root - 2019-11-06 17:43:33.451733: step 8740, total loss = 0.84, predict loss = 0.22 (55.8 examples/sec; 0.072 sec/batch; 2h:48m:50s remains)
INFO - root - 2019-11-06 17:43:34.235343: step 8750, total loss = 0.96, predict loss = 0.24 (62.1 examples/sec; 0.064 sec/batch; 2h:31m:37s remains)
INFO - root - 2019-11-06 17:43:34.964862: step 8760, total loss = 0.99, predict loss = 0.28 (56.9 examples/sec; 0.070 sec/batch; 2h:45m:22s remains)
INFO - root - 2019-11-06 17:43:35.615384: step 8770, total loss = 0.77, predict loss = 0.20 (77.6 examples/sec; 0.052 sec/batch; 2h:01m:22s remains)
INFO - root - 2019-11-06 17:43:36.059207: step 8780, total loss = 0.65, predict loss = 0.21 (102.5 examples/sec; 0.039 sec/batch; 1h:31m:51s remains)
INFO - root - 2019-11-06 17:43:36.485180: step 8790, total loss = 0.71, predict loss = 0.18 (104.1 examples/sec; 0.038 sec/batch; 1h:30m:24s remains)
INFO - root - 2019-11-06 17:43:37.744919: step 8800, total loss = 0.91, predict loss = 0.23 (67.6 examples/sec; 0.059 sec/batch; 2h:19m:14s remains)
INFO - root - 2019-11-06 17:43:38.479174: step 8810, total loss = 0.85, predict loss = 0.23 (61.7 examples/sec; 0.065 sec/batch; 2h:32m:37s remains)
INFO - root - 2019-11-06 17:43:39.177881: step 8820, total loss = 0.99, predict loss = 0.25 (61.5 examples/sec; 0.065 sec/batch; 2h:33m:06s remains)
INFO - root - 2019-11-06 17:43:39.929005: step 8830, total loss = 1.32, predict loss = 0.36 (57.5 examples/sec; 0.070 sec/batch; 2h:43m:41s remains)
INFO - root - 2019-11-06 17:43:40.701589: step 8840, total loss = 1.53, predict loss = 0.37 (62.6 examples/sec; 0.064 sec/batch; 2h:30m:19s remains)
INFO - root - 2019-11-06 17:43:41.265989: step 8850, total loss = 0.88, predict loss = 0.18 (95.1 examples/sec; 0.042 sec/batch; 1h:38m:54s remains)
INFO - root - 2019-11-06 17:43:41.712406: step 8860, total loss = 1.36, predict loss = 0.38 (93.0 examples/sec; 0.043 sec/batch; 1h:41m:07s remains)
INFO - root - 2019-11-06 17:43:42.158012: step 8870, total loss = 0.40, predict loss = 0.09 (130.1 examples/sec; 0.031 sec/batch; 1h:12m:17s remains)
INFO - root - 2019-11-06 17:43:43.554982: step 8880, total loss = 1.58, predict loss = 0.47 (56.0 examples/sec; 0.071 sec/batch; 2h:47m:57s remains)
INFO - root - 2019-11-06 17:43:44.343062: step 8890, total loss = 1.65, predict loss = 0.51 (60.8 examples/sec; 0.066 sec/batch; 2h:34m:50s remains)
INFO - root - 2019-11-06 17:43:45.054515: step 8900, total loss = 1.10, predict loss = 0.26 (74.0 examples/sec; 0.054 sec/batch; 2h:07m:07s remains)
INFO - root - 2019-11-06 17:43:45.735266: step 8910, total loss = 0.61, predict loss = 0.14 (59.2 examples/sec; 0.068 sec/batch; 2h:38m:48s remains)
INFO - root - 2019-11-06 17:43:46.368018: step 8920, total loss = 1.18, predict loss = 0.37 (80.9 examples/sec; 0.049 sec/batch; 1h:56m:14s remains)
INFO - root - 2019-11-06 17:43:46.835631: step 8930, total loss = 0.72, predict loss = 0.15 (108.2 examples/sec; 0.037 sec/batch; 1h:26m:55s remains)
INFO - root - 2019-11-06 17:43:47.270812: step 8940, total loss = 0.71, predict loss = 0.20 (104.4 examples/sec; 0.038 sec/batch; 1h:30m:06s remains)
INFO - root - 2019-11-06 17:43:48.472761: step 8950, total loss = 0.44, predict loss = 0.10 (47.7 examples/sec; 0.084 sec/batch; 3h:17m:03s remains)
INFO - root - 2019-11-06 17:43:49.224792: step 8960, total loss = 1.56, predict loss = 0.45 (42.2 examples/sec; 0.095 sec/batch; 3h:42m:38s remains)
INFO - root - 2019-11-06 17:43:49.926227: step 8970, total loss = 0.61, predict loss = 0.17 (61.7 examples/sec; 0.065 sec/batch; 2h:32m:17s remains)
INFO - root - 2019-11-06 17:43:50.641542: step 8980, total loss = 1.30, predict loss = 0.32 (62.2 examples/sec; 0.064 sec/batch; 2h:31m:06s remains)
INFO - root - 2019-11-06 17:43:51.381103: step 8990, total loss = 1.10, predict loss = 0.34 (62.5 examples/sec; 0.064 sec/batch; 2h:30m:25s remains)
INFO - root - 2019-11-06 17:43:51.939049: step 9000, total loss = 1.13, predict loss = 0.29 (104.0 examples/sec; 0.038 sec/batch; 1h:30m:24s remains)
INFO - root - 2019-11-06 17:43:52.397839: step 9010, total loss = 0.85, predict loss = 0.22 (98.9 examples/sec; 0.040 sec/batch; 1h:35m:00s remains)
INFO - root - 2019-11-06 17:43:53.483054: step 9020, total loss = 0.68, predict loss = 0.18 (5.7 examples/sec; 0.705 sec/batch; 27h:36m:37s remains)
INFO - root - 2019-11-06 17:43:54.214044: step 9030, total loss = 0.77, predict loss = 0.19 (48.6 examples/sec; 0.082 sec/batch; 3h:13m:25s remains)
INFO - root - 2019-11-06 17:43:54.955389: step 9040, total loss = 1.01, predict loss = 0.30 (58.1 examples/sec; 0.069 sec/batch; 2h:41m:52s remains)
INFO - root - 2019-11-06 17:43:55.763848: step 9050, total loss = 1.62, predict loss = 0.41 (45.7 examples/sec; 0.088 sec/batch; 3h:25m:35s remains)
INFO - root - 2019-11-06 17:43:56.514393: step 9060, total loss = 0.47, predict loss = 0.14 (59.6 examples/sec; 0.067 sec/batch; 2h:37m:39s remains)
INFO - root - 2019-11-06 17:43:57.214496: step 9070, total loss = 1.56, predict loss = 0.52 (80.6 examples/sec; 0.050 sec/batch; 1h:56m:38s remains)
INFO - root - 2019-11-06 17:43:57.698373: step 9080, total loss = 0.96, predict loss = 0.26 (92.6 examples/sec; 0.043 sec/batch; 1h:41m:28s remains)
INFO - root - 2019-11-06 17:43:58.151779: step 9090, total loss = 0.65, predict loss = 0.15 (99.4 examples/sec; 0.040 sec/batch; 1h:34m:30s remains)
INFO - root - 2019-11-06 17:43:59.389678: step 9100, total loss = 1.35, predict loss = 0.44 (60.9 examples/sec; 0.066 sec/batch; 2h:34m:10s remains)
INFO - root - 2019-11-06 17:44:00.211577: step 9110, total loss = 1.08, predict loss = 0.34 (51.1 examples/sec; 0.078 sec/batch; 3h:03m:48s remains)
INFO - root - 2019-11-06 17:44:01.049455: step 9120, total loss = 0.90, predict loss = 0.21 (52.1 examples/sec; 0.077 sec/batch; 3h:00m:07s remains)
INFO - root - 2019-11-06 17:44:01.802213: step 9130, total loss = 1.34, predict loss = 0.29 (54.8 examples/sec; 0.073 sec/batch; 2h:51m:30s remains)
INFO - root - 2019-11-06 17:44:02.497322: step 9140, total loss = 1.11, predict loss = 0.28 (73.3 examples/sec; 0.055 sec/batch; 2h:08m:08s remains)
INFO - root - 2019-11-06 17:44:02.970148: step 9150, total loss = 1.20, predict loss = 0.30 (108.2 examples/sec; 0.037 sec/batch; 1h:26m:49s remains)
INFO - root - 2019-11-06 17:44:03.412694: step 9160, total loss = 0.58, predict loss = 0.14 (107.5 examples/sec; 0.037 sec/batch; 1h:27m:21s remains)
INFO - root - 2019-11-06 17:44:04.681766: step 9170, total loss = 1.28, predict loss = 0.35 (57.5 examples/sec; 0.070 sec/batch; 2h:43m:10s remains)
INFO - root - 2019-11-06 17:44:05.515425: step 9180, total loss = 1.29, predict loss = 0.39 (55.6 examples/sec; 0.072 sec/batch; 2h:48m:45s remains)
INFO - root - 2019-11-06 17:44:06.186685: step 9190, total loss = 0.85, predict loss = 0.24 (68.1 examples/sec; 0.059 sec/batch; 2h:17m:50s remains)
INFO - root - 2019-11-06 17:44:06.922005: step 9200, total loss = 0.78, predict loss = 0.20 (57.1 examples/sec; 0.070 sec/batch; 2h:44m:23s remains)
INFO - root - 2019-11-06 17:44:07.670389: step 9210, total loss = 1.10, predict loss = 0.36 (55.8 examples/sec; 0.072 sec/batch; 2h:48m:07s remains)
INFO - root - 2019-11-06 17:44:08.304779: step 9220, total loss = 0.98, predict loss = 0.26 (96.7 examples/sec; 0.041 sec/batch; 1h:37m:05s remains)
INFO - root - 2019-11-06 17:44:08.760071: step 9230, total loss = 0.69, predict loss = 0.15 (99.4 examples/sec; 0.040 sec/batch; 1h:34m:23s remains)
INFO - root - 2019-11-06 17:44:09.190442: step 9240, total loss = 0.98, predict loss = 0.25 (101.7 examples/sec; 0.039 sec/batch; 1h:32m:16s remains)
INFO - root - 2019-11-06 17:44:10.464757: step 9250, total loss = 1.63, predict loss = 0.48 (57.0 examples/sec; 0.070 sec/batch; 2h:44m:41s remains)
INFO - root - 2019-11-06 17:44:11.289442: step 9260, total loss = 1.46, predict loss = 0.40 (49.4 examples/sec; 0.081 sec/batch; 3h:10m:02s remains)
INFO - root - 2019-11-06 17:44:12.028649: step 9270, total loss = 0.89, predict loss = 0.24 (59.6 examples/sec; 0.067 sec/batch; 2h:37m:26s remains)
INFO - root - 2019-11-06 17:44:12.772494: step 9280, total loss = 0.91, predict loss = 0.23 (62.6 examples/sec; 0.064 sec/batch; 2h:29m:49s remains)
INFO - root - 2019-11-06 17:44:13.488761: step 9290, total loss = 0.94, predict loss = 0.30 (62.6 examples/sec; 0.064 sec/batch; 2h:29m:55s remains)
INFO - root - 2019-11-06 17:44:13.979624: step 9300, total loss = 1.17, predict loss = 0.37 (100.7 examples/sec; 0.040 sec/batch; 1h:33m:09s remains)
INFO - root - 2019-11-06 17:44:14.426589: step 9310, total loss = 0.61, predict loss = 0.18 (90.7 examples/sec; 0.044 sec/batch; 1h:43m:23s remains)
INFO - root - 2019-11-06 17:44:15.581709: step 9320, total loss = 0.56, predict loss = 0.13 (67.2 examples/sec; 0.060 sec/batch; 2h:19m:39s remains)
INFO - root - 2019-11-06 17:44:16.306001: step 9330, total loss = 0.60, predict loss = 0.15 (61.6 examples/sec; 0.065 sec/batch; 2h:32m:11s remains)
INFO - root - 2019-11-06 17:44:17.022605: step 9340, total loss = 2.30, predict loss = 0.61 (62.0 examples/sec; 0.065 sec/batch; 2h:31m:19s remains)
INFO - root - 2019-11-06 17:44:17.786083: step 9350, total loss = 1.91, predict loss = 0.58 (56.3 examples/sec; 0.071 sec/batch; 2h:46m:28s remains)
INFO - root - 2019-11-06 17:44:18.561264: step 9360, total loss = 0.52, predict loss = 0.15 (61.4 examples/sec; 0.065 sec/batch; 2h:32m:39s remains)
INFO - root - 2019-11-06 17:44:19.189113: step 9370, total loss = 1.65, predict loss = 0.48 (96.0 examples/sec; 0.042 sec/batch; 1h:37m:37s remains)
INFO - root - 2019-11-06 17:44:19.628598: step 9380, total loss = 1.04, predict loss = 0.27 (96.4 examples/sec; 0.042 sec/batch; 1h:37m:16s remains)
INFO - root - 2019-11-06 17:44:20.069128: step 9390, total loss = 0.49, predict loss = 0.14 (97.0 examples/sec; 0.041 sec/batch; 1h:36m:36s remains)
INFO - root - 2019-11-06 17:44:21.396723: step 9400, total loss = 1.51, predict loss = 0.42 (60.8 examples/sec; 0.066 sec/batch; 2h:34m:16s remains)
INFO - root - 2019-11-06 17:44:22.210897: step 9410, total loss = 1.10, predict loss = 0.30 (52.6 examples/sec; 0.076 sec/batch; 2h:58m:17s remains)
INFO - root - 2019-11-06 17:44:22.936863: step 9420, total loss = 1.01, predict loss = 0.24 (53.7 examples/sec; 0.074 sec/batch; 2h:54m:21s remains)
INFO - root - 2019-11-06 17:44:23.714741: step 9430, total loss = 0.40, predict loss = 0.10 (56.8 examples/sec; 0.070 sec/batch; 2h:44m:50s remains)
INFO - root - 2019-11-06 17:44:24.456393: step 9440, total loss = 0.63, predict loss = 0.18 (70.2 examples/sec; 0.057 sec/batch; 2h:13m:31s remains)
INFO - root - 2019-11-06 17:44:25.009589: step 9450, total loss = 1.03, predict loss = 0.30 (96.1 examples/sec; 0.042 sec/batch; 1h:37m:28s remains)
INFO - root - 2019-11-06 17:44:25.452584: step 9460, total loss = 0.92, predict loss = 0.28 (94.9 examples/sec; 0.042 sec/batch; 1h:38m:45s remains)
INFO - root - 2019-11-06 17:44:26.632660: step 9470, total loss = 0.77, predict loss = 0.21 (67.0 examples/sec; 0.060 sec/batch; 2h:19m:50s remains)
INFO - root - 2019-11-06 17:44:27.383827: step 9480, total loss = 0.72, predict loss = 0.17 (48.9 examples/sec; 0.082 sec/batch; 3h:11m:43s remains)
INFO - root - 2019-11-06 17:44:28.120575: step 9490, total loss = 0.58, predict loss = 0.13 (62.8 examples/sec; 0.064 sec/batch; 2h:29m:03s remains)
INFO - root - 2019-11-06 17:44:28.894960: step 9500, total loss = 1.22, predict loss = 0.30 (63.2 examples/sec; 0.063 sec/batch; 2h:28m:11s remains)
INFO - root - 2019-11-06 17:44:29.636406: step 9510, total loss = 1.33, predict loss = 0.42 (67.9 examples/sec; 0.059 sec/batch; 2h:17m:59s remains)
INFO - root - 2019-11-06 17:44:30.211287: step 9520, total loss = 1.11, predict loss = 0.31 (104.1 examples/sec; 0.038 sec/batch; 1h:29m:58s remains)
INFO - root - 2019-11-06 17:44:30.682861: step 9530, total loss = 0.99, predict loss = 0.29 (104.7 examples/sec; 0.038 sec/batch; 1h:29m:28s remains)
INFO - root - 2019-11-06 17:44:31.126774: step 9540, total loss = 0.62, predict loss = 0.19 (91.1 examples/sec; 0.044 sec/batch; 1h:42m:45s remains)
INFO - root - 2019-11-06 17:44:32.448614: step 9550, total loss = 1.02, predict loss = 0.25 (57.3 examples/sec; 0.070 sec/batch; 2h:43m:22s remains)
INFO - root - 2019-11-06 17:44:33.163809: step 9560, total loss = 0.80, predict loss = 0.22 (59.1 examples/sec; 0.068 sec/batch; 2h:38m:32s remains)
INFO - root - 2019-11-06 17:44:33.917342: step 9570, total loss = 1.51, predict loss = 0.49 (63.3 examples/sec; 0.063 sec/batch; 2h:27m:52s remains)
INFO - root - 2019-11-06 17:44:34.650245: step 9580, total loss = 0.43, predict loss = 0.11 (49.1 examples/sec; 0.081 sec/batch; 3h:10m:28s remains)
INFO - root - 2019-11-06 17:44:35.365675: step 9590, total loss = 0.87, predict loss = 0.24 (64.8 examples/sec; 0.062 sec/batch; 2h:24m:29s remains)
INFO - root - 2019-11-06 17:44:35.857909: step 9600, total loss = 0.79, predict loss = 0.18 (95.7 examples/sec; 0.042 sec/batch; 1h:37m:48s remains)
INFO - root - 2019-11-06 17:44:36.319255: step 9610, total loss = 0.86, predict loss = 0.22 (101.1 examples/sec; 0.040 sec/batch; 1h:32m:35s remains)
INFO - root - 2019-11-06 17:44:37.538688: step 9620, total loss = 0.65, predict loss = 0.16 (67.2 examples/sec; 0.059 sec/batch; 2h:19m:10s remains)
INFO - root - 2019-11-06 17:44:38.298980: step 9630, total loss = 0.86, predict loss = 0.23 (68.6 examples/sec; 0.058 sec/batch; 2h:16m:21s remains)
INFO - root - 2019-11-06 17:44:38.976808: step 9640, total loss = 1.11, predict loss = 0.35 (72.9 examples/sec; 0.055 sec/batch; 2h:08m:21s remains)
INFO - root - 2019-11-06 17:44:39.683636: step 9650, total loss = 1.22, predict loss = 0.32 (66.3 examples/sec; 0.060 sec/batch; 2h:21m:02s remains)
INFO - root - 2019-11-06 17:44:40.384867: step 9660, total loss = 1.09, predict loss = 0.31 (60.0 examples/sec; 0.067 sec/batch; 2h:35m:50s remains)
INFO - root - 2019-11-06 17:44:40.945569: step 9670, total loss = 0.85, predict loss = 0.22 (108.5 examples/sec; 0.037 sec/batch; 1h:26m:13s remains)
INFO - root - 2019-11-06 17:44:41.379914: step 9680, total loss = 1.20, predict loss = 0.31 (103.6 examples/sec; 0.039 sec/batch; 1h:30m:17s remains)
INFO - root - 2019-11-06 17:44:41.831098: step 9690, total loss = 0.26, predict loss = 0.09 (123.9 examples/sec; 0.032 sec/batch; 1h:15m:30s remains)
INFO - root - 2019-11-06 17:44:43.165637: step 9700, total loss = 0.68, predict loss = 0.17 (55.6 examples/sec; 0.072 sec/batch; 2h:48m:06s remains)
INFO - root - 2019-11-06 17:44:43.863755: step 9710, total loss = 1.44, predict loss = 0.43 (63.6 examples/sec; 0.063 sec/batch; 2h:26m:57s remains)
INFO - root - 2019-11-06 17:44:44.587018: step 9720, total loss = 0.45, predict loss = 0.11 (61.5 examples/sec; 0.065 sec/batch; 2h:32m:07s remains)
INFO - root - 2019-11-06 17:44:45.321489: step 9730, total loss = 0.58, predict loss = 0.15 (59.2 examples/sec; 0.068 sec/batch; 2h:38m:03s remains)
INFO - root - 2019-11-06 17:44:45.975150: step 9740, total loss = 0.69, predict loss = 0.19 (82.3 examples/sec; 0.049 sec/batch; 1h:53m:40s remains)
INFO - root - 2019-11-06 17:44:46.432955: step 9750, total loss = 1.19, predict loss = 0.30 (92.8 examples/sec; 0.043 sec/batch; 1h:40m:44s remains)
INFO - root - 2019-11-06 17:44:46.899376: step 9760, total loss = 0.44, predict loss = 0.13 (72.2 examples/sec; 0.055 sec/batch; 2h:09m:30s remains)
INFO - root - 2019-11-06 17:44:48.141027: step 9770, total loss = 1.01, predict loss = 0.28 (51.9 examples/sec; 0.077 sec/batch; 3h:00m:05s remains)
INFO - root - 2019-11-06 17:44:48.887007: step 9780, total loss = 1.11, predict loss = 0.33 (52.7 examples/sec; 0.076 sec/batch; 2h:57m:29s remains)
INFO - root - 2019-11-06 17:44:49.627170: step 9790, total loss = 1.04, predict loss = 0.24 (57.3 examples/sec; 0.070 sec/batch; 2h:43m:00s remains)
INFO - root - 2019-11-06 17:44:50.403458: step 9800, total loss = 0.80, predict loss = 0.24 (55.0 examples/sec; 0.073 sec/batch; 2h:49m:53s remains)
INFO - root - 2019-11-06 17:44:51.200067: step 9810, total loss = 0.95, predict loss = 0.23 (65.2 examples/sec; 0.061 sec/batch; 2h:23m:26s remains)
INFO - root - 2019-11-06 17:44:51.751859: step 9820, total loss = 0.46, predict loss = 0.13 (101.7 examples/sec; 0.039 sec/batch; 1h:31m:55s remains)
INFO - root - 2019-11-06 17:44:52.209536: step 9830, total loss = 0.44, predict loss = 0.12 (107.6 examples/sec; 0.037 sec/batch; 1h:26m:51s remains)
INFO - root - 2019-11-06 17:44:53.364255: step 9840, total loss = 0.90, predict loss = 0.26 (5.2 examples/sec; 0.767 sec/batch; 29h:51m:08s remains)
INFO - root - 2019-11-06 17:44:54.099072: step 9850, total loss = 0.99, predict loss = 0.23 (68.9 examples/sec; 0.058 sec/batch; 2h:15m:35s remains)
INFO - root - 2019-11-06 17:44:54.799904: step 9860, total loss = 0.81, predict loss = 0.21 (59.8 examples/sec; 0.067 sec/batch; 2h:36m:09s remains)
INFO - root - 2019-11-06 17:44:55.569875: step 9870, total loss = 0.44, predict loss = 0.10 (51.6 examples/sec; 0.078 sec/batch; 3h:01m:01s remains)
INFO - root - 2019-11-06 17:44:56.340655: step 9880, total loss = 0.81, predict loss = 0.22 (49.6 examples/sec; 0.081 sec/batch; 3h:08m:31s remains)
INFO - root - 2019-11-06 17:44:57.070345: step 9890, total loss = 1.67, predict loss = 0.50 (70.8 examples/sec; 0.057 sec/batch; 2h:11m:59s remains)
INFO - root - 2019-11-06 17:44:57.532160: step 9900, total loss = 0.89, predict loss = 0.27 (105.8 examples/sec; 0.038 sec/batch; 1h:28m:16s remains)
INFO - root - 2019-11-06 17:44:58.007031: step 9910, total loss = 0.60, predict loss = 0.16 (101.0 examples/sec; 0.040 sec/batch; 1h:32m:25s remains)
INFO - root - 2019-11-06 17:44:59.326502: step 9920, total loss = 0.56, predict loss = 0.13 (66.7 examples/sec; 0.060 sec/batch; 2h:19m:58s remains)
INFO - root - 2019-11-06 17:45:00.128283: step 9930, total loss = 1.34, predict loss = 0.33 (52.6 examples/sec; 0.076 sec/batch; 2h:57m:32s remains)
INFO - root - 2019-11-06 17:45:00.865536: step 9940, total loss = 0.86, predict loss = 0.26 (63.3 examples/sec; 0.063 sec/batch; 2h:27m:29s remains)
INFO - root - 2019-11-06 17:45:01.610004: step 9950, total loss = 0.46, predict loss = 0.10 (57.0 examples/sec; 0.070 sec/batch; 2h:43m:43s remains)
INFO - root - 2019-11-06 17:45:02.365485: step 9960, total loss = 1.40, predict loss = 0.40 (70.1 examples/sec; 0.057 sec/batch; 2h:13m:07s remains)
INFO - root - 2019-11-06 17:45:02.930402: step 9970, total loss = 0.81, predict loss = 0.24 (102.2 examples/sec; 0.039 sec/batch; 1h:31m:20s remains)
INFO - root - 2019-11-06 17:45:03.377531: step 9980, total loss = 0.96, predict loss = 0.27 (90.9 examples/sec; 0.044 sec/batch; 1h:42m:39s remains)
INFO - root - 2019-11-06 17:45:04.506423: step 9990, total loss = 0.88, predict loss = 0.23 (68.6 examples/sec; 0.058 sec/batch; 2h:15m:59s remains)
INFO - root - 2019-11-06 17:45:05.207969: step 10000, total loss = 0.72, predict loss = 0.18 (58.7 examples/sec; 0.068 sec/batch; 2h:39m:01s remains)
INFO - root - 2019-11-06 17:45:05.985927: step 10010, total loss = 1.03, predict loss = 0.27 (55.1 examples/sec; 0.073 sec/batch; 2h:49m:13s remains)
INFO - root - 2019-11-06 17:45:06.766140: step 10020, total loss = 1.08, predict loss = 0.32 (61.6 examples/sec; 0.065 sec/batch; 2h:31m:31s remains)
INFO - root - 2019-11-06 17:45:07.533687: step 10030, total loss = 0.91, predict loss = 0.24 (61.2 examples/sec; 0.065 sec/batch; 2h:32m:29s remains)
INFO - root - 2019-11-06 17:45:08.160243: step 10040, total loss = 0.76, predict loss = 0.20 (98.4 examples/sec; 0.041 sec/batch; 1h:34m:46s remains)
INFO - root - 2019-11-06 17:45:08.637193: step 10050, total loss = 0.86, predict loss = 0.24 (95.2 examples/sec; 0.042 sec/batch; 1h:38m:00s remains)
INFO - root - 2019-11-06 17:45:09.083204: step 10060, total loss = 1.03, predict loss = 0.25 (99.5 examples/sec; 0.040 sec/batch; 1h:33m:44s remains)
INFO - root - 2019-11-06 17:45:10.304633: step 10070, total loss = 0.69, predict loss = 0.18 (61.4 examples/sec; 0.065 sec/batch; 2h:31m:56s remains)
INFO - root - 2019-11-06 17:45:11.000679: step 10080, total loss = 0.49, predict loss = 0.13 (44.9 examples/sec; 0.089 sec/batch; 3h:27m:35s remains)
INFO - root - 2019-11-06 17:45:11.796479: step 10090, total loss = 0.83, predict loss = 0.23 (48.3 examples/sec; 0.083 sec/batch; 3h:12m:58s remains)
INFO - root - 2019-11-06 17:45:12.556230: step 10100, total loss = 0.83, predict loss = 0.22 (64.3 examples/sec; 0.062 sec/batch; 2h:25m:00s remains)
INFO - root - 2019-11-06 17:45:13.226663: step 10110, total loss = 1.16, predict loss = 0.32 (71.1 examples/sec; 0.056 sec/batch; 2h:11m:14s remains)
INFO - root - 2019-11-06 17:45:13.728623: step 10120, total loss = 0.52, predict loss = 0.13 (100.7 examples/sec; 0.040 sec/batch; 1h:32m:35s remains)
INFO - root - 2019-11-06 17:45:14.201783: step 10130, total loss = 1.50, predict loss = 0.45 (95.4 examples/sec; 0.042 sec/batch; 1h:37m:41s remains)
INFO - root - 2019-11-06 17:45:15.389649: step 10140, total loss = 1.29, predict loss = 0.35 (70.8 examples/sec; 0.056 sec/batch; 2h:11m:41s remains)
INFO - root - 2019-11-06 17:45:16.092706: step 10150, total loss = 1.03, predict loss = 0.28 (56.2 examples/sec; 0.071 sec/batch; 2h:46m:01s remains)
INFO - root - 2019-11-06 17:45:16.839473: step 10160, total loss = 0.68, predict loss = 0.16 (60.8 examples/sec; 0.066 sec/batch; 2h:33m:16s remains)
INFO - root - 2019-11-06 17:45:17.575830: step 10170, total loss = 0.58, predict loss = 0.16 (59.0 examples/sec; 0.068 sec/batch; 2h:38m:00s remains)
INFO - root - 2019-11-06 17:45:18.292375: step 10180, total loss = 0.38, predict loss = 0.09 (61.9 examples/sec; 0.065 sec/batch; 2h:30m:38s remains)
INFO - root - 2019-11-06 17:45:18.882601: step 10190, total loss = 1.29, predict loss = 0.36 (105.2 examples/sec; 0.038 sec/batch; 1h:28m:33s remains)
INFO - root - 2019-11-06 17:45:19.337888: step 10200, total loss = 0.98, predict loss = 0.25 (103.7 examples/sec; 0.039 sec/batch; 1h:29m:54s remains)
INFO - root - 2019-11-06 17:45:19.797921: step 10210, total loss = 0.91, predict loss = 0.23 (96.3 examples/sec; 0.042 sec/batch; 1h:36m:48s remains)
INFO - root - 2019-11-06 17:45:21.053861: step 10220, total loss = 1.37, predict loss = 0.38 (60.2 examples/sec; 0.066 sec/batch; 2h:34m:55s remains)
INFO - root - 2019-11-06 17:45:21.826032: step 10230, total loss = 1.70, predict loss = 0.56 (62.9 examples/sec; 0.064 sec/batch; 2h:28m:05s remains)
INFO - root - 2019-11-06 17:45:22.618574: step 10240, total loss = 0.90, predict loss = 0.22 (58.6 examples/sec; 0.068 sec/batch; 2h:38m:53s remains)
INFO - root - 2019-11-06 17:45:23.349015: step 10250, total loss = 1.08, predict loss = 0.29 (61.8 examples/sec; 0.065 sec/batch; 2h:30m:52s remains)
INFO - root - 2019-11-06 17:45:24.016267: step 10260, total loss = 1.02, predict loss = 0.30 (79.4 examples/sec; 0.050 sec/batch; 1h:57m:21s remains)
INFO - root - 2019-11-06 17:45:24.484728: step 10270, total loss = 0.99, predict loss = 0.26 (100.4 examples/sec; 0.040 sec/batch; 1h:32m:49s remains)
INFO - root - 2019-11-06 17:45:24.935771: step 10280, total loss = 0.82, predict loss = 0.22 (98.7 examples/sec; 0.041 sec/batch; 1h:34m:20s remains)
INFO - root - 2019-11-06 17:45:26.100972: step 10290, total loss = 0.80, predict loss = 0.19 (76.0 examples/sec; 0.053 sec/batch; 2h:02m:35s remains)
INFO - root - 2019-11-06 17:45:26.797017: step 10300, total loss = 1.05, predict loss = 0.31 (64.0 examples/sec; 0.063 sec/batch; 2h:25m:34s remains)
INFO - root - 2019-11-06 17:45:27.510358: step 10310, total loss = 0.61, predict loss = 0.17 (60.4 examples/sec; 0.066 sec/batch; 2h:34m:07s remains)
INFO - root - 2019-11-06 17:45:28.310866: step 10320, total loss = 1.22, predict loss = 0.35 (53.6 examples/sec; 0.075 sec/batch; 2h:53m:49s remains)
INFO - root - 2019-11-06 17:45:29.052368: step 10330, total loss = 0.69, predict loss = 0.16 (60.7 examples/sec; 0.066 sec/batch; 2h:33m:23s remains)
INFO - root - 2019-11-06 17:45:29.654180: step 10340, total loss = 0.90, predict loss = 0.24 (101.3 examples/sec; 0.039 sec/batch; 1h:31m:53s remains)
INFO - root - 2019-11-06 17:45:30.102750: step 10350, total loss = 1.00, predict loss = 0.27 (98.4 examples/sec; 0.041 sec/batch; 1h:34m:38s remains)
INFO - root - 2019-11-06 17:45:30.559157: step 10360, total loss = 0.63, predict loss = 0.15 (103.5 examples/sec; 0.039 sec/batch; 1h:29m:54s remains)
INFO - root - 2019-11-06 17:45:31.903941: step 10370, total loss = 0.78, predict loss = 0.19 (58.9 examples/sec; 0.068 sec/batch; 2h:38m:10s remains)
INFO - root - 2019-11-06 17:45:32.667841: step 10380, total loss = 0.61, predict loss = 0.14 (68.5 examples/sec; 0.058 sec/batch; 2h:15m:56s remains)
INFO - root - 2019-11-06 17:45:33.435486: step 10390, total loss = 0.83, predict loss = 0.16 (60.8 examples/sec; 0.066 sec/batch; 2h:33m:06s remains)
INFO - root - 2019-11-06 17:45:34.247098: step 10400, total loss = 1.60, predict loss = 0.54 (61.5 examples/sec; 0.065 sec/batch; 2h:31m:17s remains)
INFO - root - 2019-11-06 17:45:34.996422: step 10410, total loss = 0.65, predict loss = 0.16 (68.6 examples/sec; 0.058 sec/batch; 2h:15m:44s remains)
INFO - root - 2019-11-06 17:45:35.471022: step 10420, total loss = 0.79, predict loss = 0.19 (96.7 examples/sec; 0.041 sec/batch; 1h:36m:16s remains)
INFO - root - 2019-11-06 17:45:35.908510: step 10430, total loss = 0.80, predict loss = 0.19 (102.2 examples/sec; 0.039 sec/batch; 1h:31m:01s remains)
INFO - root - 2019-11-06 17:45:37.098312: step 10440, total loss = 1.03, predict loss = 0.28 (66.1 examples/sec; 0.061 sec/batch; 2h:20m:45s remains)
INFO - root - 2019-11-06 17:45:37.802603: step 10450, total loss = 1.18, predict loss = 0.35 (66.7 examples/sec; 0.060 sec/batch; 2h:19m:28s remains)
INFO - root - 2019-11-06 17:45:38.581275: step 10460, total loss = 1.43, predict loss = 0.50 (59.5 examples/sec; 0.067 sec/batch; 2h:36m:14s remains)
INFO - root - 2019-11-06 17:45:39.384962: step 10470, total loss = 0.86, predict loss = 0.23 (63.2 examples/sec; 0.063 sec/batch; 2h:27m:15s remains)
INFO - root - 2019-11-06 17:45:40.094163: step 10480, total loss = 0.87, predict loss = 0.24 (63.8 examples/sec; 0.063 sec/batch; 2h:25m:47s remains)
INFO - root - 2019-11-06 17:45:40.616390: step 10490, total loss = 0.94, predict loss = 0.24 (101.3 examples/sec; 0.039 sec/batch; 1h:31m:49s remains)
INFO - root - 2019-11-06 17:45:41.041523: step 10500, total loss = 0.45, predict loss = 0.09 (102.7 examples/sec; 0.039 sec/batch; 1h:30m:34s remains)
INFO - root - 2019-11-06 17:45:41.469882: step 10510, total loss = 1.28, predict loss = 0.39 (135.4 examples/sec; 0.030 sec/batch; 1h:08m:39s remains)
INFO - root - 2019-11-06 17:45:42.825085: step 10520, total loss = 0.76, predict loss = 0.28 (62.9 examples/sec; 0.064 sec/batch; 2h:27m:44s remains)
INFO - root - 2019-11-06 17:45:43.560046: step 10530, total loss = 0.83, predict loss = 0.21 (63.8 examples/sec; 0.063 sec/batch; 2h:25m:43s remains)
INFO - root - 2019-11-06 17:45:44.262672: step 10540, total loss = 0.78, predict loss = 0.19 (59.1 examples/sec; 0.068 sec/batch; 2h:37m:13s remains)
INFO - root - 2019-11-06 17:45:45.008069: step 10550, total loss = 0.57, predict loss = 0.15 (55.2 examples/sec; 0.072 sec/batch; 2h:48m:30s remains)
INFO - root - 2019-11-06 17:45:45.693054: step 10560, total loss = 1.12, predict loss = 0.36 (71.8 examples/sec; 0.056 sec/batch; 2h:09m:24s remains)
INFO - root - 2019-11-06 17:45:46.186215: step 10570, total loss = 1.44, predict loss = 0.40 (93.0 examples/sec; 0.043 sec/batch; 1h:39m:58s remains)
INFO - root - 2019-11-06 17:45:46.624953: step 10580, total loss = 0.88, predict loss = 0.19 (100.4 examples/sec; 0.040 sec/batch; 1h:32m:34s remains)
INFO - root - 2019-11-06 17:45:47.851406: step 10590, total loss = 0.39, predict loss = 0.09 (65.2 examples/sec; 0.061 sec/batch; 2h:22m:30s remains)
INFO - root - 2019-11-06 17:45:48.559495: step 10600, total loss = 0.83, predict loss = 0.20 (64.3 examples/sec; 0.062 sec/batch; 2h:24m:28s remains)
INFO - root - 2019-11-06 17:45:49.350564: step 10610, total loss = 0.53, predict loss = 0.14 (52.7 examples/sec; 0.076 sec/batch; 2h:56m:25s remains)
INFO - root - 2019-11-06 17:45:50.133083: step 10620, total loss = 1.25, predict loss = 0.34 (52.4 examples/sec; 0.076 sec/batch; 2h:57m:23s remains)
INFO - root - 2019-11-06 17:45:50.886036: step 10630, total loss = 0.92, predict loss = 0.20 (69.9 examples/sec; 0.057 sec/batch; 2h:12m:57s remains)
INFO - root - 2019-11-06 17:45:51.479278: step 10640, total loss = 1.00, predict loss = 0.28 (97.2 examples/sec; 0.041 sec/batch; 1h:35m:35s remains)
INFO - root - 2019-11-06 17:45:51.953320: step 10650, total loss = 0.34, predict loss = 0.09 (81.3 examples/sec; 0.049 sec/batch; 1h:54m:13s remains)
INFO - root - 2019-11-06 17:45:53.033976: step 10660, total loss = 0.68, predict loss = 0.15 (5.8 examples/sec; 0.691 sec/batch; 26h:44m:44s remains)
INFO - root - 2019-11-06 17:45:53.718617: step 10670, total loss = 0.52, predict loss = 0.15 (61.8 examples/sec; 0.065 sec/batch; 2h:30m:22s remains)
INFO - root - 2019-11-06 17:45:54.459905: step 10680, total loss = 1.00, predict loss = 0.22 (61.8 examples/sec; 0.065 sec/batch; 2h:30m:16s remains)
INFO - root - 2019-11-06 17:45:55.236586: step 10690, total loss = 0.65, predict loss = 0.16 (57.3 examples/sec; 0.070 sec/batch; 2h:42m:12s remains)
INFO - root - 2019-11-06 17:45:55.956253: step 10700, total loss = 1.10, predict loss = 0.28 (67.7 examples/sec; 0.059 sec/batch; 2h:17m:04s remains)
INFO - root - 2019-11-06 17:45:56.602403: step 10710, total loss = 0.73, predict loss = 0.18 (93.0 examples/sec; 0.043 sec/batch; 1h:39m:48s remains)
INFO - root - 2019-11-06 17:45:57.057662: step 10720, total loss = 0.64, predict loss = 0.18 (98.5 examples/sec; 0.041 sec/batch; 1h:34m:17s remains)
INFO - root - 2019-11-06 17:45:57.528863: step 10730, total loss = 0.43, predict loss = 0.09 (97.6 examples/sec; 0.041 sec/batch; 1h:35m:10s remains)
INFO - root - 2019-11-06 17:45:58.736808: step 10740, total loss = 0.75, predict loss = 0.18 (63.8 examples/sec; 0.063 sec/batch; 2h:25m:34s remains)
INFO - root - 2019-11-06 17:45:59.448555: step 10750, total loss = 0.99, predict loss = 0.24 (69.8 examples/sec; 0.057 sec/batch; 2h:12m:58s remains)
INFO - root - 2019-11-06 17:46:00.162525: step 10760, total loss = 0.86, predict loss = 0.24 (61.9 examples/sec; 0.065 sec/batch; 2h:30m:02s remains)
INFO - root - 2019-11-06 17:46:00.953827: step 10770, total loss = 0.80, predict loss = 0.21 (57.2 examples/sec; 0.070 sec/batch; 2h:42m:18s remains)
INFO - root - 2019-11-06 17:46:01.625833: step 10780, total loss = 0.92, predict loss = 0.24 (77.2 examples/sec; 0.052 sec/batch; 2h:00m:10s remains)
INFO - root - 2019-11-06 17:46:02.117250: step 10790, total loss = 0.79, predict loss = 0.21 (91.5 examples/sec; 0.044 sec/batch; 1h:41m:28s remains)
INFO - root - 2019-11-06 17:46:02.567352: step 10800, total loss = 1.28, predict loss = 0.38 (94.5 examples/sec; 0.042 sec/batch; 1h:38m:10s remains)
INFO - root - 2019-11-06 17:46:03.676761: step 10810, total loss = 0.56, predict loss = 0.12 (71.6 examples/sec; 0.056 sec/batch; 2h:09m:32s remains)
INFO - root - 2019-11-06 17:46:04.357520: step 10820, total loss = 0.62, predict loss = 0.14 (62.8 examples/sec; 0.064 sec/batch; 2h:27m:38s remains)
INFO - root - 2019-11-06 17:46:05.102156: step 10830, total loss = 0.95, predict loss = 0.27 (55.0 examples/sec; 0.073 sec/batch; 2h:48m:42s remains)
INFO - root - 2019-11-06 17:46:05.902647: step 10840, total loss = 0.54, predict loss = 0.14 (57.8 examples/sec; 0.069 sec/batch; 2h:40m:27s remains)
INFO - root - 2019-11-06 17:46:06.653380: step 10850, total loss = 1.31, predict loss = 0.38 (60.8 examples/sec; 0.066 sec/batch; 2h:32m:28s remains)
INFO - root - 2019-11-06 17:46:07.289572: step 10860, total loss = 1.63, predict loss = 0.46 (92.8 examples/sec; 0.043 sec/batch; 1h:39m:58s remains)
INFO - root - 2019-11-06 17:46:07.717185: step 10870, total loss = 0.97, predict loss = 0.32 (97.9 examples/sec; 0.041 sec/batch; 1h:34m:43s remains)
INFO - root - 2019-11-06 17:46:08.177163: step 10880, total loss = 0.75, predict loss = 0.18 (93.2 examples/sec; 0.043 sec/batch; 1h:39m:32s remains)
INFO - root - 2019-11-06 17:46:09.510876: step 10890, total loss = 1.09, predict loss = 0.29 (50.9 examples/sec; 0.079 sec/batch; 3h:02m:05s remains)
INFO - root - 2019-11-06 17:46:10.288613: step 10900, total loss = 0.73, predict loss = 0.16 (64.8 examples/sec; 0.062 sec/batch; 2h:23m:13s remains)
INFO - root - 2019-11-06 17:46:10.950799: step 10910, total loss = 0.92, predict loss = 0.26 (62.4 examples/sec; 0.064 sec/batch; 2h:28m:31s remains)
INFO - root - 2019-11-06 17:46:11.642565: step 10920, total loss = 0.70, predict loss = 0.16 (55.5 examples/sec; 0.072 sec/batch; 2h:47m:08s remains)
INFO - root - 2019-11-06 17:46:12.322835: step 10930, total loss = 2.21, predict loss = 0.87 (85.8 examples/sec; 0.047 sec/batch; 1h:48m:00s remains)
INFO - root - 2019-11-06 17:46:12.801909: step 10940, total loss = 0.88, predict loss = 0.25 (93.0 examples/sec; 0.043 sec/batch; 1h:39m:44s remains)
INFO - root - 2019-11-06 17:46:13.258203: step 10950, total loss = 0.80, predict loss = 0.22 (98.6 examples/sec; 0.041 sec/batch; 1h:34m:03s remains)
INFO - root - 2019-11-06 17:46:14.442745: step 10960, total loss = 1.26, predict loss = 0.41 (62.6 examples/sec; 0.064 sec/batch; 2h:28m:06s remains)
INFO - root - 2019-11-06 17:46:15.277653: step 10970, total loss = 0.62, predict loss = 0.15 (49.7 examples/sec; 0.080 sec/batch; 3h:06m:19s remains)
INFO - root - 2019-11-06 17:46:16.025033: step 10980, total loss = 0.90, predict loss = 0.22 (65.2 examples/sec; 0.061 sec/batch; 2h:22m:08s remains)
INFO - root - 2019-11-06 17:46:16.764960: step 10990, total loss = 1.37, predict loss = 0.37 (55.3 examples/sec; 0.072 sec/batch; 2h:47m:34s remains)
INFO - root - 2019-11-06 17:46:17.515000: step 11000, total loss = 0.85, predict loss = 0.24 (57.2 examples/sec; 0.070 sec/batch; 2h:42m:05s remains)
INFO - root - 2019-11-06 17:46:18.136147: step 11010, total loss = 0.53, predict loss = 0.13 (101.5 examples/sec; 0.039 sec/batch; 1h:31m:15s remains)
INFO - root - 2019-11-06 17:46:18.587566: step 11020, total loss = 0.97, predict loss = 0.27 (100.5 examples/sec; 0.040 sec/batch; 1h:32m:13s remains)
INFO - root - 2019-11-06 17:46:19.061366: step 11030, total loss = 0.66, predict loss = 0.18 (97.9 examples/sec; 0.041 sec/batch; 1h:34m:37s remains)
INFO - root - 2019-11-06 17:46:20.389491: step 11040, total loss = 0.44, predict loss = 0.10 (67.9 examples/sec; 0.059 sec/batch; 2h:16m:22s remains)
INFO - root - 2019-11-06 17:46:21.082708: step 11050, total loss = 0.82, predict loss = 0.20 (68.7 examples/sec; 0.058 sec/batch; 2h:14m:46s remains)
INFO - root - 2019-11-06 17:46:21.782795: step 11060, total loss = 0.90, predict loss = 0.28 (54.0 examples/sec; 0.074 sec/batch; 2h:51m:33s remains)
INFO - root - 2019-11-06 17:46:22.604811: step 11070, total loss = 0.76, predict loss = 0.21 (47.8 examples/sec; 0.084 sec/batch; 3h:13m:48s remains)
INFO - root - 2019-11-06 17:46:23.323770: step 11080, total loss = 1.14, predict loss = 0.33 (71.4 examples/sec; 0.056 sec/batch; 2h:09m:41s remains)
INFO - root - 2019-11-06 17:46:23.830696: step 11090, total loss = 1.58, predict loss = 0.56 (101.3 examples/sec; 0.039 sec/batch; 1h:31m:23s remains)
INFO - root - 2019-11-06 17:46:24.275735: step 11100, total loss = 0.62, predict loss = 0.17 (99.7 examples/sec; 0.040 sec/batch; 1h:32m:53s remains)
INFO - root - 2019-11-06 17:46:25.451477: step 11110, total loss = 0.49, predict loss = 0.12 (69.3 examples/sec; 0.058 sec/batch; 2h:13m:35s remains)
INFO - root - 2019-11-06 17:46:26.171895: step 11120, total loss = 0.78, predict loss = 0.20 (61.9 examples/sec; 0.065 sec/batch; 2h:29m:40s remains)
INFO - root - 2019-11-06 17:46:26.946676: step 11130, total loss = 1.15, predict loss = 0.31 (53.2 examples/sec; 0.075 sec/batch; 2h:54m:08s remains)
INFO - root - 2019-11-06 17:46:27.726234: step 11140, total loss = 0.75, predict loss = 0.20 (59.6 examples/sec; 0.067 sec/batch; 2h:35m:23s remains)
INFO - root - 2019-11-06 17:46:28.496755: step 11150, total loss = 0.99, predict loss = 0.23 (51.0 examples/sec; 0.078 sec/batch; 3h:01m:35s remains)
INFO - root - 2019-11-06 17:46:29.097892: step 11160, total loss = 0.72, predict loss = 0.17 (97.8 examples/sec; 0.041 sec/batch; 1h:34m:36s remains)
INFO - root - 2019-11-06 17:46:29.563967: step 11170, total loss = 0.86, predict loss = 0.24 (102.8 examples/sec; 0.039 sec/batch; 1h:30m:02s remains)
INFO - root - 2019-11-06 17:46:30.017353: step 11180, total loss = 1.62, predict loss = 0.48 (102.0 examples/sec; 0.039 sec/batch; 1h:30m:46s remains)
INFO - root - 2019-11-06 17:46:31.356255: step 11190, total loss = 0.95, predict loss = 0.20 (53.5 examples/sec; 0.075 sec/batch; 2h:52m:57s remains)
INFO - root - 2019-11-06 17:46:32.023268: step 11200, total loss = 1.35, predict loss = 0.39 (53.9 examples/sec; 0.074 sec/batch; 2h:51m:48s remains)
INFO - root - 2019-11-06 17:46:32.711070: step 11210, total loss = 0.97, predict loss = 0.26 (59.7 examples/sec; 0.067 sec/batch; 2h:35m:06s remains)
INFO - root - 2019-11-06 17:46:33.501448: step 11220, total loss = 0.94, predict loss = 0.25 (46.9 examples/sec; 0.085 sec/batch; 3h:17m:08s remains)
INFO - root - 2019-11-06 17:46:34.229313: step 11230, total loss = 1.34, predict loss = 0.34 (67.8 examples/sec; 0.059 sec/batch; 2h:16m:32s remains)
INFO - root - 2019-11-06 17:46:34.684571: step 11240, total loss = 0.70, predict loss = 0.20 (102.3 examples/sec; 0.039 sec/batch; 1h:30m:27s remains)
INFO - root - 2019-11-06 17:46:35.144848: step 11250, total loss = 0.80, predict loss = 0.22 (103.3 examples/sec; 0.039 sec/batch; 1h:29m:33s remains)
INFO - root - 2019-11-06 17:46:36.348120: step 11260, total loss = 0.71, predict loss = 0.16 (69.7 examples/sec; 0.057 sec/batch; 2h:12m:41s remains)
INFO - root - 2019-11-06 17:46:37.072217: step 11270, total loss = 1.30, predict loss = 0.36 (61.3 examples/sec; 0.065 sec/batch; 2h:30m:50s remains)
INFO - root - 2019-11-06 17:46:37.811271: step 11280, total loss = 0.45, predict loss = 0.11 (61.7 examples/sec; 0.065 sec/batch; 2h:29m:46s remains)
INFO - root - 2019-11-06 17:46:38.554349: step 11290, total loss = 0.42, predict loss = 0.10 (55.9 examples/sec; 0.072 sec/batch; 2h:45m:33s remains)
INFO - root - 2019-11-06 17:46:39.238932: step 11300, total loss = 0.61, predict loss = 0.13 (62.1 examples/sec; 0.064 sec/batch; 2h:28m:47s remains)
INFO - root - 2019-11-06 17:46:39.797420: step 11310, total loss = 0.76, predict loss = 0.17 (102.4 examples/sec; 0.039 sec/batch; 1h:30m:18s remains)
INFO - root - 2019-11-06 17:46:40.236916: step 11320, total loss = 1.00, predict loss = 0.21 (94.5 examples/sec; 0.042 sec/batch; 1h:37m:48s remains)
INFO - root - 2019-11-06 17:46:40.682250: step 11330, total loss = 0.83, predict loss = 0.22 (134.4 examples/sec; 0.030 sec/batch; 1h:08m:47s remains)
INFO - root - 2019-11-06 17:46:42.128601: step 11340, total loss = 0.49, predict loss = 0.12 (50.6 examples/sec; 0.079 sec/batch; 3h:02m:50s remains)
INFO - root - 2019-11-06 17:46:42.887773: step 11350, total loss = 0.56, predict loss = 0.16 (46.3 examples/sec; 0.086 sec/batch; 3h:19m:38s remains)
INFO - root - 2019-11-06 17:46:43.672825: step 11360, total loss = 1.54, predict loss = 0.43 (55.1 examples/sec; 0.073 sec/batch; 2h:47m:39s remains)
INFO - root - 2019-11-06 17:46:44.445693: step 11370, total loss = 1.44, predict loss = 0.43 (63.8 examples/sec; 0.063 sec/batch; 2h:24m:52s remains)
INFO - root - 2019-11-06 17:46:45.144098: step 11380, total loss = 0.59, predict loss = 0.14 (74.9 examples/sec; 0.053 sec/batch; 2h:03m:24s remains)
INFO - root - 2019-11-06 17:46:45.598875: step 11390, total loss = 0.84, predict loss = 0.22 (95.7 examples/sec; 0.042 sec/batch; 1h:36m:30s remains)
INFO - root - 2019-11-06 17:46:46.048403: step 11400, total loss = 1.00, predict loss = 0.25 (97.1 examples/sec; 0.041 sec/batch; 1h:35m:10s remains)
INFO - root - 2019-11-06 17:46:47.268147: step 11410, total loss = 1.03, predict loss = 0.25 (66.3 examples/sec; 0.060 sec/batch; 2h:19m:21s remains)
INFO - root - 2019-11-06 17:46:47.963991: step 11420, total loss = 0.76, predict loss = 0.18 (63.1 examples/sec; 0.063 sec/batch; 2h:26m:18s remains)
INFO - root - 2019-11-06 17:46:48.751614: step 11430, total loss = 0.62, predict loss = 0.13 (59.4 examples/sec; 0.067 sec/batch; 2h:35m:36s remains)
INFO - root - 2019-11-06 17:46:49.492861: step 11440, total loss = 0.99, predict loss = 0.25 (63.0 examples/sec; 0.063 sec/batch; 2h:26m:35s remains)
INFO - root - 2019-11-06 17:46:50.200438: step 11450, total loss = 0.80, predict loss = 0.19 (71.8 examples/sec; 0.056 sec/batch; 2h:08m:40s remains)
INFO - root - 2019-11-06 17:46:50.712806: step 11460, total loss = 0.90, predict loss = 0.26 (102.1 examples/sec; 0.039 sec/batch; 1h:30m:24s remains)
INFO - root - 2019-11-06 17:46:51.143205: step 11470, total loss = 0.57, predict loss = 0.15 (98.5 examples/sec; 0.041 sec/batch; 1h:33m:43s remains)
INFO - root - 2019-11-06 17:46:52.264932: step 11480, total loss = 0.61, predict loss = 0.15 (5.5 examples/sec; 0.728 sec/batch; 27h:59m:38s remains)
INFO - root - 2019-11-06 17:46:52.940241: step 11490, total loss = 0.98, predict loss = 0.21 (69.4 examples/sec; 0.058 sec/batch; 2h:13m:02s remains)
INFO - root - 2019-11-06 17:46:53.656837: step 11500, total loss = 1.02, predict loss = 0.28 (63.3 examples/sec; 0.063 sec/batch; 2h:25m:52s remains)
INFO - root - 2019-11-06 17:46:54.443747: step 11510, total loss = 1.09, predict loss = 0.28 (60.5 examples/sec; 0.066 sec/batch; 2h:32m:36s remains)
INFO - root - 2019-11-06 17:46:55.164122: step 11520, total loss = 0.98, predict loss = 0.27 (62.4 examples/sec; 0.064 sec/batch; 2h:27m:59s remains)
INFO - root - 2019-11-06 17:46:55.788954: step 11530, total loss = 0.76, predict loss = 0.20 (95.4 examples/sec; 0.042 sec/batch; 1h:36m:48s remains)
INFO - root - 2019-11-06 17:46:56.237247: step 11540, total loss = 1.11, predict loss = 0.36 (94.6 examples/sec; 0.042 sec/batch; 1h:37m:33s remains)
INFO - root - 2019-11-06 17:46:56.688834: step 11550, total loss = 0.95, predict loss = 0.29 (92.1 examples/sec; 0.043 sec/batch; 1h:40m:15s remains)
INFO - root - 2019-11-06 17:46:57.952520: step 11560, total loss = 0.50, predict loss = 0.12 (68.0 examples/sec; 0.059 sec/batch; 2h:15m:38s remains)
INFO - root - 2019-11-06 17:46:58.750542: step 11570, total loss = 0.88, predict loss = 0.26 (59.1 examples/sec; 0.068 sec/batch; 2h:36m:09s remains)
INFO - root - 2019-11-06 17:46:59.477844: step 11580, total loss = 0.70, predict loss = 0.19 (58.9 examples/sec; 0.068 sec/batch; 2h:36m:41s remains)
INFO - root - 2019-11-06 17:47:00.256076: step 11590, total loss = 1.30, predict loss = 0.36 (53.3 examples/sec; 0.075 sec/batch; 2h:53m:15s remains)
INFO - root - 2019-11-06 17:47:01.040846: step 11600, total loss = 0.83, predict loss = 0.21 (59.4 examples/sec; 0.067 sec/batch; 2h:35m:21s remains)
INFO - root - 2019-11-06 17:47:01.648724: step 11610, total loss = 1.24, predict loss = 0.37 (92.5 examples/sec; 0.043 sec/batch; 1h:39m:44s remains)
INFO - root - 2019-11-06 17:47:02.086424: step 11620, total loss = 0.48, predict loss = 0.11 (96.1 examples/sec; 0.042 sec/batch; 1h:35m:59s remains)
INFO - root - 2019-11-06 17:47:03.186753: step 11630, total loss = 0.69, predict loss = 0.17 (63.4 examples/sec; 0.063 sec/batch; 2h:25m:23s remains)
INFO - root - 2019-11-06 17:47:03.882285: step 11640, total loss = 1.10, predict loss = 0.31 (68.7 examples/sec; 0.058 sec/batch; 2h:14m:18s remains)
INFO - root - 2019-11-06 17:47:04.620454: step 11650, total loss = 0.29, predict loss = 0.09 (56.4 examples/sec; 0.071 sec/batch; 2h:43m:24s remains)
INFO - root - 2019-11-06 17:47:05.351032: step 11660, total loss = 0.71, predict loss = 0.17 (69.9 examples/sec; 0.057 sec/batch; 2h:11m:59s remains)
INFO - root - 2019-11-06 17:47:06.031906: step 11670, total loss = 0.53, predict loss = 0.15 (73.1 examples/sec; 0.055 sec/batch; 2h:06m:14s remains)
INFO - root - 2019-11-06 17:47:06.663637: step 11680, total loss = 0.45, predict loss = 0.11 (95.7 examples/sec; 0.042 sec/batch; 1h:36m:21s remains)
INFO - root - 2019-11-06 17:47:07.144316: step 11690, total loss = 1.15, predict loss = 0.31 (95.2 examples/sec; 0.042 sec/batch; 1h:36m:49s remains)
INFO - root - 2019-11-06 17:47:07.592363: step 11700, total loss = 1.10, predict loss = 0.27 (103.3 examples/sec; 0.039 sec/batch; 1h:29m:16s remains)
INFO - root - 2019-11-06 17:47:08.987666: step 11710, total loss = 0.55, predict loss = 0.12 (49.6 examples/sec; 0.081 sec/batch; 3h:05m:48s remains)
INFO - root - 2019-11-06 17:47:09.758899: step 11720, total loss = 0.82, predict loss = 0.18 (54.8 examples/sec; 0.073 sec/batch; 2h:48m:21s remains)
INFO - root - 2019-11-06 17:47:10.576639: step 11730, total loss = 0.51, predict loss = 0.14 (58.8 examples/sec; 0.068 sec/batch; 2h:36m:39s remains)
INFO - root - 2019-11-06 17:47:11.306287: step 11740, total loss = 0.88, predict loss = 0.22 (58.2 examples/sec; 0.069 sec/batch; 2h:38m:21s remains)
INFO - root - 2019-11-06 17:47:11.958697: step 11750, total loss = 1.24, predict loss = 0.32 (78.8 examples/sec; 0.051 sec/batch; 1h:56m:56s remains)
INFO - root - 2019-11-06 17:47:12.443819: step 11760, total loss = 0.67, predict loss = 0.20 (97.3 examples/sec; 0.041 sec/batch; 1h:34m:41s remains)
INFO - root - 2019-11-06 17:47:12.948190: step 11770, total loss = 1.34, predict loss = 0.32 (93.3 examples/sec; 0.043 sec/batch; 1h:38m:48s remains)
INFO - root - 2019-11-06 17:47:14.304234: step 11780, total loss = 0.59, predict loss = 0.12 (63.3 examples/sec; 0.063 sec/batch; 2h:25m:40s remains)
INFO - root - 2019-11-06 17:47:15.032975: step 11790, total loss = 0.87, predict loss = 0.22 (58.7 examples/sec; 0.068 sec/batch; 2h:36m:51s remains)
INFO - root - 2019-11-06 17:47:15.790376: step 11800, total loss = 0.79, predict loss = 0.19 (65.2 examples/sec; 0.061 sec/batch; 2h:21m:18s remains)
INFO - root - 2019-11-06 17:47:16.540502: step 11810, total loss = 0.99, predict loss = 0.26 (65.2 examples/sec; 0.061 sec/batch; 2h:21m:22s remains)
INFO - root - 2019-11-06 17:47:17.223852: step 11820, total loss = 0.91, predict loss = 0.23 (53.8 examples/sec; 0.074 sec/batch; 2h:51m:08s remains)
INFO - root - 2019-11-06 17:47:17.926143: step 11830, total loss = 0.99, predict loss = 0.24 (85.0 examples/sec; 0.047 sec/batch; 1h:48m:20s remains)
INFO - root - 2019-11-06 17:47:18.382140: step 11840, total loss = 0.68, predict loss = 0.17 (102.3 examples/sec; 0.039 sec/batch; 1h:30m:03s remains)
INFO - root - 2019-11-06 17:47:18.852451: step 11850, total loss = 0.99, predict loss = 0.28 (91.3 examples/sec; 0.044 sec/batch; 1h:40m:49s remains)
INFO - root - 2019-11-06 17:47:20.244665: step 11860, total loss = 0.77, predict loss = 0.18 (64.9 examples/sec; 0.062 sec/batch; 2h:22m:00s remains)
INFO - root - 2019-11-06 17:47:20.991302: step 11870, total loss = 1.25, predict loss = 0.34 (61.4 examples/sec; 0.065 sec/batch; 2h:29m:58s remains)
INFO - root - 2019-11-06 17:47:21.758774: step 11880, total loss = 0.41, predict loss = 0.10 (71.6 examples/sec; 0.056 sec/batch; 2h:08m:36s remains)
INFO - root - 2019-11-06 17:47:22.490673: step 11890, total loss = 0.75, predict loss = 0.18 (57.0 examples/sec; 0.070 sec/batch; 2h:41m:32s remains)
INFO - root - 2019-11-06 17:47:23.179353: step 11900, total loss = 0.66, predict loss = 0.14 (64.5 examples/sec; 0.062 sec/batch; 2h:22m:48s remains)
INFO - root - 2019-11-06 17:47:23.666574: step 11910, total loss = 1.02, predict loss = 0.27 (101.2 examples/sec; 0.040 sec/batch; 1h:30m:56s remains)
INFO - root - 2019-11-06 17:47:24.118715: step 11920, total loss = 0.72, predict loss = 0.19 (101.9 examples/sec; 0.039 sec/batch; 1h:30m:18s remains)
INFO - root - 2019-11-06 17:47:25.270458: step 11930, total loss = 1.05, predict loss = 0.25 (76.0 examples/sec; 0.053 sec/batch; 2h:01m:07s remains)
INFO - root - 2019-11-06 17:47:25.971450: step 11940, total loss = 0.58, predict loss = 0.13 (65.4 examples/sec; 0.061 sec/batch; 2h:20m:45s remains)
INFO - root - 2019-11-06 17:47:26.647885: step 11950, total loss = 0.45, predict loss = 0.12 (57.4 examples/sec; 0.070 sec/batch; 2h:40m:17s remains)
INFO - root - 2019-11-06 17:47:27.372867: step 11960, total loss = 1.27, predict loss = 0.35 (58.3 examples/sec; 0.069 sec/batch; 2h:37m:50s remains)
INFO - root - 2019-11-06 17:47:28.138531: step 11970, total loss = 0.54, predict loss = 0.11 (65.9 examples/sec; 0.061 sec/batch; 2h:19m:42s remains)
INFO - root - 2019-11-06 17:47:28.690289: step 11980, total loss = 0.88, predict loss = 0.24 (107.9 examples/sec; 0.037 sec/batch; 1h:25m:18s remains)
INFO - root - 2019-11-06 17:47:29.131583: step 11990, total loss = 0.76, predict loss = 0.16 (102.0 examples/sec; 0.039 sec/batch; 1h:30m:12s remains)
INFO - root - 2019-11-06 17:47:29.592691: step 12000, total loss = 1.13, predict loss = 0.34 (99.8 examples/sec; 0.040 sec/batch; 1h:32m:09s remains)
INFO - root - 2019-11-06 17:47:30.997617: step 12010, total loss = 0.62, predict loss = 0.17 (54.5 examples/sec; 0.073 sec/batch; 2h:48m:46s remains)
INFO - root - 2019-11-06 17:47:31.853779: step 12020, total loss = 0.43, predict loss = 0.10 (66.6 examples/sec; 0.060 sec/batch; 2h:18m:09s remains)
INFO - root - 2019-11-06 17:47:32.607890: step 12030, total loss = 1.33, predict loss = 0.39 (54.1 examples/sec; 0.074 sec/batch; 2h:50m:06s remains)
INFO - root - 2019-11-06 17:47:33.332458: step 12040, total loss = 0.55, predict loss = 0.13 (63.8 examples/sec; 0.063 sec/batch; 2h:24m:03s remains)
INFO - root - 2019-11-06 17:47:34.018830: step 12050, total loss = 0.62, predict loss = 0.17 (73.3 examples/sec; 0.055 sec/batch; 2h:05m:30s remains)
INFO - root - 2019-11-06 17:47:34.503356: step 12060, total loss = 0.80, predict loss = 0.23 (108.5 examples/sec; 0.037 sec/batch; 1h:24m:45s remains)
INFO - root - 2019-11-06 17:47:34.933632: step 12070, total loss = 1.13, predict loss = 0.29 (98.4 examples/sec; 0.041 sec/batch; 1h:33m:24s remains)
INFO - root - 2019-11-06 17:47:36.124733: step 12080, total loss = 1.69, predict loss = 0.55 (68.8 examples/sec; 0.058 sec/batch; 2h:13m:43s remains)
INFO - root - 2019-11-06 17:47:36.861215: step 12090, total loss = 0.93, predict loss = 0.24 (61.8 examples/sec; 0.065 sec/batch; 2h:28m:44s remains)
INFO - root - 2019-11-06 17:47:37.602440: step 12100, total loss = 0.80, predict loss = 0.20 (61.1 examples/sec; 0.065 sec/batch; 2h:30m:31s remains)
INFO - root - 2019-11-06 17:47:38.360993: step 12110, total loss = 0.54, predict loss = 0.14 (60.6 examples/sec; 0.066 sec/batch; 2h:31m:40s remains)
INFO - root - 2019-11-06 17:47:39.161566: step 12120, total loss = 0.93, predict loss = 0.24 (63.2 examples/sec; 0.063 sec/batch; 2h:25m:28s remains)
INFO - root - 2019-11-06 17:47:39.719679: step 12130, total loss = 0.66, predict loss = 0.19 (100.1 examples/sec; 0.040 sec/batch; 1h:31m:50s remains)
INFO - root - 2019-11-06 17:47:40.158279: step 12140, total loss = 1.08, predict loss = 0.27 (97.3 examples/sec; 0.041 sec/batch; 1h:34m:26s remains)
INFO - root - 2019-11-06 17:47:40.606614: step 12150, total loss = 0.83, predict loss = 0.22 (118.4 examples/sec; 0.034 sec/batch; 1h:17m:35s remains)
INFO - root - 2019-11-06 17:47:41.905418: step 12160, total loss = 0.86, predict loss = 0.24 (59.3 examples/sec; 0.067 sec/batch; 2h:34m:53s remains)
INFO - root - 2019-11-06 17:47:42.660369: step 12170, total loss = 0.57, predict loss = 0.14 (62.3 examples/sec; 0.064 sec/batch; 2h:27m:32s remains)
INFO - root - 2019-11-06 17:47:43.443055: step 12180, total loss = 1.25, predict loss = 0.37 (57.6 examples/sec; 0.069 sec/batch; 2h:39m:25s remains)
INFO - root - 2019-11-06 17:47:44.222596: step 12190, total loss = 0.83, predict loss = 0.22 (56.9 examples/sec; 0.070 sec/batch; 2h:41m:28s remains)
INFO - root - 2019-11-06 17:47:44.912706: step 12200, total loss = 0.65, predict loss = 0.17 (67.2 examples/sec; 0.060 sec/batch; 2h:16m:39s remains)
INFO - root - 2019-11-06 17:47:45.428563: step 12210, total loss = 1.41, predict loss = 0.37 (78.0 examples/sec; 0.051 sec/batch; 1h:57m:45s remains)
INFO - root - 2019-11-06 17:47:45.866743: step 12220, total loss = 1.03, predict loss = 0.25 (103.7 examples/sec; 0.039 sec/batch; 1h:28m:33s remains)
INFO - root - 2019-11-06 17:47:47.058949: step 12230, total loss = 0.91, predict loss = 0.23 (60.3 examples/sec; 0.066 sec/batch; 2h:32m:19s remains)
INFO - root - 2019-11-06 17:47:47.882463: step 12240, total loss = 0.70, predict loss = 0.18 (46.0 examples/sec; 0.087 sec/batch; 3h:19m:51s remains)
INFO - root - 2019-11-06 17:47:48.656638: step 12250, total loss = 0.61, predict loss = 0.15 (71.3 examples/sec; 0.056 sec/batch; 2h:08m:50s remains)
INFO - root - 2019-11-06 17:47:49.341519: step 12260, total loss = 0.83, predict loss = 0.18 (66.1 examples/sec; 0.061 sec/batch; 2h:19m:01s remains)
INFO - root - 2019-11-06 17:47:50.048317: step 12270, total loss = 1.50, predict loss = 0.47 (63.4 examples/sec; 0.063 sec/batch; 2h:24m:48s remains)
INFO - root - 2019-11-06 17:47:50.596482: step 12280, total loss = 1.44, predict loss = 0.46 (100.2 examples/sec; 0.040 sec/batch; 1h:31m:37s remains)
INFO - root - 2019-11-06 17:47:51.089422: step 12290, total loss = 1.11, predict loss = 0.30 (104.6 examples/sec; 0.038 sec/batch; 1h:27m:44s remains)
INFO - root - 2019-11-06 17:47:52.269811: step 12300, total loss = 0.99, predict loss = 0.23 (5.0 examples/sec; 0.804 sec/batch; 30h:44m:49s remains)
INFO - root - 2019-11-06 17:47:52.921672: step 12310, total loss = 1.03, predict loss = 0.27 (54.1 examples/sec; 0.074 sec/batch; 2h:49m:36s remains)
INFO - root - 2019-11-06 17:47:53.666907: step 12320, total loss = 0.54, predict loss = 0.14 (61.3 examples/sec; 0.065 sec/batch; 2h:29m:47s remains)
INFO - root - 2019-11-06 17:47:54.397535: step 12330, total loss = 0.33, predict loss = 0.09 (64.8 examples/sec; 0.062 sec/batch; 2h:21m:36s remains)
INFO - root - 2019-11-06 17:47:55.156314: step 12340, total loss = 0.59, predict loss = 0.14 (55.1 examples/sec; 0.073 sec/batch; 2h:46m:27s remains)
INFO - root - 2019-11-06 17:47:55.856049: step 12350, total loss = 0.95, predict loss = 0.22 (87.3 examples/sec; 0.046 sec/batch; 1h:45m:05s remains)
INFO - root - 2019-11-06 17:47:56.295901: step 12360, total loss = 0.94, predict loss = 0.27 (99.5 examples/sec; 0.040 sec/batch; 1h:32m:11s remains)
INFO - root - 2019-11-06 17:47:56.761881: step 12370, total loss = 0.70, predict loss = 0.15 (95.5 examples/sec; 0.042 sec/batch; 1h:36m:05s remains)
INFO - root - 2019-11-06 17:47:57.979480: step 12380, total loss = 0.51, predict loss = 0.11 (64.7 examples/sec; 0.062 sec/batch; 2h:21m:48s remains)
INFO - root - 2019-11-06 17:47:58.693477: step 12390, total loss = 0.86, predict loss = 0.21 (53.5 examples/sec; 0.075 sec/batch; 2h:51m:37s remains)
INFO - root - 2019-11-06 17:47:59.484565: step 12400, total loss = 1.02, predict loss = 0.30 (56.5 examples/sec; 0.071 sec/batch; 2h:42m:21s remains)
INFO - root - 2019-11-06 17:48:00.200048: step 12410, total loss = 0.74, predict loss = 0.20 (64.7 examples/sec; 0.062 sec/batch; 2h:21m:47s remains)
INFO - root - 2019-11-06 17:48:00.912199: step 12420, total loss = 0.63, predict loss = 0.16 (63.2 examples/sec; 0.063 sec/batch; 2h:25m:05s remains)
INFO - root - 2019-11-06 17:48:01.476196: step 12430, total loss = 0.71, predict loss = 0.20 (101.1 examples/sec; 0.040 sec/batch; 1h:30m:40s remains)
INFO - root - 2019-11-06 17:48:01.922075: step 12440, total loss = 1.13, predict loss = 0.30 (97.9 examples/sec; 0.041 sec/batch; 1h:33m:41s remains)
INFO - root - 2019-11-06 17:48:03.067804: step 12450, total loss = 0.58, predict loss = 0.12 (71.8 examples/sec; 0.056 sec/batch; 2h:07m:40s remains)
INFO - root - 2019-11-06 17:48:03.734921: step 12460, total loss = 0.80, predict loss = 0.21 (64.4 examples/sec; 0.062 sec/batch; 2h:22m:22s remains)
INFO - root - 2019-11-06 17:48:04.496798: step 12470, total loss = 0.67, predict loss = 0.18 (54.4 examples/sec; 0.074 sec/batch; 2h:48m:33s remains)
INFO - root - 2019-11-06 17:48:05.205807: step 12480, total loss = 0.74, predict loss = 0.20 (62.1 examples/sec; 0.064 sec/batch; 2h:27m:39s remains)
INFO - root - 2019-11-06 17:48:05.948384: step 12490, total loss = 1.33, predict loss = 0.37 (61.0 examples/sec; 0.066 sec/batch; 2h:30m:22s remains)
INFO - root - 2019-11-06 17:48:06.557342: step 12500, total loss = 0.61, predict loss = 0.16 (98.1 examples/sec; 0.041 sec/batch; 1h:33m:26s remains)
INFO - root - 2019-11-06 17:48:06.999039: step 12510, total loss = 1.31, predict loss = 0.33 (96.5 examples/sec; 0.041 sec/batch; 1h:35m:00s remains)
INFO - root - 2019-11-06 17:48:07.443182: step 12520, total loss = 0.84, predict loss = 0.20 (96.9 examples/sec; 0.041 sec/batch; 1h:34m:36s remains)
INFO - root - 2019-11-06 17:48:08.768728: step 12530, total loss = 0.43, predict loss = 0.09 (43.2 examples/sec; 0.093 sec/batch; 3h:32m:22s remains)
INFO - root - 2019-11-06 17:48:09.498671: step 12540, total loss = 0.53, predict loss = 0.12 (60.7 examples/sec; 0.066 sec/batch; 2h:30m:51s remains)
INFO - root - 2019-11-06 17:48:10.197712: step 12550, total loss = 1.00, predict loss = 0.27 (59.7 examples/sec; 0.067 sec/batch; 2h:33m:24s remains)
INFO - root - 2019-11-06 17:48:10.964683: step 12560, total loss = 1.11, predict loss = 0.33 (56.1 examples/sec; 0.071 sec/batch; 2h:43m:23s remains)
INFO - root - 2019-11-06 17:48:11.663162: step 12570, total loss = 1.31, predict loss = 0.42 (76.0 examples/sec; 0.053 sec/batch; 2h:00m:31s remains)
INFO - root - 2019-11-06 17:48:12.155150: step 12580, total loss = 0.61, predict loss = 0.17 (94.4 examples/sec; 0.042 sec/batch; 1h:37m:00s remains)
INFO - root - 2019-11-06 17:48:12.598636: step 12590, total loss = 0.68, predict loss = 0.17 (95.9 examples/sec; 0.042 sec/batch; 1h:35m:30s remains)
INFO - root - 2019-11-06 17:48:13.728316: step 12600, total loss = 0.69, predict loss = 0.17 (69.1 examples/sec; 0.058 sec/batch; 2h:12m:29s remains)
INFO - root - 2019-11-06 17:48:14.475044: step 12610, total loss = 1.21, predict loss = 0.32 (59.4 examples/sec; 0.067 sec/batch; 2h:34m:13s remains)
INFO - root - 2019-11-06 17:48:15.213641: step 12620, total loss = 0.54, predict loss = 0.14 (67.7 examples/sec; 0.059 sec/batch; 2h:15m:16s remains)
INFO - root - 2019-11-06 17:48:15.922819: step 12630, total loss = 0.48, predict loss = 0.11 (59.5 examples/sec; 0.067 sec/batch; 2h:33m:57s remains)
INFO - root - 2019-11-06 17:48:16.645145: step 12640, total loss = 0.70, predict loss = 0.17 (63.0 examples/sec; 0.064 sec/batch; 2h:25m:24s remains)
INFO - root - 2019-11-06 17:48:17.292303: step 12650, total loss = 0.49, predict loss = 0.13 (100.0 examples/sec; 0.040 sec/batch; 1h:31m:34s remains)
INFO - root - 2019-11-06 17:48:17.730786: step 12660, total loss = 0.59, predict loss = 0.17 (98.0 examples/sec; 0.041 sec/batch; 1h:33m:25s remains)
INFO - root - 2019-11-06 17:48:18.172611: step 12670, total loss = 0.71, predict loss = 0.16 (95.7 examples/sec; 0.042 sec/batch; 1h:35m:37s remains)
INFO - root - 2019-11-06 17:48:19.433779: step 12680, total loss = 1.06, predict loss = 0.29 (53.5 examples/sec; 0.075 sec/batch; 2h:51m:04s remains)
INFO - root - 2019-11-06 17:48:20.155623: step 12690, total loss = 0.51, predict loss = 0.12 (59.9 examples/sec; 0.067 sec/batch; 2h:32m:43s remains)
INFO - root - 2019-11-06 17:48:20.939220: step 12700, total loss = 1.09, predict loss = 0.31 (57.2 examples/sec; 0.070 sec/batch; 2h:40m:05s remains)
INFO - root - 2019-11-06 17:48:21.692591: step 12710, total loss = 0.93, predict loss = 0.21 (61.6 examples/sec; 0.065 sec/batch; 2h:28m:36s remains)
INFO - root - 2019-11-06 17:48:22.429699: step 12720, total loss = 0.31, predict loss = 0.09 (67.6 examples/sec; 0.059 sec/batch; 2h:15m:23s remains)
INFO - root - 2019-11-06 17:48:22.964037: step 12730, total loss = 0.67, predict loss = 0.18 (94.4 examples/sec; 0.042 sec/batch; 1h:36m:56s remains)
INFO - root - 2019-11-06 17:48:23.434528: step 12740, total loss = 1.00, predict loss = 0.24 (92.8 examples/sec; 0.043 sec/batch; 1h:38m:37s remains)
INFO - root - 2019-11-06 17:48:24.526741: step 12750, total loss = 0.56, predict loss = 0.11 (66.2 examples/sec; 0.060 sec/batch; 2h:18m:08s remains)
INFO - root - 2019-11-06 17:48:25.257451: step 12760, total loss = 0.64, predict loss = 0.16 (50.3 examples/sec; 0.079 sec/batch; 3h:01m:49s remains)
INFO - root - 2019-11-06 17:48:26.046353: step 12770, total loss = 0.92, predict loss = 0.28 (60.4 examples/sec; 0.066 sec/batch; 2h:31m:32s remains)
INFO - root - 2019-11-06 17:48:26.811205: step 12780, total loss = 0.52, predict loss = 0.13 (70.9 examples/sec; 0.056 sec/batch; 2h:09m:00s remains)
INFO - root - 2019-11-06 17:48:27.555306: step 12790, total loss = 0.93, predict loss = 0.27 (61.4 examples/sec; 0.065 sec/batch; 2h:28m:57s remains)
INFO - root - 2019-11-06 17:48:28.126645: step 12800, total loss = 1.43, predict loss = 0.35 (106.4 examples/sec; 0.038 sec/batch; 1h:25m:57s remains)
INFO - root - 2019-11-06 17:48:28.588854: step 12810, total loss = 0.58, predict loss = 0.14 (99.5 examples/sec; 0.040 sec/batch; 1h:31m:53s remains)
INFO - root - 2019-11-06 17:48:29.057650: step 12820, total loss = 1.18, predict loss = 0.27 (92.0 examples/sec; 0.043 sec/batch; 1h:39m:21s remains)
INFO - root - 2019-11-06 17:48:30.434648: step 12830, total loss = 0.91, predict loss = 0.22 (55.5 examples/sec; 0.072 sec/batch; 2h:44m:38s remains)
INFO - root - 2019-11-06 17:48:31.185267: step 12840, total loss = 0.41, predict loss = 0.09 (55.6 examples/sec; 0.072 sec/batch; 2h:44m:28s remains)
INFO - root - 2019-11-06 17:48:31.994533: step 12850, total loss = 1.10, predict loss = 0.33 (63.4 examples/sec; 0.063 sec/batch; 2h:24m:11s remains)
INFO - root - 2019-11-06 17:48:32.804599: step 12860, total loss = 0.48, predict loss = 0.12 (55.0 examples/sec; 0.073 sec/batch; 2h:46m:17s remains)
INFO - root - 2019-11-06 17:48:33.560065: step 12870, total loss = 0.93, predict loss = 0.22 (59.1 examples/sec; 0.068 sec/batch; 2h:34m:42s remains)
INFO - root - 2019-11-06 17:48:34.028861: step 12880, total loss = 0.83, predict loss = 0.23 (107.5 examples/sec; 0.037 sec/batch; 1h:25m:00s remains)
INFO - root - 2019-11-06 17:48:34.497207: step 12890, total loss = 0.42, predict loss = 0.11 (104.0 examples/sec; 0.038 sec/batch; 1h:27m:52s remains)
INFO - root - 2019-11-06 17:48:35.742572: step 12900, total loss = 0.97, predict loss = 0.26 (62.7 examples/sec; 0.064 sec/batch; 2h:25m:45s remains)
INFO - root - 2019-11-06 17:48:36.476953: step 12910, total loss = 1.74, predict loss = 0.52 (50.2 examples/sec; 0.080 sec/batch; 3h:02m:05s remains)
INFO - root - 2019-11-06 17:48:37.248782: step 12920, total loss = 0.64, predict loss = 0.13 (47.0 examples/sec; 0.085 sec/batch; 3h:14m:16s remains)
INFO - root - 2019-11-06 17:48:38.017372: step 12930, total loss = 0.88, predict loss = 0.25 (61.6 examples/sec; 0.065 sec/batch; 2h:28m:16s remains)
INFO - root - 2019-11-06 17:48:38.766780: step 12940, total loss = 0.73, predict loss = 0.17 (56.3 examples/sec; 0.071 sec/batch; 2h:42m:15s remains)
INFO - root - 2019-11-06 17:48:39.337472: step 12950, total loss = 1.00, predict loss = 0.29 (101.4 examples/sec; 0.039 sec/batch; 1h:30m:06s remains)
INFO - root - 2019-11-06 17:48:39.778562: step 12960, total loss = 0.95, predict loss = 0.27 (102.6 examples/sec; 0.039 sec/batch; 1h:29m:02s remains)
INFO - root - 2019-11-06 17:48:40.258528: step 12970, total loss = 1.49, predict loss = 0.46 (148.7 examples/sec; 0.027 sec/batch; 1h:01m:25s remains)
INFO - root - 2019-11-06 17:48:41.787388: step 12980, total loss = 0.83, predict loss = 0.22 (54.4 examples/sec; 0.074 sec/batch; 2h:47m:52s remains)
INFO - root - 2019-11-06 17:48:42.617542: step 12990, total loss = 0.51, predict loss = 0.13 (63.7 examples/sec; 0.063 sec/batch; 2h:23m:28s remains)
INFO - root - 2019-11-06 17:48:43.330277: step 13000, total loss = 0.85, predict loss = 0.25 (67.1 examples/sec; 0.060 sec/batch; 2h:16m:04s remains)
INFO - root - 2019-11-06 17:48:44.089999: step 13010, total loss = 1.58, predict loss = 0.53 (63.6 examples/sec; 0.063 sec/batch; 2h:23m:37s remains)
INFO - root - 2019-11-06 17:48:44.743004: step 13020, total loss = 0.48, predict loss = 0.12 (79.1 examples/sec; 0.051 sec/batch; 1h:55m:25s remains)
INFO - root - 2019-11-06 17:48:45.190670: step 13030, total loss = 0.58, predict loss = 0.14 (95.8 examples/sec; 0.042 sec/batch; 1h:35m:20s remains)
INFO - root - 2019-11-06 17:48:45.700280: step 13040, total loss = 1.02, predict loss = 0.29 (88.1 examples/sec; 0.045 sec/batch; 1h:43m:36s remains)
INFO - root - 2019-11-06 17:48:47.050576: step 13050, total loss = 1.18, predict loss = 0.36 (64.1 examples/sec; 0.062 sec/batch; 2h:22m:21s remains)
INFO - root - 2019-11-06 17:48:47.785399: step 13060, total loss = 1.32, predict loss = 0.35 (64.3 examples/sec; 0.062 sec/batch; 2h:21m:58s remains)
INFO - root - 2019-11-06 17:48:48.497954: step 13070, total loss = 1.01, predict loss = 0.27 (70.8 examples/sec; 0.056 sec/batch; 2h:08m:52s remains)
INFO - root - 2019-11-06 17:48:49.215183: step 13080, total loss = 0.85, predict loss = 0.24 (56.8 examples/sec; 0.070 sec/batch; 2h:40m:49s remains)
INFO - root - 2019-11-06 17:48:49.992146: step 13090, total loss = 0.57, predict loss = 0.13 (68.5 examples/sec; 0.058 sec/batch; 2h:13m:11s remains)
INFO - root - 2019-11-06 17:48:50.511246: step 13100, total loss = 0.61, predict loss = 0.16 (96.7 examples/sec; 0.041 sec/batch; 1h:34m:25s remains)
INFO - root - 2019-11-06 17:48:50.954297: step 13110, total loss = 1.45, predict loss = 0.43 (98.3 examples/sec; 0.041 sec/batch; 1h:32m:52s remains)
INFO - root - 2019-11-06 17:48:52.084283: step 13120, total loss = 0.85, predict loss = 0.25 (5.5 examples/sec; 0.729 sec/batch; 27h:42m:50s remains)
INFO - root - 2019-11-06 17:48:52.766801: step 13130, total loss = 0.46, predict loss = 0.15 (60.8 examples/sec; 0.066 sec/batch; 2h:30m:07s remains)
INFO - root - 2019-11-06 17:48:53.564891: step 13140, total loss = 0.54, predict loss = 0.13 (55.5 examples/sec; 0.072 sec/batch; 2h:44m:16s remains)
INFO - root - 2019-11-06 17:48:54.338385: step 13150, total loss = 0.77, predict loss = 0.21 (60.8 examples/sec; 0.066 sec/batch; 2h:30m:05s remains)
INFO - root - 2019-11-06 17:48:55.096192: step 13160, total loss = 0.88, predict loss = 0.21 (58.2 examples/sec; 0.069 sec/batch; 2h:36m:46s remains)
INFO - root - 2019-11-06 17:48:55.767021: step 13170, total loss = 0.95, predict loss = 0.23 (93.7 examples/sec; 0.043 sec/batch; 1h:37m:22s remains)
INFO - root - 2019-11-06 17:48:56.210972: step 13180, total loss = 0.84, predict loss = 0.22 (101.3 examples/sec; 0.039 sec/batch; 1h:30m:02s remains)
INFO - root - 2019-11-06 17:48:56.657941: step 13190, total loss = 0.64, predict loss = 0.16 (98.9 examples/sec; 0.040 sec/batch; 1h:32m:13s remains)
INFO - root - 2019-11-06 17:48:57.873906: step 13200, total loss = 0.44, predict loss = 0.12 (49.1 examples/sec; 0.081 sec/batch; 3h:05m:39s remains)
INFO - root - 2019-11-06 17:48:58.613362: step 13210, total loss = 1.10, predict loss = 0.30 (66.7 examples/sec; 0.060 sec/batch; 2h:16m:42s remains)
INFO - root - 2019-11-06 17:48:59.426328: step 13220, total loss = 0.66, predict loss = 0.18 (55.4 examples/sec; 0.072 sec/batch; 2h:44m:38s remains)
INFO - root - 2019-11-06 17:49:00.292189: step 13230, total loss = 0.60, predict loss = 0.14 (59.2 examples/sec; 0.068 sec/batch; 2h:33m:54s remains)
INFO - root - 2019-11-06 17:49:01.013471: step 13240, total loss = 0.92, predict loss = 0.26 (76.7 examples/sec; 0.052 sec/batch; 1h:58m:52s remains)
INFO - root - 2019-11-06 17:49:01.551183: step 13250, total loss = 0.86, predict loss = 0.18 (102.2 examples/sec; 0.039 sec/batch; 1h:29m:11s remains)
INFO - root - 2019-11-06 17:49:02.000043: step 13260, total loss = 0.74, predict loss = 0.18 (96.8 examples/sec; 0.041 sec/batch; 1h:34m:11s remains)
INFO - root - 2019-11-06 17:49:03.105861: step 13270, total loss = 1.09, predict loss = 0.26 (72.8 examples/sec; 0.055 sec/batch; 2h:05m:09s remains)
INFO - root - 2019-11-06 17:49:03.768882: step 13280, total loss = 0.43, predict loss = 0.10 (65.0 examples/sec; 0.062 sec/batch; 2h:20m:13s remains)
INFO - root - 2019-11-06 17:49:04.541687: step 13290, total loss = 0.96, predict loss = 0.27 (54.9 examples/sec; 0.073 sec/batch; 2h:46m:01s remains)
INFO - root - 2019-11-06 17:49:05.325055: step 13300, total loss = 0.72, predict loss = 0.14 (51.9 examples/sec; 0.077 sec/batch; 2h:55m:32s remains)
INFO - root - 2019-11-06 17:49:06.089998: step 13310, total loss = 0.63, predict loss = 0.15 (60.0 examples/sec; 0.067 sec/batch; 2h:31m:56s remains)
INFO - root - 2019-11-06 17:49:06.734171: step 13320, total loss = 1.32, predict loss = 0.38 (98.8 examples/sec; 0.040 sec/batch; 1h:32m:11s remains)
INFO - root - 2019-11-06 17:49:07.172913: step 13330, total loss = 0.74, predict loss = 0.20 (107.4 examples/sec; 0.037 sec/batch; 1h:24m:51s remains)
INFO - root - 2019-11-06 17:49:07.623665: step 13340, total loss = 0.96, predict loss = 0.27 (93.7 examples/sec; 0.043 sec/batch; 1h:37m:15s remains)
INFO - root - 2019-11-06 17:49:08.983136: step 13350, total loss = 0.71, predict loss = 0.17 (43.8 examples/sec; 0.091 sec/batch; 3h:28m:05s remains)
INFO - root - 2019-11-06 17:49:09.797981: step 13360, total loss = 0.74, predict loss = 0.18 (57.6 examples/sec; 0.069 sec/batch; 2h:38m:07s remains)
INFO - root - 2019-11-06 17:49:10.608513: step 13370, total loss = 0.75, predict loss = 0.19 (62.9 examples/sec; 0.064 sec/batch; 2h:24m:54s remains)
INFO - root - 2019-11-06 17:49:11.275118: step 13380, total loss = 0.87, predict loss = 0.21 (60.8 examples/sec; 0.066 sec/batch; 2h:29m:45s remains)
INFO - root - 2019-11-06 17:49:11.999445: step 13390, total loss = 0.67, predict loss = 0.16 (70.3 examples/sec; 0.057 sec/batch; 2h:09m:29s remains)
INFO - root - 2019-11-06 17:49:12.495845: step 13400, total loss = 1.04, predict loss = 0.37 (97.6 examples/sec; 0.041 sec/batch; 1h:33m:16s remains)
INFO - root - 2019-11-06 17:49:12.986360: step 13410, total loss = 1.68, predict loss = 0.45 (96.9 examples/sec; 0.041 sec/batch; 1h:33m:57s remains)
INFO - root - 2019-11-06 17:49:14.102646: step 13420, total loss = 0.66, predict loss = 0.16 (73.2 examples/sec; 0.055 sec/batch; 2h:04m:26s remains)
INFO - root - 2019-11-06 17:49:14.781938: step 13430, total loss = 0.50, predict loss = 0.14 (66.7 examples/sec; 0.060 sec/batch; 2h:16m:24s remains)
INFO - root - 2019-11-06 17:49:15.551313: step 13440, total loss = 0.72, predict loss = 0.17 (51.0 examples/sec; 0.078 sec/batch; 2h:58m:31s remains)
INFO - root - 2019-11-06 17:49:16.281918: step 13450, total loss = 0.53, predict loss = 0.12 (57.1 examples/sec; 0.070 sec/batch; 2h:39m:17s remains)
INFO - root - 2019-11-06 17:49:17.052303: step 13460, total loss = 1.21, predict loss = 0.33 (61.8 examples/sec; 0.065 sec/batch; 2h:27m:19s remains)
INFO - root - 2019-11-06 17:49:17.699084: step 13470, total loss = 1.58, predict loss = 0.42 (100.1 examples/sec; 0.040 sec/batch; 1h:30m:53s remains)
INFO - root - 2019-11-06 17:49:18.124858: step 13480, total loss = 1.42, predict loss = 0.40 (102.4 examples/sec; 0.039 sec/batch; 1h:28m:52s remains)
INFO - root - 2019-11-06 17:49:18.611129: step 13490, total loss = 1.06, predict loss = 0.27 (92.4 examples/sec; 0.043 sec/batch; 1h:38m:29s remains)
INFO - root - 2019-11-06 17:49:19.914315: step 13500, total loss = 0.75, predict loss = 0.20 (48.5 examples/sec; 0.082 sec/batch; 3h:07m:32s remains)
INFO - root - 2019-11-06 17:49:20.697657: step 13510, total loss = 0.59, predict loss = 0.15 (60.5 examples/sec; 0.066 sec/batch; 2h:30m:29s remains)
INFO - root - 2019-11-06 17:49:21.443819: step 13520, total loss = 1.07, predict loss = 0.33 (58.7 examples/sec; 0.068 sec/batch; 2h:35m:05s remains)
INFO - root - 2019-11-06 17:49:22.252918: step 13530, total loss = 0.96, predict loss = 0.28 (59.1 examples/sec; 0.068 sec/batch; 2h:33m:55s remains)
INFO - root - 2019-11-06 17:49:22.991812: step 13540, total loss = 1.36, predict loss = 0.37 (62.1 examples/sec; 0.064 sec/batch; 2h:26m:27s remains)
INFO - root - 2019-11-06 17:49:23.494842: step 13550, total loss = 0.77, predict loss = 0.20 (89.1 examples/sec; 0.045 sec/batch; 1h:42m:06s remains)
INFO - root - 2019-11-06 17:49:23.981981: step 13560, total loss = 0.78, predict loss = 0.20 (100.3 examples/sec; 0.040 sec/batch; 1h:30m:39s remains)
INFO - root - 2019-11-06 17:49:25.360243: step 13570, total loss = 0.71, predict loss = 0.16 (59.3 examples/sec; 0.067 sec/batch; 2h:33m:25s remains)
INFO - root - 2019-11-06 17:49:26.156644: step 13580, total loss = 0.77, predict loss = 0.25 (54.6 examples/sec; 0.073 sec/batch; 2h:46m:40s remains)
INFO - root - 2019-11-06 17:49:26.927584: step 13590, total loss = 1.32, predict loss = 0.34 (65.9 examples/sec; 0.061 sec/batch; 2h:17m:55s remains)
INFO - root - 2019-11-06 17:49:27.677707: step 13600, total loss = 0.49, predict loss = 0.12 (59.5 examples/sec; 0.067 sec/batch; 2h:32m:54s remains)
INFO - root - 2019-11-06 17:49:28.411320: step 13610, total loss = 0.35, predict loss = 0.08 (62.0 examples/sec; 0.064 sec/batch; 2h:26m:34s remains)
INFO - root - 2019-11-06 17:49:28.996861: step 13620, total loss = 1.37, predict loss = 0.40 (94.1 examples/sec; 0.042 sec/batch; 1h:36m:34s remains)
INFO - root - 2019-11-06 17:49:29.451316: step 13630, total loss = 0.82, predict loss = 0.21 (101.4 examples/sec; 0.039 sec/batch; 1h:29m:40s remains)
INFO - root - 2019-11-06 17:49:29.906838: step 13640, total loss = 1.21, predict loss = 0.30 (95.0 examples/sec; 0.042 sec/batch; 1h:35m:40s remains)
INFO - root - 2019-11-06 17:49:31.334912: step 13650, total loss = 1.34, predict loss = 0.37 (64.0 examples/sec; 0.062 sec/batch; 2h:22m:01s remains)
INFO - root - 2019-11-06 17:49:32.099356: step 13660, total loss = 0.99, predict loss = 0.26 (56.2 examples/sec; 0.071 sec/batch; 2h:41m:35s remains)
INFO - root - 2019-11-06 17:49:32.949937: step 13670, total loss = 1.81, predict loss = 0.57 (58.7 examples/sec; 0.068 sec/batch; 2h:34m:55s remains)
INFO - root - 2019-11-06 17:49:33.677036: step 13680, total loss = 0.70, predict loss = 0.22 (60.9 examples/sec; 0.066 sec/batch; 2h:29m:17s remains)
INFO - root - 2019-11-06 17:49:34.402698: step 13690, total loss = 0.70, predict loss = 0.15 (71.5 examples/sec; 0.056 sec/batch; 2h:07m:09s remains)
INFO - root - 2019-11-06 17:49:34.885362: step 13700, total loss = 1.20, predict loss = 0.28 (96.5 examples/sec; 0.041 sec/batch; 1h:34m:12s remains)
INFO - root - 2019-11-06 17:49:35.327972: step 13710, total loss = 0.70, predict loss = 0.16 (103.4 examples/sec; 0.039 sec/batch; 1h:27m:50s remains)
INFO - root - 2019-11-06 17:49:36.483850: step 13720, total loss = 0.77, predict loss = 0.19 (63.0 examples/sec; 0.064 sec/batch; 2h:24m:17s remains)
INFO - root - 2019-11-06 17:49:37.209450: step 13730, total loss = 1.11, predict loss = 0.23 (58.8 examples/sec; 0.068 sec/batch; 2h:34m:36s remains)
INFO - root - 2019-11-06 17:49:37.925494: step 13740, total loss = 0.89, predict loss = 0.21 (67.2 examples/sec; 0.060 sec/batch; 2h:15m:07s remains)
INFO - root - 2019-11-06 17:49:38.724249: step 13750, total loss = 0.76, predict loss = 0.18 (42.1 examples/sec; 0.095 sec/batch; 3h:35m:36s remains)
INFO - root - 2019-11-06 17:49:39.506095: step 13760, total loss = 1.24, predict loss = 0.34 (67.9 examples/sec; 0.059 sec/batch; 2h:13m:46s remains)
INFO - root - 2019-11-06 17:49:40.078617: step 13770, total loss = 1.02, predict loss = 0.29 (94.9 examples/sec; 0.042 sec/batch; 1h:35m:44s remains)
INFO - root - 2019-11-06 17:49:40.530963: step 13780, total loss = 0.68, predict loss = 0.21 (94.8 examples/sec; 0.042 sec/batch; 1h:35m:50s remains)
INFO - root - 2019-11-06 17:49:40.965388: step 13790, total loss = 1.44, predict loss = 0.45 (132.3 examples/sec; 0.030 sec/batch; 1h:08m:37s remains)
INFO - root - 2019-11-06 17:49:42.332358: step 13800, total loss = 0.86, predict loss = 0.27 (66.0 examples/sec; 0.061 sec/batch; 2h:17m:40s remains)
INFO - root - 2019-11-06 17:49:43.086410: step 13810, total loss = 0.63, predict loss = 0.19 (56.7 examples/sec; 0.071 sec/batch; 2h:40m:08s remains)
INFO - root - 2019-11-06 17:49:43.802313: step 13820, total loss = 1.06, predict loss = 0.28 (65.6 examples/sec; 0.061 sec/batch; 2h:18m:21s remains)
INFO - root - 2019-11-06 17:49:44.468404: step 13830, total loss = 0.61, predict loss = 0.14 (58.5 examples/sec; 0.068 sec/batch; 2h:35m:13s remains)
INFO - root - 2019-11-06 17:49:45.109524: step 13840, total loss = 1.41, predict loss = 0.38 (83.2 examples/sec; 0.048 sec/batch; 1h:49m:07s remains)
INFO - root - 2019-11-06 17:49:45.589478: step 13850, total loss = 0.99, predict loss = 0.26 (95.6 examples/sec; 0.042 sec/batch; 1h:34m:54s remains)
INFO - root - 2019-11-06 17:49:46.027243: step 13860, total loss = 0.86, predict loss = 0.19 (100.4 examples/sec; 0.040 sec/batch; 1h:30m:22s remains)
INFO - root - 2019-11-06 17:49:47.179368: step 13870, total loss = 0.63, predict loss = 0.13 (67.8 examples/sec; 0.059 sec/batch; 2h:13m:52s remains)
INFO - root - 2019-11-06 17:49:47.907623: step 13880, total loss = 0.70, predict loss = 0.18 (64.1 examples/sec; 0.062 sec/batch; 2h:21m:28s remains)
INFO - root - 2019-11-06 17:49:48.674916: step 13890, total loss = 0.73, predict loss = 0.20 (56.5 examples/sec; 0.071 sec/batch; 2h:40m:39s remains)
INFO - root - 2019-11-06 17:49:49.357165: step 13900, total loss = 0.69, predict loss = 0.17 (59.5 examples/sec; 0.067 sec/batch; 2h:32m:30s remains)
INFO - root - 2019-11-06 17:49:50.027402: step 13910, total loss = 0.91, predict loss = 0.26 (72.5 examples/sec; 0.055 sec/batch; 2h:05m:12s remains)
INFO - root - 2019-11-06 17:49:50.559321: step 13920, total loss = 0.89, predict loss = 0.22 (96.4 examples/sec; 0.042 sec/batch; 1h:34m:07s remains)
INFO - root - 2019-11-06 17:49:51.011609: step 13930, total loss = 0.53, predict loss = 0.13 (104.9 examples/sec; 0.038 sec/batch; 1h:26m:30s remains)
INFO - root - 2019-11-06 17:49:52.131496: step 13940, total loss = 0.88, predict loss = 0.21 (5.6 examples/sec; 0.719 sec/batch; 27h:11m:32s remains)
INFO - root - 2019-11-06 17:49:52.823741: step 13950, total loss = 0.79, predict loss = 0.22 (56.1 examples/sec; 0.071 sec/batch; 2h:41m:39s remains)
INFO - root - 2019-11-06 17:49:53.587200: step 13960, total loss = 0.57, predict loss = 0.12 (52.0 examples/sec; 0.077 sec/batch; 2h:54m:21s remains)
INFO - root - 2019-11-06 17:49:54.341767: step 13970, total loss = 0.58, predict loss = 0.14 (61.2 examples/sec; 0.065 sec/batch; 2h:28m:05s remains)
INFO - root - 2019-11-06 17:49:55.094511: step 13980, total loss = 1.18, predict loss = 0.36 (56.4 examples/sec; 0.071 sec/batch; 2h:40m:51s remains)
INFO - root - 2019-11-06 17:49:55.775567: step 13990, total loss = 1.02, predict loss = 0.30 (91.3 examples/sec; 0.044 sec/batch; 1h:39m:21s remains)
INFO - root - 2019-11-06 17:49:56.222024: step 14000, total loss = 0.63, predict loss = 0.13 (98.5 examples/sec; 0.041 sec/batch; 1h:32m:00s remains)
INFO - root - 2019-11-06 17:49:56.687811: step 14010, total loss = 0.88, predict loss = 0.17 (98.7 examples/sec; 0.041 sec/batch; 1h:31m:48s remains)
INFO - root - 2019-11-06 17:49:57.944604: step 14020, total loss = 1.15, predict loss = 0.32 (66.0 examples/sec; 0.061 sec/batch; 2h:17m:22s remains)
INFO - root - 2019-11-06 17:49:58.639011: step 14030, total loss = 0.94, predict loss = 0.24 (60.3 examples/sec; 0.066 sec/batch; 2h:30m:21s remains)
INFO - root - 2019-11-06 17:49:59.358014: step 14040, total loss = 1.07, predict loss = 0.31 (69.9 examples/sec; 0.057 sec/batch; 2h:09m:43s remains)
INFO - root - 2019-11-06 17:50:00.156845: step 14050, total loss = 1.57, predict loss = 0.43 (52.0 examples/sec; 0.077 sec/batch; 2h:54m:13s remains)
INFO - root - 2019-11-06 17:50:00.878695: step 14060, total loss = 0.79, predict loss = 0.21 (64.4 examples/sec; 0.062 sec/batch; 2h:20m:40s remains)
INFO - root - 2019-11-06 17:50:01.397720: step 14070, total loss = 0.52, predict loss = 0.13 (97.2 examples/sec; 0.041 sec/batch; 1h:33m:11s remains)
INFO - root - 2019-11-06 17:50:01.844926: step 14080, total loss = 0.55, predict loss = 0.13 (102.8 examples/sec; 0.039 sec/batch; 1h:28m:09s remains)
INFO - root - 2019-11-06 17:50:03.004231: step 14090, total loss = 0.94, predict loss = 0.30 (69.1 examples/sec; 0.058 sec/batch; 2h:11m:03s remains)
INFO - root - 2019-11-06 17:50:03.687899: step 14100, total loss = 0.75, predict loss = 0.18 (60.0 examples/sec; 0.067 sec/batch; 2h:30m:56s remains)
INFO - root - 2019-11-06 17:50:04.432753: step 14110, total loss = 0.52, predict loss = 0.12 (60.2 examples/sec; 0.066 sec/batch; 2h:30m:26s remains)
INFO - root - 2019-11-06 17:50:05.176595: step 14120, total loss = 0.29, predict loss = 0.07 (58.7 examples/sec; 0.068 sec/batch; 2h:34m:25s remains)
INFO - root - 2019-11-06 17:50:05.922360: step 14130, total loss = 0.76, predict loss = 0.17 (64.0 examples/sec; 0.063 sec/batch; 2h:21m:34s remains)
INFO - root - 2019-11-06 17:50:06.592442: step 14140, total loss = 0.88, predict loss = 0.22 (90.7 examples/sec; 0.044 sec/batch; 1h:39m:50s remains)
INFO - root - 2019-11-06 17:50:07.045870: step 14150, total loss = 0.82, predict loss = 0.22 (84.2 examples/sec; 0.047 sec/batch; 1h:47m:32s remains)
INFO - root - 2019-11-06 17:50:07.486912: step 14160, total loss = 0.63, predict loss = 0.15 (106.1 examples/sec; 0.038 sec/batch; 1h:25m:22s remains)
INFO - root - 2019-11-06 17:50:08.801207: step 14170, total loss = 1.34, predict loss = 0.40 (68.2 examples/sec; 0.059 sec/batch; 2h:12m:50s remains)
INFO - root - 2019-11-06 17:50:09.523752: step 14180, total loss = 1.05, predict loss = 0.29 (67.2 examples/sec; 0.060 sec/batch; 2h:14m:42s remains)
INFO - root - 2019-11-06 17:50:10.250195: step 14190, total loss = 0.91, predict loss = 0.25 (67.6 examples/sec; 0.059 sec/batch; 2h:13m:50s remains)
INFO - root - 2019-11-06 17:50:10.961622: step 14200, total loss = 0.54, predict loss = 0.14 (61.3 examples/sec; 0.065 sec/batch; 2h:27m:45s remains)
INFO - root - 2019-11-06 17:50:11.696188: step 14210, total loss = 0.73, predict loss = 0.19 (68.2 examples/sec; 0.059 sec/batch; 2h:12m:49s remains)
INFO - root - 2019-11-06 17:50:12.191091: step 14220, total loss = 1.70, predict loss = 0.52 (98.6 examples/sec; 0.041 sec/batch; 1h:31m:46s remains)
INFO - root - 2019-11-06 17:50:12.635359: step 14230, total loss = 0.96, predict loss = 0.22 (94.7 examples/sec; 0.042 sec/batch; 1h:35m:35s remains)
INFO - root - 2019-11-06 17:50:13.768937: step 14240, total loss = 0.43, predict loss = 0.09 (68.8 examples/sec; 0.058 sec/batch; 2h:11m:37s remains)
INFO - root - 2019-11-06 17:50:14.475195: step 14250, total loss = 1.93, predict loss = 0.65 (68.6 examples/sec; 0.058 sec/batch; 2h:11m:56s remains)
INFO - root - 2019-11-06 17:50:15.212219: step 14260, total loss = 0.83, predict loss = 0.24 (67.8 examples/sec; 0.059 sec/batch; 2h:13m:32s remains)
INFO - root - 2019-11-06 17:50:15.956642: step 14270, total loss = 1.24, predict loss = 0.33 (61.2 examples/sec; 0.065 sec/batch; 2h:27m:54s remains)
INFO - root - 2019-11-06 17:50:16.703904: step 14280, total loss = 0.80, predict loss = 0.22 (55.6 examples/sec; 0.072 sec/batch; 2h:42m:37s remains)
INFO - root - 2019-11-06 17:50:17.324629: step 14290, total loss = 0.44, predict loss = 0.10 (99.4 examples/sec; 0.040 sec/batch; 1h:31m:03s remains)
INFO - root - 2019-11-06 17:50:17.764722: step 14300, total loss = 0.33, predict loss = 0.08 (95.4 examples/sec; 0.042 sec/batch; 1h:34m:49s remains)
INFO - root - 2019-11-06 17:50:18.229735: step 14310, total loss = 0.70, predict loss = 0.16 (89.7 examples/sec; 0.045 sec/batch; 1h:40m:49s remains)
INFO - root - 2019-11-06 17:50:19.517270: step 14320, total loss = 0.55, predict loss = 0.12 (62.0 examples/sec; 0.064 sec/batch; 2h:25m:47s remains)
INFO - root - 2019-11-06 17:50:20.275528: step 14330, total loss = 1.32, predict loss = 0.34 (55.6 examples/sec; 0.072 sec/batch; 2h:42m:39s remains)
INFO - root - 2019-11-06 17:50:20.981470: step 14340, total loss = 0.76, predict loss = 0.17 (65.3 examples/sec; 0.061 sec/batch; 2h:18m:31s remains)
INFO - root - 2019-11-06 17:50:21.664969: step 14350, total loss = 0.52, predict loss = 0.13 (66.1 examples/sec; 0.060 sec/batch; 2h:16m:43s remains)
INFO - root - 2019-11-06 17:50:22.326513: step 14360, total loss = 0.82, predict loss = 0.21 (79.3 examples/sec; 0.050 sec/batch; 1h:53m:59s remains)
INFO - root - 2019-11-06 17:50:22.839136: step 14370, total loss = 0.73, predict loss = 0.20 (93.9 examples/sec; 0.043 sec/batch; 1h:36m:17s remains)
INFO - root - 2019-11-06 17:50:23.298643: step 14380, total loss = 0.63, predict loss = 0.17 (91.2 examples/sec; 0.044 sec/batch; 1h:39m:06s remains)
INFO - root - 2019-11-06 17:50:24.387275: step 14390, total loss = 1.14, predict loss = 0.29 (70.9 examples/sec; 0.056 sec/batch; 2h:07m:28s remains)
INFO - root - 2019-11-06 17:50:25.068631: step 14400, total loss = 0.99, predict loss = 0.27 (56.7 examples/sec; 0.071 sec/batch; 2h:39m:23s remains)
INFO - root - 2019-11-06 17:50:25.874301: step 14410, total loss = 0.65, predict loss = 0.17 (55.6 examples/sec; 0.072 sec/batch; 2h:42m:37s remains)
INFO - root - 2019-11-06 17:50:26.660725: step 14420, total loss = 0.80, predict loss = 0.19 (56.6 examples/sec; 0.071 sec/batch; 2h:39m:45s remains)
INFO - root - 2019-11-06 17:50:27.451224: step 14430, total loss = 0.60, predict loss = 0.13 (61.2 examples/sec; 0.065 sec/batch; 2h:27m:35s remains)
INFO - root - 2019-11-06 17:50:28.047553: step 14440, total loss = 0.67, predict loss = 0.15 (97.5 examples/sec; 0.041 sec/batch; 1h:32m:42s remains)
INFO - root - 2019-11-06 17:50:28.519979: step 14450, total loss = 0.46, predict loss = 0.11 (101.2 examples/sec; 0.040 sec/batch; 1h:29m:15s remains)
INFO - root - 2019-11-06 17:50:28.965332: step 14460, total loss = 1.01, predict loss = 0.26 (95.8 examples/sec; 0.042 sec/batch; 1h:34m:20s remains)
INFO - root - 2019-11-06 17:50:30.227848: step 14470, total loss = 0.59, predict loss = 0.14 (63.0 examples/sec; 0.064 sec/batch; 2h:23m:30s remains)
INFO - root - 2019-11-06 17:50:30.951687: step 14480, total loss = 0.67, predict loss = 0.20 (61.7 examples/sec; 0.065 sec/batch; 2h:26m:30s remains)
INFO - root - 2019-11-06 17:50:31.725127: step 14490, total loss = 0.78, predict loss = 0.19 (55.5 examples/sec; 0.072 sec/batch; 2h:42m:54s remains)
INFO - root - 2019-11-06 17:50:32.500648: step 14500, total loss = 1.55, predict loss = 0.50 (59.9 examples/sec; 0.067 sec/batch; 2h:30m:51s remains)
INFO - root - 2019-11-06 17:50:33.165229: step 14510, total loss = 0.75, predict loss = 0.20 (78.5 examples/sec; 0.051 sec/batch; 1h:55m:06s remains)
INFO - root - 2019-11-06 17:50:33.614739: step 14520, total loss = 1.37, predict loss = 0.38 (98.2 examples/sec; 0.041 sec/batch; 1h:32m:00s remains)
INFO - root - 2019-11-06 17:50:34.085161: step 14530, total loss = 0.67, predict loss = 0.16 (96.9 examples/sec; 0.041 sec/batch; 1h:33m:11s remains)
INFO - root - 2019-11-06 17:50:35.261405: step 14540, total loss = 0.85, predict loss = 0.20 (70.6 examples/sec; 0.057 sec/batch; 2h:07m:52s remains)
INFO - root - 2019-11-06 17:50:36.000216: step 14550, total loss = 0.55, predict loss = 0.13 (53.1 examples/sec; 0.075 sec/batch; 2h:50m:11s remains)
INFO - root - 2019-11-06 17:50:36.712307: step 14560, total loss = 0.90, predict loss = 0.26 (61.3 examples/sec; 0.065 sec/batch; 2h:27m:12s remains)
INFO - root - 2019-11-06 17:50:37.516359: step 14570, total loss = 0.52, predict loss = 0.14 (51.1 examples/sec; 0.078 sec/batch; 2h:56m:41s remains)
INFO - root - 2019-11-06 17:50:38.361129: step 14580, total loss = 0.85, predict loss = 0.19 (57.7 examples/sec; 0.069 sec/batch; 2h:36m:25s remains)
INFO - root - 2019-11-06 17:50:38.945834: step 14590, total loss = 1.41, predict loss = 0.42 (103.3 examples/sec; 0.039 sec/batch; 1h:27m:25s remains)
INFO - root - 2019-11-06 17:50:39.387233: step 14600, total loss = 0.95, predict loss = 0.23 (102.7 examples/sec; 0.039 sec/batch; 1h:27m:52s remains)
INFO - root - 2019-11-06 17:50:39.856183: step 14610, total loss = 0.74, predict loss = 0.20 (140.1 examples/sec; 0.029 sec/batch; 1h:04m:25s remains)
INFO - root - 2019-11-06 17:50:41.185132: step 14620, total loss = 0.65, predict loss = 0.17 (60.4 examples/sec; 0.066 sec/batch; 2h:29m:23s remains)
INFO - root - 2019-11-06 17:50:41.985830: step 14630, total loss = 0.74, predict loss = 0.16 (59.8 examples/sec; 0.067 sec/batch; 2h:30m:57s remains)
INFO - root - 2019-11-06 17:50:42.701410: step 14640, total loss = 0.67, predict loss = 0.15 (65.7 examples/sec; 0.061 sec/batch; 2h:17m:25s remains)
INFO - root - 2019-11-06 17:50:43.529291: step 14650, total loss = 0.54, predict loss = 0.13 (50.2 examples/sec; 0.080 sec/batch; 2h:59m:38s remains)
INFO - root - 2019-11-06 17:50:44.217210: step 14660, total loss = 1.13, predict loss = 0.28 (65.5 examples/sec; 0.061 sec/batch; 2h:17m:40s remains)
INFO - root - 2019-11-06 17:50:44.670537: step 14670, total loss = 1.19, predict loss = 0.32 (99.1 examples/sec; 0.040 sec/batch; 1h:31m:01s remains)
INFO - root - 2019-11-06 17:50:45.108593: step 14680, total loss = 0.78, predict loss = 0.18 (94.3 examples/sec; 0.042 sec/batch; 1h:35m:38s remains)
INFO - root - 2019-11-06 17:50:46.355519: step 14690, total loss = 0.64, predict loss = 0.19 (72.0 examples/sec; 0.056 sec/batch; 2h:05m:19s remains)
INFO - root - 2019-11-06 17:50:47.065219: step 14700, total loss = 1.35, predict loss = 0.37 (61.3 examples/sec; 0.065 sec/batch; 2h:27m:15s remains)
INFO - root - 2019-11-06 17:50:47.801399: step 14710, total loss = 0.48, predict loss = 0.11 (57.6 examples/sec; 0.069 sec/batch; 2h:36m:32s remains)
INFO - root - 2019-11-06 17:50:48.582955: step 14720, total loss = 0.96, predict loss = 0.27 (51.4 examples/sec; 0.078 sec/batch; 2h:55m:22s remains)
INFO - root - 2019-11-06 17:50:49.305353: step 14730, total loss = 0.43, predict loss = 0.10 (65.2 examples/sec; 0.061 sec/batch; 2h:18m:23s remains)
INFO - root - 2019-11-06 17:50:49.858617: step 14740, total loss = 0.62, predict loss = 0.12 (99.0 examples/sec; 0.040 sec/batch; 1h:31m:07s remains)
INFO - root - 2019-11-06 17:50:50.301492: step 14750, total loss = 0.80, predict loss = 0.17 (91.3 examples/sec; 0.044 sec/batch; 1h:38m:42s remains)
INFO - root - 2019-11-06 17:50:51.397562: step 14760, total loss = 0.68, predict loss = 0.19 (5.6 examples/sec; 0.710 sec/batch; 26h:40m:29s remains)
INFO - root - 2019-11-06 17:50:52.122744: step 14770, total loss = 0.54, predict loss = 0.14 (57.9 examples/sec; 0.069 sec/batch; 2h:35m:49s remains)
INFO - root - 2019-11-06 17:50:52.827326: step 14780, total loss = 0.50, predict loss = 0.13 (63.3 examples/sec; 0.063 sec/batch; 2h:22m:25s remains)
INFO - root - 2019-11-06 17:50:53.576300: step 14790, total loss = 0.85, predict loss = 0.22 (67.5 examples/sec; 0.059 sec/batch; 2h:13m:34s remains)
INFO - root - 2019-11-06 17:50:54.436106: step 14800, total loss = 0.45, predict loss = 0.10 (56.6 examples/sec; 0.071 sec/batch; 2h:39m:07s remains)
INFO - root - 2019-11-06 17:50:55.105903: step 14810, total loss = 0.89, predict loss = 0.24 (88.9 examples/sec; 0.045 sec/batch; 1h:41m:25s remains)
INFO - root - 2019-11-06 17:50:55.542019: step 14820, total loss = 1.49, predict loss = 0.44 (94.8 examples/sec; 0.042 sec/batch; 1h:35m:02s remains)
INFO - root - 2019-11-06 17:50:55.989254: step 14830, total loss = 0.72, predict loss = 0.17 (94.9 examples/sec; 0.042 sec/batch; 1h:34m:57s remains)
INFO - root - 2019-11-06 17:50:57.257335: step 14840, total loss = 0.66, predict loss = 0.16 (48.7 examples/sec; 0.082 sec/batch; 3h:05m:07s remains)
INFO - root - 2019-11-06 17:50:58.010302: step 14850, total loss = 0.72, predict loss = 0.19 (61.2 examples/sec; 0.065 sec/batch; 2h:27m:14s remains)
INFO - root - 2019-11-06 17:50:58.747940: step 14860, total loss = 0.50, predict loss = 0.12 (68.2 examples/sec; 0.059 sec/batch; 2h:12m:02s remains)
INFO - root - 2019-11-06 17:50:59.504907: step 14870, total loss = 0.85, predict loss = 0.20 (57.7 examples/sec; 0.069 sec/batch; 2h:36m:08s remains)
INFO - root - 2019-11-06 17:51:00.234267: step 14880, total loss = 1.10, predict loss = 0.28 (68.4 examples/sec; 0.059 sec/batch; 2h:11m:45s remains)
INFO - root - 2019-11-06 17:51:00.809498: step 14890, total loss = 0.50, predict loss = 0.13 (95.7 examples/sec; 0.042 sec/batch; 1h:34m:08s remains)
INFO - root - 2019-11-06 17:51:01.245000: step 14900, total loss = 0.53, predict loss = 0.13 (101.9 examples/sec; 0.039 sec/batch; 1h:28m:23s remains)
INFO - root - 2019-11-06 17:51:02.479082: step 14910, total loss = 1.13, predict loss = 0.29 (62.5 examples/sec; 0.064 sec/batch; 2h:24m:11s remains)
INFO - root - 2019-11-06 17:51:03.253982: step 14920, total loss = 0.55, predict loss = 0.14 (65.6 examples/sec; 0.061 sec/batch; 2h:17m:20s remains)
INFO - root - 2019-11-06 17:51:04.009768: step 14930, total loss = 0.69, predict loss = 0.15 (59.7 examples/sec; 0.067 sec/batch; 2h:30m:53s remains)
INFO - root - 2019-11-06 17:51:04.747337: step 14940, total loss = 1.29, predict loss = 0.38 (63.3 examples/sec; 0.063 sec/batch; 2h:22m:19s remains)
